{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ==================== COMPLETE ENHANCED MEME ANALYSIS PIPELINE ====================\n# FIXED VERSION: Prints \"Task A Weighted F1\" in Validation Logs & Final Summary\n# ==================================================================================\n\n# ==================== PART 0: SETUP & DEPENDENCIES ====================\nimport sys, subprocess, os, json, zipfile, shutil, random, warnings\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, Sampler, WeightedRandomSampler\nfrom torch.cuda.amp import GradScaler, autocast\nimport torchvision.transforms as transforms\nfrom PIL import Image\nfrom tqdm import tqdm\nimport yaml\nimport pickle \n\nwarnings.filterwarnings('ignore')\n\nprint(\"=\" * 80)\nprint(\"INSTALLING DEPENDENCIES...\")\nprint(\"=\" * 80)\n\n# Install required packages\nsubprocess.check_call([\n    sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n    \"transformers>=4.40.0\", \"accelerate\", \"torch\", \"timm\",\n    \"scikit-learn\", \"pandas\", \"matplotlib\", \"seaborn\",\n    \"huggingface_hub>=0.18.0\", \"gdown\", \"iterative-stratification\"\n])\n\n# Import additional packages\nfrom sklearn.metrics import (\n    accuracy_score, precision_recall_fscore_support,\n    mean_squared_error, mean_absolute_error, f1_score, fbeta_score\n)\nfrom transformers import AutoModel, AutoTokenizer, CLIPModel\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n\nprint(\"âœ“ All dependencies installed\\n\")\n\n\n# ==================== PART 1: DATA PREPARATION ====================\nprint(\"=\" * 80)\nprint(\"PART 1: DATA PREPARATION\")\nprint(\"=\" * 80)\n\n# Download and extract dataset\nprint(\"\\nDownloading dataset...\")\nsubprocess.run([\"gdown\", \"1jEJ2nf5CDJknq80ogzU-Uyz7jbBi-1LZ\", \"--fuzzy\"],\n               check=False, capture_output=True)\n\nprint(\"Extracting dataset...\")\nzip_files = [f for f in os.listdir('.') if f.endswith('.zip')]\nif zip_files:\n    subprocess.run([\"unzip\", \"-q\", \"-o\", zip_files[0]], check=False, capture_output=True)\n\n# Download additional files\nsubprocess.run([\n    \"gdown\", \"--folder\", \"19yaav8ORSVj9DeJUaHKq1H3HtVnkClBw\", \"--remaining-ok\"\n], check=False, capture_output=True)\n\n# Extract password-protected archive\nprint(\"Extracting protected archive...\")\nzip_path = '/kaggle/working/Memotion 3/memotion3.zip'\nextract_to = '/kaggle/working/'\npassword = b'memotion3taskaaai@22'\n\nif os.path.exists(zip_path):\n    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n        zip_ref.extractall(extract_to, pwd=password)\n    print(f\"âœ“ Extracted to: {extract_to}\")\n\n# Setup paths\nORIGINAL_TRAIN_IMG_DIR = '/kaggle/working/trainImages/'\nORIGINAL_CSV_PATH = '/kaggle/working/memotion3/train.csv'\nVALIDATION_SPLIT_RATIO = 0.15\n\nOUTPUT_BASE_DIR = '/kaggle/working/'\nNEW_VAL_DIR = os.path.join(OUTPUT_BASE_DIR, 'validation_images/')\nNEW_TRAIN_DIR = os.path.join(OUTPUT_BASE_DIR, 'new_train_images/')\n\nos.makedirs(NEW_VAL_DIR, exist_ok=True)\nos.makedirs(NEW_TRAIN_DIR, exist_ok=True)\n\n# Load and process CSV\nprint(\"\\nLoading CSV file...\")\ndf = pd.read_csv(ORIGINAL_CSV_PATH)\n\n# Detect image column\npossible_image_cols = ['image_name', 'image', 'img_name', 'filename', 'Unnamed: 0']\nIMAGE_FILENAME_COLUMN = next((col for col in possible_image_cols if col in df.columns), df.columns[0])\nprint(f\"âœ“ Image column: {IMAGE_FILENAME_COLUMN}\")\n\n# Normalize labels\nfor col in ['offensive', 'motivational', 'humour', 'humor', 'sarcastic', 'sarcasm', 'overall', 'sentiment']:\n    if col in df.columns:\n        df[col] = df[col].astype(str).str.lower().str.strip()\n\n# Create binary labels\ndef create_binary_label(value, positive_values):\n    if pd.isna(value) or value in ['nan', 'none', '']:\n        return 0\n    return 1 if value in positive_values else 0\n\nif 'offensive' in df.columns:\n    df['offensive_bin'] = df['offensive'].apply(\n        lambda x: create_binary_label(x, ['slight', 'very_offensive', 'hateful_offensive'])\n    )\nelse:\n    df['offensive_bin'] = 0\n\nif 'motivational' in df.columns:\n    df['motivational_bin'] = df['motivational'].apply(\n        lambda x: create_binary_label(x, ['motivational'])\n    )\nelse:\n    df['motivational_bin'] = 0\n\nif 'humour' in df.columns or 'humor' in df.columns:\n    humor_col = 'humour' if 'humour' in df.columns else 'humor'\n    df['humor_bin'] = df[humor_col].apply(\n        lambda x: create_binary_label(x, ['funny', 'very_funny', 'hilarious'])\n    )\nelse:\n    df['humor_bin'] = 0\n\nif 'sarcastic' in df.columns or 'sarcasm' in df.columns:\n    sarcasm_col = 'sarcastic' if 'sarcastic' in df.columns else 'sarcasm'\n    df['sarcasm_bin'] = df[sarcasm_col].apply(\n        lambda x: create_binary_label(x, ['general', 'twisted_meaning', 'very_twisted'])\n    )\nelse:\n    df['sarcasm_bin'] = 0\n\n# Stratified split\nstratify_columns = ['offensive_bin', 'motivational_bin', 'humor_bin', 'sarcasm_bin']\ny_stratify = df[stratify_columns].values\n\nmsss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=VALIDATION_SPLIT_RATIO, random_state=42)\ntrain_idx, val_idx = next(msss.split(df, y_stratify))\n\ntrain_df = df.iloc[train_idx].reset_index(drop=True)\nval_df = df.iloc[val_idx].reset_index(drop=True)\n\nprint(f\"\\nâœ“ Stratified split complete:\")\nprint(f\"  Training: {len(train_df)} samples\")\nprint(f\"  Validation: {len(val_df)} samples\")\n\n# Calculate label priors\nlabel_priors = {\n    'offensive_pos_rate': float(train_df['offensive_bin'].sum() / len(train_df)),\n    'motivational_pos_rate': float(train_df['motivational_bin'].sum() / len(train_df)),\n    'humor_pos_rate': float(train_df['humor_bin'].sum() / len(train_df)),\n    'sarcasm_pos_rate': float(train_df['sarcasm_bin'].sum() / len(train_df))\n}\n\npriors_path = os.path.join(OUTPUT_BASE_DIR, 'label_priors.json')\nwith open(priors_path, 'w') as f:\n    json.dump(label_priors, f, indent=2)\n\nprint(f\"\\nâœ“ Label priors calculated:\")\nfor key, val in label_priors.items():\n    print(f\"  {key}: {val:.4f}\")\n\n# Copy images\ndef copy_images(df_subset, dest_dir, source_dir, image_col):\n    copied = 0\n    missing = 0\n    \n    for idx in tqdm(df_subset[image_col], desc=f\"Copying to {dest_dir}\"):\n        filename = str(idx)\n        if not any(filename.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif']):\n            for ext in ['.jpg', '.jpeg', '.png']:\n                test_path = os.path.join(source_dir, f\"{filename}{ext}\")\n                if os.path.exists(test_path):\n                    filename = f\"{filename}{ext}\"\n                    break\n            else:\n                filename = f\"{filename}.jpg\"\n        \n        source_path = os.path.join(source_dir, filename)\n        if os.path.exists(source_path):\n            shutil.copy(source_path, os.path.join(dest_dir, filename))\n            copied += 1\n        else:\n            missing += 1\n    \n    return copied, missing\n\nprint(\"\\nCopying images...\")\ncopied_val, missing_val = copy_images(val_df, NEW_VAL_DIR, ORIGINAL_TRAIN_IMG_DIR, IMAGE_FILENAME_COLUMN)\ncopied_train, missing_train = copy_images(train_df, NEW_TRAIN_DIR, ORIGINAL_TRAIN_IMG_DIR, IMAGE_FILENAME_COLUMN)\n\nprint(f\"âœ“ Validation: {copied_val} copied, {missing_val} missing\")\nprint(f\"âœ“ Training: {copied_train} copied, {missing_train} missing\")\n\n# Save CSVs\ntrain_csv_path = os.path.join(OUTPUT_BASE_DIR, 'train_split.csv')\nval_csv_path = os.path.join(OUTPUT_BASE_DIR, 'validation_split.csv')\n\ntrain_df.to_csv(train_csv_path, index=False)\nval_df.to_csv(val_csv_path, index=False)\n\nprint(f\"\\nâœ“ Saved train CSV: {train_csv_path}\")\nprint(f\"âœ“ Saved validation CSV: {val_csv_path}\")\nprint(\"\\nâœ… DATA PREPARATION COMPLETE\\n\")\n\n\n# ==================== PART 2: CONFIGURATION ====================\nprint(\"=\" * 80)\nprint(\"PART 2: CONFIGURATION (BALANCED STRATEGY)\")\nprint(\"=\" * 80)\n\nCONFIG_YAML = \"\"\"\nTEXT_MODEL: \"google/muril-base-cased\"\nIMAGE_MODEL: \"openai/clip-vit-base-patch32\"\nTEXT_DIM: 768\nIMAGE_DIM: 768\nFUSION_DIM: 512\nFUSION_OUT_DIM: 512\n\nMAX_LEN: 128\nIMG_SIZE: 224\nBATCH_SIZE: 16\nGRADIENT_ACCUMULATION_STEPS: 2\n\n# --- UPDATED LEARNING RATES ---\nLR_HEADS: 0.0003\nLR_BACKBONE: 0.00001\nWEIGHT_DECAY: 0.01\n\nEPOCHS: 20\nFINE_TUNE_EPOCHS: 5\nSEED: 42\nDEVICE: \"cuda\"\nCHECKPOINT_PATH: \"/kaggle/working/checkpoints\"\n\nNUM_SENTIMENT_CLASSES: 5\nNUM_EMOTION_CLASSES: 4\n\nUSE_ORDINAL_REGRESSION: true\nORDINAL_LINK: \"logit\"\n\n# --- UPDATED LOSS WEIGHTS ---\nLOSS_WEIGHTS:\n  sentiment: 1.0\n  emotion: 4.0\n  intensity: 0.1\n\n# --- UPDATED ASL SETTINGS ---\nASL_GAMMA_NEG: 4.0\nASL_GAMMA_POS: 0.25\nASL_CLIP: 0.04\nASL_PRIOR_TAU: 1.2\n\nEMOTION_LABELS: [\"humor\", \"sarcasm\", \"offensive\", \"motivational\"]\n\n# --- THRESHOLDS & TUNING ---\nEMO_THRESHOLDS: [0.5, 0.5, 0.25, 0.25]\nTUNE_EMOTION_THRESHOLDS: true\n\nPOOLING: \"mean\"\nUSE_AMP: false\nGRADIENT_CLIP: 1.0\nSCHEDULER: \"cosine\"\nUNFREEZE_BACKBONE_EPOCH: 2\nUNFREEZE_LAYERS: 3\n\n# --- SAMPLING STRATEGY ---\nMOTIVATIONAL_OVERSAMPLE_FACTOR: 10.0\nMOTIVATIONAL_BATCH_RATIO: 0.30\n\nCROSS_ATTN_HEADS: 8\nCROSS_ATTN_DROPOUT: 0.1\n\nSENTIMENT_MAP_REV:\n  0: \"very_positive\"\n  1: \"positive\"\n  2: \"neutral\"\n  3: \"negative\"\n  4: \"very_negative\"\n\"\"\"\n\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\ncfg = yaml.safe_load(CONFIG_YAML)\nset_seed(cfg['SEED'])\n\n# Load priors\npriors_path = '/kaggle/working/label_priors.json'\nif os.path.exists(priors_path):\n    with open(priors_path, 'r') as f:\n        priors = json.load(f)\n\n    cfg['EMO_PRIORS'] = [\n        priors['humor_pos_rate'],\n        priors['sarcasm_pos_rate'],\n        priors['offensive_pos_rate'],\n        priors['motivational_pos_rate']\n    ]\nelse:\n    print(\"Warning: Label priors not found. Using defaults.\")\n    cfg['EMO_PRIORS'] = [0.1, 0.1, 0.1, 0.1]\n\ndevice = torch.device(cfg['DEVICE'] if torch.cuda.is_available() else 'cpu')\n\nprint(f\"\\nâœ“ Configuration loaded:\")\nprint(f\"  Device: {device}\")\nprint(f\"  Motivational Batch Ratio: {cfg['MOTIVATIONAL_BATCH_RATIO']}\")\nprint(f\"  Fine-tune Epochs: {cfg['FINE_TUNE_EPOCHS']}\")\n\n\n# ==================== PART 3: MODEL COMPONENTS ====================\nprint(\"=\" * 80)\nprint(\"MODEL COMPONENTS\")\nprint(\"=\" * 80)\n\nclass OrdinalRegressionHead(nn.Module):\n    def __init__(self, input_dim, num_classes):\n        super().__init__()\n        self.num_classes = num_classes\n        self.num_thresholds = num_classes - 1\n        \n        self.projection = nn.Sequential(\n            nn.Linear(input_dim, 256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, 1)\n        )\n        \n        initial_thresholds = torch.linspace(-2, 2, self.num_thresholds)\n        self.thresholds = nn.Parameter(initial_thresholds)\n    \n    def forward(self, x):\n        score = self.projection(x).squeeze(-1)\n        ordered_thresholds = torch.cumsum(F.softplus(self.thresholds), dim=0)\n        cumulative_logits = ordered_thresholds.unsqueeze(0) - score.unsqueeze(1)\n        cumulative_probs = torch.sigmoid(cumulative_logits)\n        \n        batch_size = cumulative_probs.size(0)\n        class_probs = torch.zeros(batch_size, self.num_classes, device=x.device)\n        \n        class_probs[:, 0] = cumulative_probs[:, 0]\n        for k in range(1, self.num_thresholds):\n            class_probs[:, k] = cumulative_probs[:, k] - cumulative_probs[:, k-1]\n        class_probs[:, -1] = 1.0 - cumulative_probs[:, -1]\n        class_probs = torch.clamp(class_probs, min=1e-7, max=1.0)\n        \n        return {'cumulative_logits': cumulative_logits, 'class_probs': class_probs}\n\nclass HybridSentimentHead(nn.Module):\n    def __init__(self, input_dim, num_classes):\n        super().__init__()\n        self.num_classes = num_classes\n        self.ordinal_head = OrdinalRegressionHead(input_dim, num_classes)\n        self.ce_head = nn.Sequential(\n            nn.Linear(input_dim, 256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, num_classes)\n        )\n    \n    def forward(self, x):\n        ordinal_outputs = self.ordinal_head(x)\n        ce_logits = self.ce_head(x)\n        return {\n            'cumulative_logits': ordinal_outputs['cumulative_logits'],\n            'class_probs': ordinal_outputs['class_probs'],\n            'ce_logits': ce_logits\n        }\n\nclass CrossAttentionFusion(nn.Module):\n    def __init__(self, dim, num_heads=8, dropout=0.1):\n        super().__init__()\n        self.text_to_image_attn = nn.MultiheadAttention(dim, num_heads, dropout, batch_first=True)\n        self.image_to_text_attn = nn.MultiheadAttention(dim, num_heads, dropout, batch_first=True)\n        self.text_norm = nn.LayerNorm(dim)\n        self.image_norm = nn.LayerNorm(dim)\n        self.text_ffn = nn.Sequential(\n            nn.Linear(dim, dim * 4), nn.GELU(), nn.Dropout(dropout),\n            nn.Linear(dim * 4, dim), nn.Dropout(dropout)\n        )\n        self.image_ffn = nn.Sequential(\n            nn.Linear(dim, dim * 4), nn.GELU(), nn.Dropout(dropout),\n            nn.Linear(dim * 4, dim), nn.Dropout(dropout)\n        )\n        self.ffn_norm_text = nn.LayerNorm(dim)\n        self.ffn_norm_image = nn.LayerNorm(dim)\n    \n    def forward(self, text_emb, image_emb):\n        text_seq = text_emb.unsqueeze(1)\n        image_seq = image_emb.unsqueeze(1)\n        \n        text_attended, _ = self.text_to_image_attn(text_seq, image_seq, image_seq)\n        text_out = self.text_norm(text_emb + text_attended.squeeze(1))\n        \n        image_attended, _ = self.image_to_text_attn(image_seq, text_seq, text_seq)\n        image_out = self.image_norm(image_emb + image_attended.squeeze(1))\n        \n        text_final = self.ffn_norm_text(text_out + self.text_ffn(text_out))\n        image_final = self.ffn_norm_image(image_out + self.image_ffn(image_out))\n        \n        return text_final, image_final\n\nclass EnhancedFusionModel(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg = cfg\n        \n        self.text_model = AutoModel.from_pretrained(cfg['TEXT_MODEL'])\n        clip_model = CLIPModel.from_pretrained(cfg['IMAGE_MODEL'])\n        self.image_model = clip_model.vision_model\n        \n        self._freeze_encoders()\n        \n        self.text_proj = nn.Linear(cfg['TEXT_DIM'], cfg['FUSION_DIM'])\n        self.image_proj = nn.Linear(cfg['IMAGE_DIM'], cfg['FUSION_DIM'])\n        \n        self.cross_attention = CrossAttentionFusion(\n            dim=cfg['FUSION_DIM'],\n            num_heads=cfg['CROSS_ATTN_HEADS'],\n            dropout=cfg['CROSS_ATTN_DROPOUT']\n        )\n        \n        fusion_input_dim = cfg['FUSION_DIM'] * 2\n        self.fusion_norm = nn.LayerNorm(fusion_input_dim)\n        self.fusion_mlp = nn.Sequential(\n            nn.Linear(fusion_input_dim, 512), nn.GELU(), nn.Dropout(0.2),\n            nn.Linear(512, cfg['FUSION_OUT_DIM']), nn.LayerNorm(cfg['FUSION_OUT_DIM'])\n        )\n        \n        if cfg.get('USE_HYBRID_SENTIMENT_LOSS', False):\n            self.sentiment_head = HybridSentimentHead(cfg['FUSION_OUT_DIM'], cfg['NUM_SENTIMENT_CLASSES'])\n        else:\n            self.sentiment_head = OrdinalRegressionHead(cfg['FUSION_OUT_DIM'], cfg['NUM_SENTIMENT_CLASSES'])\n        \n        self.emotion_head = nn.Sequential(\n            nn.Linear(cfg['FUSION_OUT_DIM'], 256), nn.ReLU(), nn.Dropout(0.2),\n            nn.Linear(256, cfg['NUM_EMOTION_CLASSES'])\n        )\n        self.intensity_head = nn.Sequential(\n            nn.Linear(cfg['FUSION_OUT_DIM'], 128), nn.ReLU(), nn.Dropout(0.2),\n            nn.Linear(128, 1)\n        )\n    \n    def _freeze_encoders(self):\n        for param in self.text_model.parameters():\n            param.requires_grad = False\n        for param in self.image_model.parameters():\n            param.requires_grad = False\n    \n    def unfreeze_backbone(self, layers_to_unfreeze=3):\n        if hasattr(self.text_model, 'encoder') and hasattr(self.text_model.encoder, 'layer'):\n            for layer in list(self.text_model.encoder.layer[-layers_to_unfreeze:]):\n                for param in layer.parameters():\n                    param.requires_grad = True\n        \n        if hasattr(self.image_model, 'encoder') and hasattr(self.image_model.encoder, 'layers'):\n            for layer in list(self.image_model.encoder.layers[-layers_to_unfreeze:]):\n                for param in layer.parameters():\n                    param.requires_grad = True\n    \n    def pool_text(self, model_output, attention_mask):\n        last_hidden = model_output.last_hidden_state\n        if self.cfg['POOLING'] == 'cls':\n            return last_hidden[:, 0]\n        mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden.size()).float()\n        sum_embeddings = torch.sum(last_hidden * mask_expanded, 1)\n        sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n        return sum_embeddings / sum_mask\n    \n    def forward(self, input_ids, attention_mask, image):\n        text_output = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n        text_emb = self.pool_text(text_output, attention_mask)\n        \n        image_output = self.image_model(pixel_values=image)\n        image_emb = image_output.pooler_output\n        \n        text_proj = self.text_proj(text_emb)\n        image_proj = self.image_proj(image_emb)\n        \n        text_cross, image_cross = self.cross_attention(text_proj, image_proj)\n        \n        fused = torch.cat([text_cross, image_cross], dim=1)\n        fused = self.fusion_norm(fused)\n        fused = self.fusion_mlp(fused)\n        \n        sentiment_outputs = self.sentiment_head(fused)\n        emotion_logits = self.emotion_head(fused)\n        intensity = self.intensity_head(fused).squeeze(-1)\n        \n        return {\n            'sentiment': sentiment_outputs,\n            'emotion_logits': emotion_logits,\n            'intensity': intensity\n        }\n\nprint(\"âœ“ Model components defined\")\n\n\n# ==================== PART 4: DATASET ====================\nprint(\"=\" * 80)\nprint(\"DATASET\")\nprint(\"=\" * 80)\n\nclass MemeDataset(Dataset):\n    def __init__(self, df, tokenizer, image_transform, image_dir, cfg):\n        self.df = df.reset_index(drop=True)\n        self.tokenizer = tokenizer\n        self.image_transform = image_transform\n        self.image_dir = image_dir\n        self.cfg = cfg\n        self._detect_columns()\n    \n    def _detect_columns(self):\n        cols = self.df.columns.tolist()\n        self.image_col = next((c for c in ['image_name', 'image', 'img_name', 'filename', 'Unnamed: 0'] if c in cols), cols[0])\n        self.text_col = next((c for c in ['text', 'ocr_text', 'caption', 'OCR_extracted_text'] if c in cols), None)\n        self.sentiment_col = next((c for c in ['sentiment', 'overall_sentiment', 'overall'] if c in cols), None)\n        \n        self.sentiment_map = {'very_positive': 0, 'positive': 1, 'neutral': 2, 'negative': 3, 'very_negative': 4}\n        self.humor_map = {'not_funny': 0, 'funny': 1, 'very_funny': 1, 'hilarious': 1}\n        self.sarcasm_map = {'not_sarcastic': 0, 'general': 1, 'twisted_meaning': 1, 'very_twisted': 1}\n        self.offensive_map = {'not_offensive': 0, 'slight': 1, 'very_offensive': 1, 'hateful_offensive': 1}\n        self.motivational_map = {'not_motivational': 0, 'motivational': 1}\n    \n    def _map_label(self, value, mapping, default=0):\n        if pd.isna(value):\n            return default\n        if isinstance(value, str):\n            return mapping.get(value.lower().strip(), default)\n        return int(value)\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        \n        image_name = str(row[self.image_col])\n        if not any(image_name.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png']):\n            image_name = f\"{image_name}.jpg\"\n        image_path = os.path.join(self.image_dir, image_name)\n        \n        try:\n            image = Image.open(image_path).convert('RGB')\n            image = self.image_transform(image)\n        except:\n            image = torch.zeros(3, self.cfg['IMG_SIZE'], self.cfg['IMG_SIZE'])\n        \n        text = str(row.get(self.text_col, '')) if self.text_col else 'No text'\n        encoding = self.tokenizer(text, max_length=self.cfg['MAX_LEN'], padding='max_length', truncation=True, return_tensors='pt')\n        \n        sentiment_val = row.get(self.sentiment_col, 'neutral') if self.sentiment_col else 'neutral'\n        sentiment_label = self._map_label(sentiment_val, self.sentiment_map, default=2)\n        \n        emotion_labels = torch.tensor([\n            float(self._map_label(row.get('humour', row.get('humor', 0)), self.humor_map, 0)),\n            float(self._map_label(row.get('sarcastic', row.get('sarcasm', 0)), self.sarcasm_map, 0)),\n            float(self._map_label(row.get('offensive', 0), self.offensive_map, 0)),\n            float(self._map_label(row.get('motivational', 0), self.motivational_map, 0))\n        ], dtype=torch.float)\n        \n        is_extreme = sentiment_label in [0, 4]\n        \n        return {\n            'input_ids': encoding['input_ids'].squeeze(0),\n            'attention_mask': encoding['attention_mask'].squeeze(0),\n            'image': image,\n            'sentiment_label': torch.tensor(sentiment_label, dtype=torch.long),\n            'emotion_labels': emotion_labels,\n            'intensity': torch.tensor(0.5, dtype=torch.float),\n            'motivational_flag': emotion_labels[3],\n            'extreme_sentiment_flag': torch.tensor(float(is_extreme))\n        }\n\nprint(\"âœ“ Dataset class defined\")\n\n\n# ==================== PART 5: LOSS FUNCTIONS & METRICS ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"LOSS FUNCTIONS & METRICS (F2 OPTIMIZATION)\")\nprint(\"=\" * 80)\n\nclass EnhancedAsymmetricLoss(nn.Module):\n    def __init__(self, gamma_neg=4.0, gamma_pos=0.25, clip=0.04, priors=None, prior_tau=1.2, eps=1e-8):\n        super().__init__()\n        self.gamma_neg = gamma_neg\n        self.gamma_pos = gamma_pos\n        self.clip = clip\n        self.eps = eps\n        self.priors = priors\n        self.prior_tau = prior_tau\n\n    def forward(self, logits, targets):\n        if self.priors is not None:\n            priors_tensor = torch.tensor(self.priors, device=logits.device, dtype=logits.dtype)\n            adjustment = self.prior_tau * torch.log(priors_tensor.clamp(min=self.eps))\n            logits = logits - adjustment\n\n        xs_pos = torch.sigmoid(logits)\n        xs_neg = 1 - xs_pos\n\n        if self.clip is not None and self.clip > 0:\n            xs_neg = (xs_neg + self.clip).clamp(max=1)\n\n        los_pos = targets * torch.log(xs_pos.clamp(min=self.eps))\n        los_neg = (1 - targets) * torch.log(xs_neg.clamp(min=self.eps))\n\n        if self.gamma_neg > 0 or self.gamma_pos > 0:\n            pt0 = xs_pos * targets\n            pt1 = xs_neg * (1 - targets)\n            pt = pt0 + pt1\n            one_sided_gamma = self.gamma_pos * targets + self.gamma_neg * (1 - targets)\n            one_sided_w = torch.pow(1 - pt, one_sided_gamma)\n            loss = -one_sided_w * (los_pos + los_neg)\n        else:\n            loss = -(los_pos + los_neg)\n\n        # --- UPDATED: MANUAL WEIGHTING FOR MOTIVATIONAL ---\n        if logits.size(1) == 4:\n            # [Humor, Sarcasm, Offensive, Motivational]\n            # Boosting Motivational by 1.7x\n            manual_weights = torch.tensor([1.0, 1.0, 1.0, 1.7], device=logits.device, dtype=logits.dtype)\n            loss = loss * manual_weights\n\n        return loss.mean()\n\ndef ordinal_regression_loss(cumulative_logits, labels):\n    batch_size = labels.size(0)\n    num_thresholds = cumulative_logits.size(1)\n    target_cumulative = torch.zeros_like(cumulative_logits)\n    for i in range(batch_size):\n        y = int(labels[i].item())\n        if y < num_thresholds:\n            target_cumulative[i, y:] = 1.0\n    return F.binary_cross_entropy_with_logits(cumulative_logits, target_cumulative, reduction='mean')\n\ndef combined_loss(outputs, batch, cfg, emotion_loss_fn):\n    loss_sent = ordinal_regression_loss(outputs['sentiment']['cumulative_logits'], batch['sentiment_label'])\n    loss_emotion = emotion_loss_fn(outputs['emotion_logits'], batch['emotion_labels'])\n    loss_intensity = F.smooth_l1_loss(outputs['intensity'], batch['intensity'])\n    \n    total_loss = (\n        cfg['LOSS_WEIGHTS']['sentiment'] * loss_sent +\n        cfg['LOSS_WEIGHTS']['emotion'] * loss_emotion +\n        cfg['LOSS_WEIGHTS']['intensity'] * loss_intensity\n    )\n    return total_loss, loss_sent, loss_emotion, loss_intensity\n\ndef tune_emotion_thresholds(emotion_logits, emotion_labels, num_thresholds=100):\n    emotion_probs = torch.sigmoid(emotion_logits).cpu().numpy()\n    emotion_true = emotion_labels.cpu().numpy()\n    \n    num_emotions = emotion_probs.shape[1]\n    optimal_thresholds = []\n    \n    for emo_idx in range(num_emotions):\n        best_score = 0.0\n        best_threshold = 0.5\n        \n        y_true = emotion_true[:, emo_idx]\n        y_prob = emotion_probs[:, emo_idx]\n        \n        # --- UPDATED: Targeted F2 Optimization for Motivational (Idx 3) ---\n        if emo_idx == 3:\n            # Specific Band: 0.15 to 0.60\n            search_range = np.linspace(0.15, 0.60, num_thresholds)\n        else:\n            search_range = np.linspace(0.1, 0.9, num_thresholds)\n        \n        for threshold in search_range:\n            y_pred = (y_prob >= threshold).astype(float)\n            \n            if emo_idx == 3:\n                # OPTIMIZE F2 (Recall-Weighted) for Motivational\n                score = fbeta_score(y_true, y_pred, beta=2.0, zero_division=0)\n            else:\n                score = f1_score(y_true, y_pred, zero_division=0)\n            \n            if score > best_score:\n                best_score = score\n                best_threshold = threshold\n        \n        optimal_thresholds.append(best_threshold)\n        print(f\"  Emotion {emo_idx}: threshold={best_threshold:.3f}, Score={best_score:.4f}\")\n    \n    return optimal_thresholds\n\ndef compute_metrics(sentiment_outputs, sentiment_labels, emotion_logits, emotion_labels, thresholds):\n    # Sentiment\n    class_probs = sentiment_outputs['class_probs']\n    y_pred = torch.argmax(class_probs, dim=1).cpu().numpy()\n    y_true = sentiment_labels.cpu().numpy()\n    sent_acc = accuracy_score(y_true, y_pred)\n    _, _, sent_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)\n    sent_mae = mean_absolute_error(y_true, y_pred)\n    sent_1off = np.mean(np.abs(y_true - y_pred) <= 1)\n\n    # NEW: Task A Style Metrics (Collapse 5 classes -> 3 classes)\n    task_a_map = {0: 0, 1: 0, 2: 1, 3: 2, 4: 2}\n    y_true_3class = np.array([task_a_map[val] for val in y_true])\n    y_pred_3class = np.array([task_a_map[val] for val in y_pred])\n    sent_f1_taskA_weighted = f1_score(y_true_3class, y_pred_3class, average='weighted', zero_division=0)\n\n    # Emotions\n    emo_probs = torch.sigmoid(emotion_logits).cpu().numpy()\n    emo_true = emotion_labels.cpu().numpy()\n    thresholds = np.array(thresholds)\n    emo_pred = (emo_probs >= thresholds).astype(float)\n    \n    _, _, emo_f1, _ = precision_recall_fscore_support(emo_true, emo_pred, average='samples', zero_division=0)\n    \n    per_emotion_f1 = []\n    for i in range(emo_true.shape[1]):\n        f1 = f1_score(emo_true[:, i], emo_pred[:, i], zero_division=0)\n        per_emotion_f1.append(f1)\n\n    return {\n        'sentiment_accuracy': sent_acc,\n        'sentiment_f1': sent_f1,\n        'sentiment_taskA_weighted_f1': sent_f1_taskA_weighted,\n        'sentiment_mae': sent_mae,\n        'sentiment_1off_accuracy': sent_1off,\n        'emotion_f1': emo_f1,\n        'per_emotion_f1': per_emotion_f1\n    }\n\nprint(\"âœ“ Loss functions and metrics defined\")\n\n\n# ==================== PART 6: TRAINER (UPDATED) ====================\nprint(\"=\" * 80)\nprint(\"TRAINER (TWO-STAGE TRAINING + BALANCED SAMPLER + FINAL SUMMARY)\")\nprint(\"=\" * 80)\n\nclass Trainer:\n    def __init__(self, model, cfg, train_loader, val_loader, device, emotion_loss_fn):\n        self.model = model\n        self.cfg = cfg\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.device = device\n        self.emotion_loss_fn = emotion_loss_fn\n\n        self.optimizer = self.make_optimizer()\n        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=cfg['EPOCHS'])\n        self.scaler = GradScaler() if cfg['USE_AMP'] else None\n        self.best_metric = -float('inf')\n        self.optimal_thresholds = cfg['EMO_THRESHOLDS'].copy()\n        \n        # Tracking best epoch details\n        self.best_epoch_metrics = None\n        self.best_epoch_num = -1\n\n        # Early Stopping\n        self.patience = 3\n        self.counter = 0\n\n    def make_optimizer(self):\n        head_params = []\n        backbone_params = []\n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                if 'text_model' in name or 'image_model' in name:\n                    backbone_params.append(param)\n                else:\n                    head_params.append(param)\n        param_groups = [{'params': head_params, 'lr': self.cfg['LR_HEADS']}]\n        if backbone_params:\n            param_groups.append({'params': backbone_params, 'lr': self.cfg['LR_BACKBONE']})\n        return torch.optim.AdamW(param_groups, weight_decay=self.cfg['WEIGHT_DECAY'])\n\n    def train_epoch(self, epoch, loader, desc_suffix=\"\"):\n        self.model.train()\n        total_loss = 0.0\n        valid_batches = 0\n\n        pbar = tqdm(loader, desc=f\"Epoch {epoch+1} {desc_suffix}\")\n        self.optimizer.zero_grad()\n\n        for batch_idx, batch in enumerate(pbar):\n            batch_device = {k: v.to(self.device) for k, v in batch.items()\n                           if k not in ['motivational_flag', 'extreme_sentiment_flag']}\n\n            if self.cfg['USE_AMP']:\n                with autocast():\n                    outputs = self.model(batch_device['input_ids'], batch_device['attention_mask'], batch_device['image'])\n                    loss, _, _, _ = combined_loss(outputs, batch_device, self.cfg, self.emotion_loss_fn)\n                    loss = loss / self.cfg['GRADIENT_ACCUMULATION_STEPS']\n\n                if torch.isnan(loss) or torch.isinf(loss):\n                    continue\n\n                self.scaler.scale(loss).backward()\n\n                if (batch_idx + 1) % self.cfg['GRADIENT_ACCUMULATION_STEPS'] == 0:\n                    self.scaler.unscale_(self.optimizer)\n                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.cfg['GRADIENT_CLIP'])\n                    self.scaler.step(self.optimizer)\n                    self.scaler.update()\n                    self.optimizer.zero_grad()\n            else:\n                outputs = self.model(batch_device['input_ids'], batch_device['attention_mask'], batch_device['image'])\n                loss, _, _, _ = combined_loss(outputs, batch_device, self.cfg, self.emotion_loss_fn)\n                loss = loss / self.cfg['GRADIENT_ACCUMULATION_STEPS']\n\n                if torch.isnan(loss) or torch.isinf(loss):\n                    continue\n\n                loss.backward()\n\n                if (batch_idx + 1) % self.cfg['GRADIENT_ACCUMULATION_STEPS'] == 0:\n                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.cfg['GRADIENT_CLIP'])\n                    self.optimizer.step()\n                    self.optimizer.zero_grad()\n\n            loss_val = loss.item() * self.cfg['GRADIENT_ACCUMULATION_STEPS']\n            total_loss += loss_val\n            valid_batches += 1\n            pbar.set_postfix({'loss': f\"{loss_val:.4f}\"})\n\n        return total_loss / max(valid_batches, 1)\n\n    def validate(self, epoch):\n        self.model.eval()\n        total_loss = 0.0\n        all_sentiment_labels = []\n        all_sentiment_outputs = []\n        all_emotion_labels = []\n        all_emotion_logits = []\n\n        with torch.no_grad():\n            for batch in tqdm(self.val_loader, desc=f\"Epoch {epoch+1} [Val]\"):\n                batch_device = {k: v.to(self.device) for k, v in batch.items()\n                               if k not in ['motivational_flag', 'extreme_sentiment_flag']}\n\n                outputs = self.model(batch_device['input_ids'], batch_device['attention_mask'], batch_device['image'])\n                loss, _, _, _ = combined_loss(outputs, batch_device, self.cfg, self.emotion_loss_fn)\n                total_loss += loss.item()\n\n                all_sentiment_labels.append(batch_device['sentiment_label'].cpu())\n                all_sentiment_outputs.append({\n                    'cumulative_logits': outputs['sentiment']['cumulative_logits'].cpu(),\n                    'class_probs': outputs['sentiment']['class_probs'].cpu()\n                })\n                all_emotion_labels.append(batch_device['emotion_labels'].cpu())\n                all_emotion_logits.append(outputs['emotion_logits'].cpu())\n\n        all_sentiment_labels = torch.cat(all_sentiment_labels)\n        combined_sentiment = {\n            'cumulative_logits': torch.cat([o['cumulative_logits'] for o in all_sentiment_outputs]),\n            'class_probs': torch.cat([o['class_probs'] for o in all_sentiment_outputs])\n        }\n        all_emotion_labels = torch.cat(all_emotion_labels)\n        all_emotion_logits = torch.cat(all_emotion_logits)\n\n        if self.cfg.get('TUNE_EMOTION_THRESHOLDS', False):\n            print(\"\\nðŸ”§ Tuning emotion thresholds...\")\n            self.optimal_thresholds = tune_emotion_thresholds(all_emotion_logits, all_emotion_labels)\n\n        metrics = compute_metrics(combined_sentiment, all_sentiment_labels, all_emotion_logits,\n                                all_emotion_labels, self.optimal_thresholds)\n        avg_loss = total_loss / len(self.val_loader)\n\n        # UPDATED PRINT FORMAT\n        print(f\"\\nValidation Results (Epoch {epoch+1}): \"\n              f\"Loss: {avg_loss:.4f} \"\n              f\"Sentiment Accuracy: {metrics['sentiment_accuracy']:.4f} \"\n              f\"Sentiment F1 (5-class): {metrics['sentiment_f1']:.4f} \"\n              f\"Sentiment F1 (Task A Weighted): {metrics['sentiment_taskA_weighted_f1']:.4f} \"\n              f\"Sentiment MAE: {metrics['sentiment_mae']:.4f} \"\n              f\"Emotion F1 (avg): {metrics['emotion_f1']:.4f} \"\n              f\"humor F1: {metrics['per_emotion_f1'][0]:.4f} \"\n              f\"sarcasm F1: {metrics['per_emotion_f1'][1]:.4f} \"\n              f\"offensive F1: {metrics['per_emotion_f1'][2]:.4f} \"\n              f\"motivational F1: {metrics['per_emotion_f1'][3]:.4f} \"\n              f\"Thresholds: {[f'{t:.3f}' for t in self.optimal_thresholds]}\")\n\n        return {**metrics, 'val_loss': avg_loss}\n    \n    def print_best_results(self):\n        \"\"\"Prints the stored best results at the end of training\"\"\"\n        if self.best_epoch_metrics is None:\n            print(\"\\nâš ï¸ No best model was saved.\")\n            return\n            \n        m = self.best_epoch_metrics\n        print(f\"\\n{'='*80}\")\n        print(f\"ðŸ† BEST EPOCH RESULTS (Epoch {self.best_epoch_num})\")\n        print(f\"{'='*80}\")\n        print(f\"Validation Results (Epoch {self.best_epoch_num}): \"\n              f\"Loss: {m['val_loss']:.4f} \"\n              f\"Sentiment Accuracy: {m['sentiment_accuracy']:.4f} \"\n              f\"Sentiment F1 (5-class): {m['sentiment_f1']:.4f} \"\n              f\"Sentiment F1 (Task A Weighted): {m.get('sentiment_taskA_weighted_f1', 0.0):.4f} \"\n              f\"Sentiment MAE: {m['sentiment_mae']:.4f} \"\n              f\"Emotion F1 (avg): {m['emotion_f1']:.4f} \"\n              f\"humor F1: {m['per_emotion_f1'][0]:.4f} \"\n              f\"sarcasm F1: {m['per_emotion_f1'][1]:.4f} \"\n              f\"offensive F1: {m['per_emotion_f1'][2]:.4f} \"\n              f\"motivational F1: {m['per_emotion_f1'][3]:.4f} \"\n              f\"Thresholds: {[f'{t:.3f}' for t in self.optimal_thresholds]}\")\n        print(f\"{'='*80}\\n\")\n\n    def fine_tune_motivational(self):\n        print(\"\\n\" + \"=\"*70)\n        print(\"STAGE 2: MOTIVATIONAL-ONLY FINE-TUNING\")\n        print(\"=\"*70)\n        \n        # 1. Load best checkpoint\n        checkpoint_path = os.path.join(self.cfg['CHECKPOINT_PATH'], 'best_model_enhanced.pt')\n        # FIX: weights_only=False\n        checkpoint = torch.load(checkpoint_path, map_location=self.device, weights_only=False)\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        \n        # 2. Freeze everything except emotion head\n        for param in self.model.parameters():\n            param.requires_grad = False\n        for param in self.model.emotion_head.parameters():\n            param.requires_grad = True\n            \n        # 3. Create Balanced Batch Sampler\n        print(\"Creating strict Balanced Batch Sampler...\")\n        balanced_sampler = BalancedBatchSampler(\n            self.train_loader.dataset, \n            self.cfg['BATCH_SIZE'], \n            pos_ratio=self.cfg['MOTIVATIONAL_BATCH_RATIO']\n        )\n        balanced_loader = DataLoader(\n            self.train_loader.dataset,\n            batch_sampler=balanced_sampler, # Use batch_sampler instead of sampler\n            num_workers=2,\n            pin_memory=True\n        )\n        \n        # 4. Train loop\n        self.optimizer = torch.optim.AdamW(\n            filter(lambda p: p.requires_grad, self.model.parameters()), \n            lr=1e-4, weight_decay=1e-3\n        )\n        \n        best_ft_metric = -float('inf')\n        \n        for epoch in range(self.cfg['FINE_TUNE_EPOCHS']):\n            real_epoch = self.cfg['EPOCHS'] + epoch + 1\n            loss = self.train_epoch(real_epoch, balanced_loader, desc_suffix=\"[Fine-Tune]\")\n            print(f\"Fine-tune Loss: {loss:.4f}\")\n            \n            metrics = self.validate(real_epoch)\n            \n            # Metric: Motivational F1 + Emotion Avg\n            current_metric = metrics['per_emotion_f1'][3] * 1.5 + metrics['emotion_f1']\n            \n            # Update BEST TRACKER if fine-tuning improved things\n            if current_metric > best_ft_metric:\n                best_ft_metric = current_metric\n                ft_path = os.path.join(self.cfg['CHECKPOINT_PATH'], 'best_model_finetuned.pt')\n                \n                # Update global best record for final printing\n                self.best_epoch_metrics = metrics\n                self.best_epoch_num = real_epoch\n                self.optimal_thresholds = self.optimal_thresholds # Ensure latest thresholds are saved\n                \n                torch.save({\n                    'model_state_dict': self.model.state_dict(),\n                    'config': self.cfg,\n                    'optimal_thresholds': self.optimal_thresholds\n                }, ft_path)\n                print(\"âœ“ Saved fine-tuned model\")\n\n    def fit(self):\n        print(f\"\\nSTARTING STAGE 1 TRAINING: {self.cfg['EPOCHS']} EPOCHS\")\n        \n        for epoch in range(self.cfg['EPOCHS']):\n            if epoch == self.cfg['UNFREEZE_BACKBONE_EPOCH']:\n                print(f\"ðŸ”“ UNFREEZING BACKBONE at epoch {epoch+1}\")\n                self.model.unfreeze_backbone(layers_to_unfreeze=self.cfg['UNFREEZE_LAYERS'])\n                self.optimizer = self.make_optimizer()\n                self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=self.cfg['EPOCHS'])\n\n            loss = self.train_epoch(epoch, self.train_loader)\n            print(f\"Train Loss: {loss:.4f}\")\n            val_metrics = self.validate(epoch)\n            \n            if self.scheduler:\n                self.scheduler.step()\n\n            composite = val_metrics['sentiment_f1'] + val_metrics['emotion_f1'] * 2.0\n            \n            if composite > self.best_metric:\n                self.best_metric = composite\n                self.counter = 0\n                \n                # Update global best record\n                self.best_epoch_metrics = val_metrics\n                self.best_epoch_num = epoch + 1\n                \n                os.makedirs(self.cfg['CHECKPOINT_PATH'], exist_ok=True)\n                checkpoint_path = os.path.join(self.cfg['CHECKPOINT_PATH'], 'best_model_enhanced.pt')\n                torch.save({\n                    'model_state_dict': self.model.state_dict(),\n                    'best_metric': self.best_metric,\n                    'config': self.cfg,\n                    'optimal_thresholds': self.optimal_thresholds\n                }, checkpoint_path)\n                print(f\"âœ“ Saved best model (New Record)\")\n            else:\n                self.counter += 1\n                if self.counter >= self.patience:\n                    print(f\"Early stopping at epoch {epoch+1}\")\n                    break\n        \n        # Trigger Fine-Tuning\n        self.fine_tune_motivational()\n        \n        # PRINT FINAL SUMMARY\n        self.print_best_results()\n        \n        return self.best_metric\n\nprint(\"âœ“ Trainer with Fine-Tuning defined\")\n\n\n# ==================== PART 7: DATA LOADING & SAMPLER ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 7: DATA LOADING & BALANCED SAMPLER\")\nprint(\"=\" * 80)\n\nclass BalancedBatchSampler(Sampler):\n    \"\"\"\n    Custom Sampler that yields batch indices ensuring a fixed ratio of \n    positive motivational samples per batch.\n    \"\"\"\n    def __init__(self, dataset, batch_size, pos_ratio=0.30):\n        self.dataset = dataset\n        self.batch_size = batch_size\n        self.n_pos = int(batch_size * pos_ratio)\n        self.n_neg = batch_size - self.n_pos\n        \n        # Separate indices\n        self.pos_indices = [i for i, x in enumerate(dataset) if int(x['motivational_flag'].item()) == 1]\n        self.neg_indices = [i for i, x in enumerate(dataset) if int(x['motivational_flag'].item()) == 0]\n        \n        self.n_batches = len(self.neg_indices) // self.n_neg # Based on majority class\n        \n    def __iter__(self):\n        for _ in range(self.n_batches):\n            batch = []\n            # Sample Positives (with replacement if needed to fill ratios)\n            batch.extend(np.random.choice(self.pos_indices, self.n_pos, replace=True))\n            # Sample Negatives\n            batch.extend(np.random.choice(self.neg_indices, self.n_neg, replace=False))\n            np.random.shuffle(batch)\n            yield batch\n\n    def __len__(self):\n        return self.n_batches\n\n# Initialize tokenizer and transforms\ntokenizer = AutoTokenizer.from_pretrained(cfg['TEXT_MODEL'])\ntrain_transform = transforms.Compose([\n    transforms.Resize((cfg['IMG_SIZE'], cfg['IMG_SIZE'])),\n    transforms.RandomHorizontalFlip(p=0.3),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n])\nval_transform = transforms.Compose([\n    transforms.Resize((cfg['IMG_SIZE'], cfg['IMG_SIZE'])),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n])\n\n# Create datasets\ntrain_dataset = MemeDataset(train_df, tokenizer, train_transform, NEW_TRAIN_DIR, cfg)\nval_dataset = MemeDataset(val_df, tokenizer, val_transform, NEW_VAL_DIR, cfg)\n\n# Standard weighted sampler for Stage 1\nsample_weights = []\nfor idx in range(len(train_dataset)):\n    item = train_dataset[idx]\n    weight = cfg['MOTIVATIONAL_OVERSAMPLE_FACTOR'] if item['motivational_flag'].item() == 1 else 1.0\n    sample_weights.append(weight)\nsampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=cfg['BATCH_SIZE'], sampler=sampler, num_workers=2, pin_memory=True, drop_last=True)\nval_loader = DataLoader(val_dataset, batch_size=cfg['BATCH_SIZE'], shuffle=False, num_workers=2, pin_memory=True)\n\nprint(f\"âœ“ Train batches: {len(train_loader)}\")\nprint(\"âœ“ Balanced Batch Sampler defined (will be used in Stage 2)\")\n\n\n# ==================== PART 8: MODEL INITIALIZATION & TRAINING ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 8: MODEL INITIALIZATION\")\nprint(\"=\" * 80)\n\nmodel = EnhancedFusionModel(cfg).to(device)\n\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f\"\\nModel Statistics:\")\nprint(f\"  Total parameters: {total_params:,}\")\nprint(f\"  Trainable parameters: {trainable_params:,}\")\n\n# Initialize enhanced emotion loss\nemotion_loss_fn = EnhancedAsymmetricLoss(\n    gamma_neg=cfg['ASL_GAMMA_NEG'],\n    gamma_pos=cfg['ASL_GAMMA_POS'],\n    clip=cfg['ASL_CLIP'],\n    priors=cfg['EMO_PRIORS'],\n    prior_tau=cfg['ASL_PRIOR_TAU']\n)\n\n# Initialize trainer\ntrainer = Trainer(model, cfg, train_loader, val_loader, device, emotion_loss_fn)\n\nprint(\"\\nâœ“ Trainer initialized\")\n\n# ==================== START TRAINING ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"STARTING TRAINING\")\nprint(\"=\" * 80)\n\nbest_metric = trainer.fit()\n\nprint(f\"\\n{'='*80}\")\nprint(f\"âœ… TRAINING COMPLETED!\")\nprint(f\"{'='*80}\")\nprint(f\"Best composite metric: {best_metric:.4f}\")\nprint(f\"Fine-tuned Model saved to: {cfg['CHECKPOINT_PATH']}/best_model_finetuned.pt\")\n\n\n# ==================== PART 9: INFERENCE ====================\nprint(\"=\" * 80)\nprint(\"INFERENCE PIPELINE\")\nprint(\"=\" * 80)\n\nclass MemeInference:\n    def __init__(self, checkpoint_path, device='cuda', thresholds=None):\n        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n        \n        print(f\"Loading checkpoint from {checkpoint_path}...\")\n        # FIX: Added weights_only=False\n        checkpoint = torch.load(checkpoint_path, map_location=self.device, weights_only=False)\n        self.cfg = checkpoint['config']\n        \n        if thresholds:\n            self.current_thresholds = thresholds\n        else:\n            self.current_thresholds = checkpoint.get('optimal_thresholds', self.cfg['EMO_THRESHOLDS'])\n            \n        self.model = EnhancedFusionModel(self.cfg).to(self.device)\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        self.model.eval()\n        \n        self.tokenizer = AutoTokenizer.from_pretrained(self.cfg['TEXT_MODEL'])\n        self.image_transform = transforms.Compose([\n            transforms.Resize((self.cfg['IMG_SIZE'], self.cfg['IMG_SIZE'])),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n        ])\n        print(f\"âœ“ Thresholds: {[f'{t:.3f}' for t in self.current_thresholds]}\")\n    \n    def preprocess_image(self, image_path):\n        try:\n            image = Image.open(image_path).convert('RGB')\n            return self.image_transform(image)\n        except Exception:\n            return torch.zeros(3, self.cfg['IMG_SIZE'], self.cfg['IMG_SIZE'])\n    \n    def preprocess_text(self, text):\n        if not text or text.strip() == '': text = 'No text'\n        encoding = self.tokenizer(text, max_length=self.cfg['MAX_LEN'], padding='max_length', truncation=True, return_tensors='pt')\n        return encoding['input_ids'], encoding['attention_mask']\n\n    @torch.no_grad()\n    def predict_single(self, image_path, text):\n        image_tensor = self.preprocess_image(image_path).unsqueeze(0).to(self.device)\n        input_ids, attention_mask = self.preprocess_text(text)\n        input_ids = input_ids.to(self.device)\n        attention_mask = attention_mask.to(self.device)\n        \n        outputs = self.model(input_ids, attention_mask, image_tensor)\n        probs = torch.sigmoid(outputs['emotion_logits'])[0]\n        thresholds_tensor = torch.tensor(self.current_thresholds, device=self.device)\n        preds = (probs >= thresholds_tensor).cpu().numpy()\n        probs = probs.cpu().numpy()\n        \n        sent_probs = outputs['sentiment']['class_probs'][0]\n        sent_idx = torch.argmax(sent_probs).item()\n        \n        emotions = {}\n        for k, label in enumerate(self.cfg['EMOTION_LABELS']):\n            emotions[label] = {\n                'present': bool(preds[k]),\n                'probability': float(probs[k]),\n                'threshold': float(self.current_thresholds[k])\n            }\n            \n        return {\n            'sentiment': self.cfg['SENTIMENT_MAP_REV'][sent_idx],\n            'sentiment_conf': float(sent_probs[sent_idx]),\n            'emotions': emotions,\n            'intensity': float(outputs['intensity'].item())\n        }\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-02T19:30:37.622269Z","iopub.execute_input":"2025-12-02T19:30:37.622627Z","iopub.status.idle":"2025-12-02T19:48:46.865904Z","shell.execute_reply.started":"2025-12-02T19:30:37.622600Z","shell.execute_reply":"2025-12-02T19:48:46.864982Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nINSTALLING DEPENDENCIES...\n================================================================================\n","output_type":"stream"},{"name":"stderr","text":"2025-12-02 19:30:47.883431: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764703847.904424     221 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764703847.910764     221 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"âœ“ All dependencies installed\n\n================================================================================\nPART 1: DATA PREPARATION\n================================================================================\n\nDownloading dataset...\nExtracting dataset...\nExtracting protected archive...\nâœ“ Extracted to: /kaggle/working/\n\nLoading CSV file...\nâœ“ Image column: Unnamed: 0\n\nâœ“ Stratified split complete:\n  Training: 5950 samples\n  Validation: 1050 samples\n\nâœ“ Label priors calculated:\n  offensive_pos_rate: 0.3909\n  motivational_pos_rate: 0.1187\n  humor_pos_rate: 0.8558\n  sarcasm_pos_rate: 0.7891\n\nCopying images...\n","output_type":"stream"},{"name":"stderr","text":"Copying to /kaggle/working/validation_images/: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1050/1050 [00:00<00:00, 6210.57it/s]\nCopying to /kaggle/working/new_train_images/: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5950/5950 [00:00<00:00, 7181.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ“ Validation: 1050 copied, 0 missing\nâœ“ Training: 5950 copied, 0 missing\n\nâœ“ Saved train CSV: /kaggle/working/train_split.csv\nâœ“ Saved validation CSV: /kaggle/working/validation_split.csv\n\nâœ… DATA PREPARATION COMPLETE\n\n================================================================================\nPART 2: CONFIGURATION (BALANCED STRATEGY)\n================================================================================\n\nâœ“ Configuration loaded:\n  Device: cuda\n  Motivational Batch Ratio: 0.3\n  Fine-tune Epochs: 5\n================================================================================\nMODEL COMPONENTS\n================================================================================\nâœ“ Model components defined\n================================================================================\nDATASET\n================================================================================\nâœ“ Dataset class defined\n\n================================================================================\nLOSS FUNCTIONS & METRICS (F2 OPTIMIZATION)\n================================================================================\nâœ“ Loss functions and metrics defined\n================================================================================\nTRAINER (TWO-STAGE TRAINING + BALANCED SAMPLER + FINAL SUMMARY)\n================================================================================\nâœ“ Trainer with Fine-Tuning defined\n\n================================================================================\nPART 7: DATA LOADING & BALANCED SAMPLER\n================================================================================\nâœ“ Train batches: 371\nâœ“ Balanced Batch Sampler defined (will be used in Stage 2)\n\n================================================================================\nPART 8: MODEL INITIALIZATION\n================================================================================\n\nModel Statistics:\n  Total parameters: 333,224,714\n  Trainable parameters: 8,212,490\n\nâœ“ Trainer initialized\n\n================================================================================\nSTARTING TRAINING\n================================================================================\n\nSTARTING STAGE 1 TRAINING: 20 EPOCHS\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1 :   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 1 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:37<00:00,  9.93it/s, loss=1.4961]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.5094\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 1 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nðŸ”§ Tuning emotion thresholds...\n  Emotion 0: threshold=0.100, Score=0.9220\n  Emotion 1: threshold=0.553, Score=0.8825\n  Emotion 2: threshold=0.270, Score=0.5776\n  Emotion 3: threshold=0.150, Score=0.3086\n\nValidation Results (Epoch 1): Loss: 1.4259 Sentiment Accuracy: 0.1600 Sentiment F1 (5-class): 0.0942 Sentiment F1 (Task A Weighted): 0.2576 Sentiment MAE: 1.3933 Emotion F1 (avg): 0.7385 humor F1: 0.9220 sarcasm F1: 0.8825 offensive F1: 0.5776 motivational F1: 0.2147 Thresholds: ['0.100', '0.553', '0.270', '0.150']\nâœ“ Saved best model (New Record)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 :   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 2 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:36<00:00, 10.28it/s, loss=1.5021]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.3807\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 2 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nðŸ”§ Tuning emotion thresholds...\n  Emotion 0: threshold=0.431, Score=0.9238\n  Emotion 1: threshold=0.100, Score=0.8824\n  Emotion 2: threshold=0.262, Score=0.5806\n  Emotion 3: threshold=0.164, Score=0.3542\n\nValidation Results (Epoch 2): Loss: 1.6062 Sentiment Accuracy: 0.1352 Sentiment F1 (5-class): 0.0917 Sentiment F1 (Task A Weighted): 0.2643 Sentiment MAE: 1.5181 Emotion F1 (avg): 0.7486 humor F1: 0.9238 sarcasm F1: 0.8824 offensive F1: 0.5806 motivational F1: 0.2526 Thresholds: ['0.431', '0.100', '0.262', '0.164']\nâœ“ Saved best model (New Record)\nðŸ”“ UNFREEZING BACKBONE at epoch 3\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 :   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 3 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.87it/s, loss=1.4194]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.2346\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 3 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nðŸ”§ Tuning emotion thresholds...\n  Emotion 0: threshold=0.100, Score=0.9220\n  Emotion 1: threshold=0.100, Score=0.8824\n  Emotion 2: threshold=0.229, Score=0.5705\n  Emotion 3: threshold=0.150, Score=0.2711\n\nValidation Results (Epoch 3): Loss: 1.4652 Sentiment Accuracy: 0.1810 Sentiment F1 (5-class): 0.1083 Sentiment F1 (Task A Weighted): 0.2637 Sentiment MAE: 1.3038 Emotion F1 (avg): 0.7619 humor F1: 0.9220 sarcasm F1: 0.8824 offensive F1: 0.5705 motivational F1: 0.2466 Thresholds: ['0.100', '0.100', '0.229', '0.150']\nâœ“ Saved best model (New Record)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 :   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 4 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:53<00:00,  6.87it/s, loss=0.6646]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.9459\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 4 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nðŸ”§ Tuning emotion thresholds...\n  Emotion 0: threshold=0.189, Score=0.9228\n  Emotion 1: threshold=0.100, Score=0.8824\n  Emotion 2: threshold=0.254, Score=0.5726\n  Emotion 3: threshold=0.159, Score=0.2232\n\nValidation Results (Epoch 4): Loss: 1.5637 Sentiment Accuracy: 0.1990 Sentiment F1 (5-class): 0.1061 Sentiment F1 (Task A Weighted): 0.2427 Sentiment MAE: 1.2257 Emotion F1 (avg): 0.7648 humor F1: 0.9228 sarcasm F1: 0.8824 offensive F1: 0.5726 motivational F1: 0.2000 Thresholds: ['0.189', '0.100', '0.254', '0.159']\nâœ“ Saved best model (New Record)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 :   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 5 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.79it/s, loss=0.8680]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7965\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 5 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nðŸ”§ Tuning emotion thresholds...\n  Emotion 0: threshold=0.205, Score=0.9219\n  Emotion 1: threshold=0.100, Score=0.8818\n  Emotion 2: threshold=0.262, Score=0.5674\n  Emotion 3: threshold=0.150, Score=0.2336\n\nValidation Results (Epoch 5): Loss: 1.6054 Sentiment Accuracy: 0.2181 Sentiment F1 (5-class): 0.1296 Sentiment F1 (Task A Weighted): 0.2880 Sentiment MAE: 1.1438 Emotion F1 (avg): 0.7683 humor F1: 0.9219 sarcasm F1: 0.8818 offensive F1: 0.5674 motivational F1: 0.2222 Thresholds: ['0.205', '0.100', '0.262', '0.150']\nâœ“ Saved best model (New Record)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6 :   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 6 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:53<00:00,  6.88it/s, loss=0.6067]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7011\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 6 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nðŸ”§ Tuning emotion thresholds...\n  Emotion 0: threshold=0.100, Score=0.9220\n  Emotion 1: threshold=0.286, Score=0.8833\n  Emotion 2: threshold=0.237, Score=0.5710\n  Emotion 3: threshold=0.159, Score=0.1024\n\nValidation Results (Epoch 6): Loss: 1.4554 Sentiment Accuracy: 0.2248 Sentiment F1 (5-class): 0.1579 Sentiment F1 (Task A Weighted): 0.4021 Sentiment MAE: 1.2676 Emotion F1 (avg): 0.7678 humor F1: 0.9220 sarcasm F1: 0.8833 offensive F1: 0.5710 motivational F1: 0.1333 Thresholds: ['0.100', '0.286', '0.237', '0.159']\nâœ“ Saved best model (New Record)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7 :   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 7 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.86it/s, loss=0.4503]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.6439\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 7 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nðŸ”§ Tuning emotion thresholds...\n  Emotion 0: threshold=0.100, Score=0.9209\n  Emotion 1: threshold=0.100, Score=0.8812\n  Emotion 2: threshold=0.278, Score=0.5703\n  Emotion 3: threshold=0.150, Score=0.1746\n\nValidation Results (Epoch 7): Loss: 1.7714 Sentiment Accuracy: 0.2495 Sentiment F1 (5-class): 0.1647 Sentiment F1 (Task A Weighted): 0.3932 Sentiment MAE: 1.1571 Emotion F1 (avg): 0.7640 humor F1: 0.9209 sarcasm F1: 0.8812 offensive F1: 0.5703 motivational F1: 0.1705 Thresholds: ['0.100', '0.100', '0.278', '0.150']\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8 :   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 8 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:53<00:00,  6.88it/s, loss=0.4199]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.5877\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 8 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nðŸ”§ Tuning emotion thresholds...\n  Emotion 0: threshold=0.100, Score=0.9220\n  Emotion 1: threshold=0.100, Score=0.8821\n  Emotion 2: threshold=0.173, Score=0.5684\n  Emotion 3: threshold=0.150, Score=0.1882\n\nValidation Results (Epoch 8): Loss: 1.7138 Sentiment Accuracy: 0.3010 Sentiment F1 (5-class): 0.1784 Sentiment F1 (Task A Weighted): 0.3877 Sentiment MAE: 1.0162 Emotion F1 (avg): 0.7557 humor F1: 0.9220 sarcasm F1: 0.8821 offensive F1: 0.5684 motivational F1: 0.1925 Thresholds: ['0.100', '0.100', '0.173', '0.150']\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9 :   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 9 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.86it/s, loss=0.3917]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.5577\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 9 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nðŸ”§ Tuning emotion thresholds...\n  Emotion 0: threshold=0.124, Score=0.9224\n  Emotion 1: threshold=0.132, Score=0.8817\n  Emotion 2: threshold=0.254, Score=0.5714\n  Emotion 3: threshold=0.159, Score=0.0864\n\nValidation Results (Epoch 9): Loss: 1.6200 Sentiment Accuracy: 0.3295 Sentiment F1 (5-class): 0.1909 Sentiment F1 (Task A Weighted): 0.4232 Sentiment MAE: 0.9543 Emotion F1 (avg): 0.7819 humor F1: 0.9224 sarcasm F1: 0.8817 offensive F1: 0.5714 motivational F1: 0.1208 Thresholds: ['0.124', '0.132', '0.254', '0.159']\nâœ“ Saved best model (New Record)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10 :   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 10 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.86it/s, loss=0.2915]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.5145\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 10 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nðŸ”§ Tuning emotion thresholds...\n  Emotion 0: threshold=0.100, Score=0.9214\n  Emotion 1: threshold=0.100, Score=0.8811\n  Emotion 2: threshold=0.197, Score=0.5797\n  Emotion 3: threshold=0.164, Score=0.1107\n\nValidation Results (Epoch 10): Loss: 1.5880 Sentiment Accuracy: 0.3029 Sentiment F1 (5-class): 0.1929 Sentiment F1 (Task A Weighted): 0.4455 Sentiment MAE: 1.0552 Emotion F1 (avg): 0.7670 humor F1: 0.9214 sarcasm F1: 0.8811 offensive F1: 0.5797 motivational F1: 0.1412 Thresholds: ['0.100', '0.100', '0.197', '0.164']\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11 :   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 11 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.86it/s, loss=0.3650]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4897\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 11 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nðŸ”§ Tuning emotion thresholds...\n  Emotion 0: threshold=0.100, Score=0.9214\n  Emotion 1: threshold=0.100, Score=0.8824\n  Emotion 2: threshold=0.302, Score=0.5865\n  Emotion 3: threshold=0.155, Score=0.0573\n\nValidation Results (Epoch 11): Loss: 1.7811 Sentiment Accuracy: 0.3210 Sentiment F1 (5-class): 0.1963 Sentiment F1 (Task A Weighted): 0.3510 Sentiment MAE: 0.9019 Emotion F1 (avg): 0.7748 humor F1: 0.9214 sarcasm F1: 0.8824 offensive F1: 0.5865 motivational F1: 0.0789 Thresholds: ['0.100', '0.100', '0.302', '0.155']\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12 :   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 12 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:43<00:00,  8.44it/s, loss=0.5329]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4620\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 12 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nðŸ”§ Tuning emotion thresholds...\n  Emotion 0: threshold=0.500, Score=0.0000\n  Emotion 1: threshold=0.500, Score=0.0000\n  Emotion 2: threshold=0.500, Score=0.0000\n  Emotion 3: threshold=0.500, Score=0.0000\n\nValidation Results (Epoch 12): Loss: nan Sentiment Accuracy: 0.0419 Sentiment F1 (5-class): 0.0161 Sentiment F1 (Task A Weighted): 0.1495 Sentiment MAE: 1.9524 Emotion F1 (avg): 0.0000 humor F1: 0.0000 sarcasm F1: 0.0000 offensive F1: 0.0000 motivational F1: 0.0000 Thresholds: ['0.500', '0.500', '0.500', '0.500']\nEarly stopping at epoch 12\n\n======================================================================\nSTAGE 2: MOTIVATIONAL-ONLY FINE-TUNING\n======================================================================\nCreating strict Balanced Batch Sampler...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22 [Fine-Tune]:   0%|          | 0/437 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 22 [Fine-Tune]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 437/437 [00:40<00:00, 10.85it/s, loss=0.6215]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Loss: 0.7257\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 22 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nðŸ”§ Tuning emotion thresholds...\n  Emotion 0: threshold=0.140, Score=0.9224\n  Emotion 1: threshold=0.100, Score=0.8818\n  Emotion 2: threshold=0.229, Score=0.5797\n  Emotion 3: threshold=0.150, Score=0.0583\n\nValidation Results (Epoch 22): Loss: 1.6022 Sentiment Accuracy: 0.3295 Sentiment F1 (5-class): 0.1909 Sentiment F1 (Task A Weighted): 0.4232 Sentiment MAE: 0.9543 Emotion F1 (avg): 0.7689 humor F1: 0.9224 sarcasm F1: 0.8818 offensive F1: 0.5797 motivational F1: 0.0839 Thresholds: ['0.140', '0.100', '0.229', '0.150']\nâœ“ Saved fine-tuned model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23 [Fine-Tune]:   0%|          | 0/437 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 23 [Fine-Tune]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 437/437 [00:40<00:00, 10.81it/s, loss=0.7305]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Loss: 0.7185\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 23 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nðŸ”§ Tuning emotion thresholds...\n  Emotion 0: threshold=0.165, Score=0.9224\n  Emotion 1: threshold=0.197, Score=0.8817\n  Emotion 2: threshold=0.254, Score=0.5768\n  Emotion 3: threshold=0.159, Score=0.0583\n\nValidation Results (Epoch 23): Loss: 1.5482 Sentiment Accuracy: 0.3295 Sentiment F1 (5-class): 0.1909 Sentiment F1 (Task A Weighted): 0.4232 Sentiment MAE: 0.9543 Emotion F1 (avg): 0.7716 humor F1: 0.9224 sarcasm F1: 0.8817 offensive F1: 0.5768 motivational F1: 0.0839 Thresholds: ['0.165', '0.197', '0.254', '0.159']\nâœ“ Saved fine-tuned model\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24 [Fine-Tune]:   0%|          | 0/437 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 24 [Fine-Tune]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 437/437 [00:40<00:00, 10.83it/s, loss=0.9562]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Loss: 0.7160\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 24 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nðŸ”§ Tuning emotion thresholds...\n  Emotion 0: threshold=0.189, Score=0.9224\n  Emotion 1: threshold=0.100, Score=0.8818\n  Emotion 2: threshold=0.221, Score=0.5779\n  Emotion 3: threshold=0.150, Score=0.0488\n\nValidation Results (Epoch 24): Loss: 1.5656 Sentiment Accuracy: 0.3295 Sentiment F1 (5-class): 0.1909 Sentiment F1 (Task A Weighted): 0.4232 Sentiment MAE: 0.9543 Emotion F1 (avg): 0.7669 humor F1: 0.9224 sarcasm F1: 0.8818 offensive F1: 0.5779 motivational F1: 0.0714 Thresholds: ['0.189', '0.100', '0.221', '0.150']\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25 [Fine-Tune]:   0%|          | 0/437 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 25 [Fine-Tune]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 437/437 [00:40<00:00, 10.82it/s, loss=0.9364]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Loss: 0.7021\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 25 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nðŸ”§ Tuning emotion thresholds...\n  Emotion 0: threshold=0.189, Score=0.9224\n  Emotion 1: threshold=0.100, Score=0.8818\n  Emotion 2: threshold=0.237, Score=0.5767\n  Emotion 3: threshold=0.200, Score=0.0394\n\nValidation Results (Epoch 25): Loss: 1.5678 Sentiment Accuracy: 0.3295 Sentiment F1 (5-class): 0.1909 Sentiment F1 (Task A Weighted): 0.4232 Sentiment MAE: 0.9543 Emotion F1 (avg): 0.7706 humor F1: 0.9224 sarcasm F1: 0.8818 offensive F1: 0.5767 motivational F1: 0.0588 Thresholds: ['0.189', '0.100', '0.237', '0.200']\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26 [Fine-Tune]:   0%|          | 0/437 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 26 [Fine-Tune]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 437/437 [00:39<00:00, 10.97it/s, loss=0.7597]\n","output_type":"stream"},{"name":"stdout","text":"Fine-tune Loss: 0.7154\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 26 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nðŸ”§ Tuning emotion thresholds...\n  Emotion 0: threshold=0.500, Score=0.0000\n  Emotion 1: threshold=0.500, Score=0.0000\n  Emotion 2: threshold=0.500, Score=0.0000\n  Emotion 3: threshold=0.500, Score=0.0000\n\nValidation Results (Epoch 26): Loss: nan Sentiment Accuracy: 0.3295 Sentiment F1 (5-class): 0.1909 Sentiment F1 (Task A Weighted): 0.4232 Sentiment MAE: 0.9543 Emotion F1 (avg): 0.0000 humor F1: 0.0000 sarcasm F1: 0.0000 offensive F1: 0.0000 motivational F1: 0.0000 Thresholds: ['0.500', '0.500', '0.500', '0.500']\n\n================================================================================\nðŸ† BEST EPOCH RESULTS (Epoch 22)\n================================================================================\nValidation Results (Epoch 22): Loss: 1.5482 Sentiment Accuracy: 0.3295 Sentiment F1 (5-class): 0.1909 Sentiment F1 (Task A Weighted): 0.4232 Sentiment MAE: 0.9543 Emotion F1 (avg): 0.7716 humor F1: 0.9224 sarcasm F1: 0.8817 offensive F1: 0.5768 motivational F1: 0.0839 Thresholds: ['0.500', '0.500', '0.500', '0.500']\n================================================================================\n\n\n================================================================================\nâœ… TRAINING COMPLETED!\n================================================================================\nBest composite metric: 1.7547\nFine-tuned Model saved to: /kaggle/working/checkpoints/best_model_finetuned.pt\n================================================================================\nINFERENCE PIPELINE\n================================================================================\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ==================== PART 11: INTERACTIVE DEMO (FINAL WORKING VERSION) ====================\nimport sys\nimport subprocess\n\n# 1. Install Gradio quietly\nprint(\"Installing Gradio...\")\nsubprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"gradio\"])\n\nimport gradio as gr\nimport numpy as np\nfrom PIL import Image\nimport os\nimport torch\n\nprint(\"=\" * 80)\nprint(\"STARTING INTERACTIVE DEMO\")\nprint(\"=\" * 80)\n\n# 2. Initialize Inference Engine (if not already loaded)\nif 'inferencer' not in globals():\n    print(\"Initializing Inference Engine...\")\n    # Check for the fine-tuned model first, fallback to the base enhanced model\n    checkpoint = '/kaggle/working/checkpoints/best_model_finetuned.pt'\n    if not os.path.exists(checkpoint):\n        print(\"Fine-tuned model not found, looking for base model...\")\n        checkpoint = '/kaggle/working/checkpoints/best_model_enhanced.pt'\n    \n    if os.path.exists(checkpoint):\n        inferencer = MemeInference(checkpoint_path=checkpoint, device='cuda')\n        print(f\"âœ“ Loaded model from: {checkpoint}\")\n    else:\n        raise FileNotFoundError(\"No checkpoint found! Did you run the training (Part 8)?\")\n\n# 3. Define the Analysis Function\ndef analyze_meme(image_obj, text_input):\n    \"\"\"\n    Takes an image and text, runs the model, and formats the output for Gradio.\n    \"\"\"\n    if image_obj is None:\n        return \"âš ï¸ Please upload an image.\", 0.0, {}\n    \n    # Save temporary file because predict_single expects a file path\n    temp_path = \"temp_meme_upload.jpg\"\n    image_obj.save(temp_path)\n    \n    try:\n        # --- RUN INFERENCE ---\n        result = inferencer.predict_single(temp_path, text_input)\n        \n        # --- FORMAT RESULTS ---\n        \n        # 1. Sentiment (Fixing the key access error)\n        # The model returns 'sentiment' as a simple string, and 'sentiment_conf' as a float\n        sent_label = result['sentiment'] \n        sent_conf = result['sentiment_conf']\n        sent_str = f\"{sent_label.upper()} \\n(Confidence: {sent_conf:.1%})\"\n        \n        # 2. Emotions\n        emo_out = {}\n        for emo, details in result['emotions'].items():\n            prob = details['probability']\n            is_present = details['present']\n            \n            # Add a checkmark to the label if the model thinks it's present\n            label_str = emo.upper()\n            if is_present:\n                label_str = f\"âœ… {label_str}\"\n            \n            emo_out[label_str] = prob\n            \n        return sent_str, result['intensity'], emo_out\n        \n    except Exception as e:\n        return f\"Error during analysis: {str(e)}\", 0.0, {}\n\n# 4. Prepare Examples (Robust Loading)\n# We try to load 2 images from the validation set to use as clickable examples.\nexamples_list = []\ntry:\n    if 'val_df' in globals() and 'NEW_VAL_DIR' in globals():\n        # Helper to find a valid image path from the dataframe\n        def get_valid_path(row, base_dir):\n            # Handle different column names for the image filename\n            col_name = 'image_name' if 'image_name' in row else row.index[0]\n            fname = str(row[col_name])\n            if not fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n                fname += \".jpg\"\n            full_path = os.path.join(base_dir, fname)\n            return full_path if os.path.exists(full_path) else None\n\n        # Try to grab the 1st and 6th image from validation\n        indices_to_try = [0, 5]\n        for idx in indices_to_try:\n            if idx < len(val_df):\n                path = get_valid_path(val_df.iloc[idx], NEW_VAL_DIR)\n                text = str(val_df.iloc[idx].get('text', ''))\n                if path:\n                    examples_list.append([path, text])\n        \n        if examples_list:\n            print(f\"âœ“ Loaded {len(examples_list)} examples for the demo.\")\nexcept Exception as e:\n    print(f\"âš ï¸ Could not load auto-examples (minor issue): {e}\")\n\n# 5. Build and Launch the Interface\niface = gr.Interface(\n    fn=analyze_meme,\n    inputs=[\n        gr.Image(type=\"pil\", label=\"1. Upload Meme\"), \n        gr.Textbox(label=\"2. Enter Text (Optional)\", placeholder=\"Type the text inside the meme here...\", lines=2)\n    ],\n    outputs=[\n        gr.Label(label=\"Predicted Sentiment\"),\n        gr.Number(label=\"Intensity Score (0.0 - 1.0)\"),\n        gr.Label(label=\"Detected Emotions & Probabilities\", num_top_classes=4)\n    ],\n    title=\"ðŸ¤– Enhanced Meme Analysis AI\",\n    description=f\"\"\"\n    **Task:** Multimodal Classification (Text + Image Analysis)\n    <br><b>Model:</b> Dual-Encoder (MurilBERT + CLIP) with Cross-Attention Fusion.\n    <br><b>Current Status:</b> Fine-tuned for Sarcasm & Motivation.\n    <br><b>Active Thresholds:</b> {[f'{t:.3f}' for t in inferencer.current_thresholds]}\n    \"\"\",\n    examples=examples_list if examples_list else None,\n    theme=\"default\"\n)\n\nprint(\"\\nðŸš€ Launching Demo... Click the public link below!\")\niface.launch(share=True, debug=True, inline=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T20:13:39.999130Z","iopub.execute_input":"2025-12-02T20:13:39.999545Z"}},"outputs":[{"name":"stdout","text":"Installing Gradio...\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 68.6/68.6 kB 2.1 MB/s eta 0:00:00\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 444.8/444.8 kB 10.4 MB/s eta 0:00:00\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.0/2.0 MB 43.8 MB/s eta 0:00:00\n","output_type":"stream"},{"name":"stderr","text":"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n","output_type":"stream"},{"name":"stdout","text":"================================================================================\nSTARTING INTERACTIVE DEMO\n================================================================================\nInitializing Inference Engine...\nLoading checkpoint from /kaggle/working/checkpoints/best_model_finetuned.pt...\nâœ“ Thresholds: ['0.165', '0.197', '0.254', '0.159']\nâœ“ Loaded model from: /kaggle/working/checkpoints/best_model_finetuned.pt\nâœ“ Loaded 2 examples for the demo.\n\nðŸš€ Launching Demo... Click the public link below!\n* Running on local URL:  http://127.0.0.1:7860\n* Running on public URL: https://efe476f5aedd5d2e5c.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://efe476f5aedd5d2e5c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}