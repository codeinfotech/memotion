{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ==================== COMPLETE ENHANCED MEME ANALYSIS PIPELINE ====================\n# This code includes BOTH data preparation AND enhanced training\n# Run this entire script from start to finish\n\n# ==================== PART 0: SETUP & DEPENDENCIES ====================\nimport sys, subprocess, os, json, zipfile, shutil, random, warnings\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom torch.cuda.amp import GradScaler, autocast\nimport torchvision.transforms as transforms\nfrom PIL import Image\nfrom tqdm import tqdm\nimport yaml\n\nwarnings.filterwarnings('ignore')\n\nprint(\"=\" * 80)\nprint(\"INSTALLING DEPENDENCIES...\")\nprint(\"=\" * 80)\n\n# Install required packages\nsubprocess.check_call([\n    sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n    \"transformers>=4.40.0\", \"accelerate\", \"torch\", \"timm\",\n    \"scikit-learn\", \"pandas\", \"matplotlib\", \"seaborn\",\n    \"huggingface_hub>=0.18.0\", \"gdown\", \"iterative-stratification\"\n])\n\n# Import additional packages\nfrom sklearn.metrics import (\n    accuracy_score, precision_recall_fscore_support,\n    mean_squared_error, mean_absolute_error, f1_score\n)\nfrom transformers import AutoModel, AutoTokenizer, CLIPModel\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n\nprint(\"âœ“ All dependencies installed\\n\")\n\n# ==================== PART 1: DATA PREPARATION ====================\nprint(\"=\" * 80)\nprint(\"PART 1: DATA PREPARATION\")\nprint(\"=\" * 80)\n\n# Download and extract dataset\nprint(\"\\nDownloading dataset...\")\nsubprocess.run([\"gdown\", \"1jEJ2nf5CDJknq80ogzU-Uyz7jbBi-1LZ\", \"--fuzzy\"], \n               check=False, capture_output=True)\n\nprint(\"Extracting dataset...\")\nzip_files = [f for f in os.listdir('.') if f.endswith('.zip')]\nif zip_files:\n    subprocess.run([\"unzip\", \"-q\", \"-o\", zip_files[0]], check=False, capture_output=True)\n\n# Download additional files\nsubprocess.run([\n    \"gdown\", \"--folder\", \"19yaav8ORSVj9DeJUaHKq1H3HtVnkClBw\", \"--remaining-ok\"\n], check=False, capture_output=True)\n\n# Extract password-protected archive\nprint(\"Extracting protected archive...\")\nzip_path = '/kaggle/working/Memotion 3/memotion3.zip'\nextract_to = '/kaggle/working/'\npassword = b'memotion3taskaaai@22'\n\nif os.path.exists(zip_path):\n    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n        zip_ref.extractall(extract_to, pwd=password)\n    print(f\"âœ“ Extracted to: {extract_to}\")\n\n# Setup paths\nORIGINAL_TRAIN_IMG_DIR = '/kaggle/working/trainImages/'\nORIGINAL_CSV_PATH = '/kaggle/working/memotion3/train.csv'\nVALIDATION_SPLIT_RATIO = 0.15\n\nOUTPUT_BASE_DIR = '/kaggle/working/'\nNEW_VAL_DIR = os.path.join(OUTPUT_BASE_DIR, 'validation_images/')\nNEW_TRAIN_DIR = os.path.join(OUTPUT_BASE_DIR, 'new_train_images/')\n\nos.makedirs(NEW_VAL_DIR, exist_ok=True)\nos.makedirs(NEW_TRAIN_DIR, exist_ok=True)\n\n# Load and process CSV\nprint(\"\\nLoading CSV file...\")\ndf = pd.read_csv(ORIGINAL_CSV_PATH)\n\n# Detect image column\npossible_image_cols = ['image_name', 'image', 'img_name', 'filename', 'Unnamed: 0']\nIMAGE_FILENAME_COLUMN = next((col for col in possible_image_cols if col in df.columns), df.columns[0])\nprint(f\"âœ“ Image column: {IMAGE_FILENAME_COLUMN}\")\n\n# Normalize labels\nfor col in ['offensive', 'motivational', 'humour', 'humor', 'sarcastic', 'sarcasm', 'overall', 'sentiment']:\n    if col in df.columns:\n        df[col] = df[col].astype(str).str.lower().str.strip()\n\n# Create binary labels\ndef create_binary_label(value, positive_values):\n    if pd.isna(value) or value in ['nan', 'none', '']:\n        return 0\n    return 1 if value in positive_values else 0\n\nif 'offensive' in df.columns:\n    df['offensive_bin'] = df['offensive'].apply(\n        lambda x: create_binary_label(x, ['slight', 'very_offensive', 'hateful_offensive'])\n    )\nelse:\n    df['offensive_bin'] = 0\n\nif 'motivational' in df.columns:\n    df['motivational_bin'] = df['motivational'].apply(\n        lambda x: create_binary_label(x, ['motivational'])\n    )\nelse:\n    df['motivational_bin'] = 0\n\nif 'humour' in df.columns or 'humor' in df.columns:\n    humor_col = 'humour' if 'humour' in df.columns else 'humor'\n    df['humor_bin'] = df[humor_col].apply(\n        lambda x: create_binary_label(x, ['funny', 'very_funny', 'hilarious'])\n    )\nelse:\n    df['humor_bin'] = 0\n\nif 'sarcastic' in df.columns or 'sarcasm' in df.columns:\n    sarcasm_col = 'sarcastic' if 'sarcastic' in df.columns else 'sarcasm'\n    df['sarcasm_bin'] = df[sarcasm_col].apply(\n        lambda x: create_binary_label(x, ['general', 'twisted_meaning', 'very_twisted'])\n    )\nelse:\n    df['sarcasm_bin'] = 0\n\n# Stratified split\nstratify_columns = ['offensive_bin', 'motivational_bin', 'humor_bin', 'sarcasm_bin']\ny_stratify = df[stratify_columns].values\n\nmsss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=VALIDATION_SPLIT_RATIO, random_state=42)\ntrain_idx, val_idx = next(msss.split(df, y_stratify))\n\ntrain_df = df.iloc[train_idx].reset_index(drop=True)\nval_df = df.iloc[val_idx].reset_index(drop=True)\n\nprint(f\"\\nâœ“ Stratified split complete:\")\nprint(f\"  Training: {len(train_df)} samples\")\nprint(f\"  Validation: {len(val_df)} samples\")\n\n# Calculate label priors\nlabel_priors = {\n    'offensive_pos_rate': float(train_df['offensive_bin'].sum() / len(train_df)),\n    'motivational_pos_rate': float(train_df['motivational_bin'].sum() / len(train_df)),\n    'humor_pos_rate': float(train_df['humor_bin'].sum() / len(train_df)),\n    'sarcasm_pos_rate': float(train_df['sarcasm_bin'].sum() / len(train_df))\n}\n\npriors_path = os.path.join(OUTPUT_BASE_DIR, 'label_priors.json')\nwith open(priors_path, 'w') as f:\n    json.dump(label_priors, f, indent=2)\n\nprint(f\"\\nâœ“ Label priors calculated:\")\nfor key, val in label_priors.items():\n    print(f\"  {key}: {val:.4f}\")\n\n# Copy images\ndef copy_images(df_subset, dest_dir, source_dir, image_col):\n    copied = 0\n    missing = 0\n    \n    for idx in tqdm(df_subset[image_col], desc=f\"Copying to {dest_dir}\"):\n        filename = str(idx)\n        if not any(filename.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif']):\n            for ext in ['.jpg', '.jpeg', '.png']:\n                test_path = os.path.join(source_dir, f\"{filename}{ext}\")\n                if os.path.exists(test_path):\n                    filename = f\"{filename}{ext}\"\n                    break\n            else:\n                filename = f\"{filename}.jpg\"\n        \n        source_path = os.path.join(source_dir, filename)\n        if os.path.exists(source_path):\n            shutil.copy(source_path, os.path.join(dest_dir, filename))\n            copied += 1\n        else:\n            missing += 1\n    \n    return copied, missing\n\nprint(\"\\nCopying images...\")\ncopied_val, missing_val = copy_images(val_df, NEW_VAL_DIR, ORIGINAL_TRAIN_IMG_DIR, IMAGE_FILENAME_COLUMN)\ncopied_train, missing_train = copy_images(train_df, NEW_TRAIN_DIR, ORIGINAL_TRAIN_IMG_DIR, IMAGE_FILENAME_COLUMN)\n\nprint(f\"âœ“ Validation: {copied_val} copied, {missing_val} missing\")\nprint(f\"âœ“ Training: {copied_train} copied, {missing_train} missing\")\n\n# Save CSVs\ntrain_csv_path = os.path.join(OUTPUT_BASE_DIR, 'train_split.csv')\nval_csv_path = os.path.join(OUTPUT_BASE_DIR, 'validation_split.csv')\n\ntrain_df.to_csv(train_csv_path, index=False)\nval_df.to_csv(val_csv_path, index=False)\n\nprint(f\"\\nâœ“ Saved train CSV: {train_csv_path}\")\nprint(f\"âœ“ Saved validation CSV: {val_csv_path}\")\nprint(\"\\nâœ… DATA PREPARATION COMPLETE\\n\")\n\n# ==================== PART 2: CONFIGURATION ====================\nprint(\"=\" * 80)\nprint(\"PART 2: CONFIGURATION\")\nprint(\"=\" * 80)\n\nCONFIG_YAML = \"\"\"\nTEXT_MODEL: \"google/muril-base-cased\"\nIMAGE_MODEL: \"openai/clip-vit-base-patch32\"\nTEXT_DIM: 768\nIMAGE_DIM: 768\nFUSION_DIM: 512\nFUSION_OUT_DIM: 512\n\nMAX_LEN: 128\nIMG_SIZE: 224\nBATCH_SIZE: 16\nGRADIENT_ACCUMULATION_STEPS: 2\nLR_HEADS: 0.001\nLR_BACKBONE: 0.00002\nWEIGHT_DECAY: 0.01\nEPOCHS: 20\nSEED: 42\nDEVICE: \"cuda\"\nCHECKPOINT_PATH: \"/kaggle/working/checkpoints\"\n\nNUM_SENTIMENT_CLASSES: 5\nNUM_EMOTION_CLASSES: 4\n\nUSE_ORDINAL_REGRESSION: true\nORDINAL_LINK: \"logit\"\n\nLOSS_WEIGHTS:\n  sentiment: 2.0\n  emotion: 1.5\n  intensity: 0.5\n\nASL_GAMMA_NEG: 6.0\nASL_GAMMA_POS: 0.5\nASL_CLIP: 0.05\nASL_PRIOR_TAU: 1.2\n\nEMOTION_LABELS: [\"humor\", \"sarcasm\", \"offensive\", \"motivational\"]\nEMO_THRESHOLDS: [0.5, 0.5, 0.60, 0.60]\n\nPOOLING: \"mean\"\nUSE_AMP: true\nGRADIENT_CLIP: 1.0\nSCHEDULER: \"cosine\"\nUNFREEZE_BACKBONE_EPOCH: 2\nUNFREEZE_LAYERS: 3\n\nMOTIVATIONAL_OVERSAMPLE_FACTOR: 8.0\n\nCROSS_ATTN_HEADS: 8\nCROSS_ATTN_DROPOUT: 0.1\n\nSENTIMENT_MAP_REV:\n  0: \"very_positive\"\n  1: \"positive\"\n  2: \"neutral\"\n  3: \"negative\"\n  4: \"very_negative\"\n\"\"\"\n\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\ncfg = yaml.safe_load(CONFIG_YAML)\nset_seed(cfg['SEED'])\n\n# Load priors\nwith open(priors_path, 'r') as f:\n    priors = json.load(f)\n\ncfg['EMO_PRIORS'] = [\n    priors['humor_pos_rate'],\n    priors['sarcasm_pos_rate'],\n    priors['offensive_pos_rate'],\n    priors['motivational_pos_rate']\n]\n\ndevice = torch.device(cfg['DEVICE'] if torch.cuda.is_available() else 'cpu')\n\nprint(f\"\\nâœ“ Configuration loaded:\")\nprint(f\"  Device: {device}\")\nprint(f\"  Epochs: {cfg['EPOCHS']}\")\nprint(f\"  Batch size: {cfg['BATCH_SIZE']}\")\nprint(f\"  Motivational oversampling: {cfg['MOTIVATIONAL_OVERSAMPLE_FACTOR']}x\")\nprint(f\"  Emotion priors: {[f'{p:.3f}' for p in cfg['EMO_PRIORS']]}\")\n\n# ==================== PART 3: MODEL COMPONENTS ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 3: MODEL COMPONENTS\")\nprint(\"=\" * 80)\n\nclass EnhancedAsymmetricLoss(nn.Module):\n    \"\"\"Enhanced ASL with prior adjustment\"\"\"\n    def __init__(self, gamma_neg=6.0, gamma_pos=0.5, clip=0.05, priors=None, prior_tau=1.2, eps=1e-8):\n        super().__init__()\n        self.gamma_neg = gamma_neg\n        self.gamma_pos = gamma_pos\n        self.clip = clip\n        self.eps = eps\n        self.priors = priors\n        self.prior_tau = prior_tau\n    \n    def forward(self, logits, targets):\n        # Prior adjustment\n        if self.priors is not None:\n            priors_tensor = torch.tensor(self.priors, device=logits.device, dtype=logits.dtype)\n            adjustment = self.prior_tau * torch.log(priors_tensor.clamp(min=self.eps))\n            logits = logits - adjustment\n        \n        xs_pos = torch.sigmoid(logits)\n        xs_neg = 1 - xs_pos\n        \n        if self.clip is not None and self.clip > 0:\n            xs_neg = (xs_neg + self.clip).clamp(max=1)\n        \n        los_pos = targets * torch.log(xs_pos.clamp(min=self.eps))\n        los_neg = (1 - targets) * torch.log(xs_neg.clamp(min=self.eps))\n        \n        if self.gamma_neg > 0 or self.gamma_pos > 0:\n            pt0 = xs_pos * targets\n            pt1 = xs_neg * (1 - targets)\n            pt = pt0 + pt1\n            one_sided_gamma = self.gamma_pos * targets + self.gamma_neg * (1 - targets)\n            one_sided_w = torch.pow(1 - pt, one_sided_gamma)\n            loss = one_sided_w * (los_pos + los_neg)\n        else:\n            loss = los_pos + los_neg\n        \n        return -loss.mean()\n\nclass OrdinalRegressionHead(nn.Module):\n    \"\"\"Ordinal regression using cumulative link model\"\"\"\n    def __init__(self, input_dim, num_classes):\n        super().__init__()\n        self.num_classes = num_classes\n        self.num_thresholds = num_classes - 1\n        \n        self.projection = nn.Sequential(\n            nn.Linear(input_dim, 256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, 1)\n        )\n        \n        initial_thresholds = torch.linspace(-2, 2, self.num_thresholds)\n        self.thresholds = nn.Parameter(initial_thresholds)\n    \n    def forward(self, x):\n        score = self.projection(x).squeeze(-1)\n        ordered_thresholds = torch.cumsum(F.softplus(self.thresholds), dim=0)\n        cumulative_logits = ordered_thresholds.unsqueeze(0) - score.unsqueeze(1)\n        cumulative_probs = torch.sigmoid(cumulative_logits)\n        \n        batch_size = cumulative_probs.size(0)\n        class_probs = torch.zeros(batch_size, self.num_classes, device=x.device)\n        \n        class_probs[:, 0] = cumulative_probs[:, 0]\n        for k in range(1, self.num_thresholds):\n            class_probs[:, k] = cumulative_probs[:, k] - cumulative_probs[:, k-1]\n        class_probs[:, -1] = 1.0 - cumulative_probs[:, -1]\n        class_probs = torch.clamp(class_probs, min=1e-7, max=1.0)\n        \n        return {'cumulative_logits': cumulative_logits, 'class_probs': class_probs}\n\nclass CrossAttentionFusion(nn.Module):\n    \"\"\"Bidirectional cross-attention\"\"\"\n    def __init__(self, dim, num_heads=8, dropout=0.1):\n        super().__init__()\n        self.text_to_image_attn = nn.MultiheadAttention(dim, num_heads, dropout, batch_first=True)\n        self.image_to_text_attn = nn.MultiheadAttention(dim, num_heads, dropout, batch_first=True)\n        self.text_norm = nn.LayerNorm(dim)\n        self.image_norm = nn.LayerNorm(dim)\n        self.text_ffn = nn.Sequential(\n            nn.Linear(dim, dim * 4), nn.GELU(), nn.Dropout(dropout),\n            nn.Linear(dim * 4, dim), nn.Dropout(dropout)\n        )\n        self.image_ffn = nn.Sequential(\n            nn.Linear(dim, dim * 4), nn.GELU(), nn.Dropout(dropout),\n            nn.Linear(dim * 4, dim), nn.Dropout(dropout)\n        )\n        self.ffn_norm_text = nn.LayerNorm(dim)\n        self.ffn_norm_image = nn.LayerNorm(dim)\n    \n    def forward(self, text_emb, image_emb):\n        text_seq = text_emb.unsqueeze(1)\n        image_seq = image_emb.unsqueeze(1)\n        \n        text_attended, _ = self.text_to_image_attn(text_seq, image_seq, image_seq)\n        text_out = self.text_norm(text_emb + text_attended.squeeze(1))\n        \n        image_attended, _ = self.image_to_text_attn(image_seq, text_seq, text_seq)\n        image_out = self.image_norm(image_emb + image_attended.squeeze(1))\n        \n        text_final = self.ffn_norm_text(text_out + self.text_ffn(text_out))\n        image_final = self.ffn_norm_image(image_out + self.image_ffn(image_out))\n        \n        return text_final, image_final\n\nclass EnhancedFusionModel(nn.Module):\n    \"\"\"Multi-modal model with ordinal regression + enhanced ASL\"\"\"\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg = cfg\n        \n        self.text_model = AutoModel.from_pretrained(cfg['TEXT_MODEL'])\n        clip_model = CLIPModel.from_pretrained(cfg['IMAGE_MODEL'])\n        self.image_model = clip_model.vision_model\n        \n        self._freeze_encoders()\n        \n        self.text_proj = nn.Linear(cfg['TEXT_DIM'], cfg['FUSION_DIM'])\n        self.image_proj = nn.Linear(cfg['IMAGE_DIM'], cfg['FUSION_DIM'])\n        \n        self.cross_attention = CrossAttentionFusion(\n            dim=cfg['FUSION_DIM'],\n            num_heads=cfg['CROSS_ATTN_HEADS'],\n            dropout=cfg['CROSS_ATTN_DROPOUT']\n        )\n        \n        fusion_input_dim = cfg['FUSION_DIM'] * 2\n        self.fusion_norm = nn.LayerNorm(fusion_input_dim)\n        self.fusion_mlp = nn.Sequential(\n            nn.Linear(fusion_input_dim, 512), nn.GELU(), nn.Dropout(0.2),\n            nn.Linear(512, cfg['FUSION_OUT_DIM']), nn.LayerNorm(cfg['FUSION_OUT_DIM'])\n        )\n        \n        self.sentiment_head = OrdinalRegressionHead(cfg['FUSION_OUT_DIM'], cfg['NUM_SENTIMENT_CLASSES'])\n        self.emotion_head = nn.Sequential(\n            nn.Linear(cfg['FUSION_OUT_DIM'], 256), nn.ReLU(), nn.Dropout(0.2),\n            nn.Linear(256, cfg['NUM_EMOTION_CLASSES'])\n        )\n        self.intensity_head = nn.Sequential(\n            nn.Linear(cfg['FUSION_OUT_DIM'], 128), nn.ReLU(), nn.Dropout(0.2),\n            nn.Linear(128, 1)\n        )\n    \n    def _freeze_encoders(self):\n        for param in self.text_model.parameters():\n            param.requires_grad = False\n        for param in self.image_model.parameters():\n            param.requires_grad = False\n    \n    def unfreeze_backbone(self, layers_to_unfreeze=3):\n        if hasattr(self.text_model, 'encoder') and hasattr(self.text_model.encoder, 'layer'):\n            for layer in list(self.text_model.encoder.layer[-layers_to_unfreeze:]):\n                for param in layer.parameters():\n                    param.requires_grad = True\n        \n        if hasattr(self.image_model, 'encoder') and hasattr(self.image_model.encoder, 'layers'):\n            for layer in list(self.image_model.encoder.layers[-layers_to_unfreeze:]):\n                for param in layer.parameters():\n                    param.requires_grad = True\n    \n    def pool_text(self, model_output, attention_mask):\n        last_hidden = model_output.last_hidden_state\n        if self.cfg['POOLING'] == 'cls':\n            return last_hidden[:, 0]\n        mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden.size()).float()\n        sum_embeddings = torch.sum(last_hidden * mask_expanded, 1)\n        sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n        return sum_embeddings / sum_mask\n    \n    def forward(self, input_ids, attention_mask, image):\n        text_output = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n        text_emb = self.pool_text(text_output, attention_mask)\n        \n        image_output = self.image_model(pixel_values=image)\n        image_emb = image_output.pooler_output\n        \n        text_proj = self.text_proj(text_emb)\n        image_proj = self.image_proj(image_emb)\n        \n        text_cross, image_cross = self.cross_attention(text_proj, image_proj)\n        \n        fused = torch.cat([text_cross, image_cross], dim=1)\n        fused = self.fusion_norm(fused)\n        fused = self.fusion_mlp(fused)\n        \n        sentiment_outputs = self.sentiment_head(fused)\n        emotion_logits = self.emotion_head(fused)\n        intensity = self.intensity_head(fused).squeeze(-1)\n        \n        return {\n            'sentiment': sentiment_outputs,\n            'emotion_logits': emotion_logits,\n            'intensity': intensity\n        }\n\nprint(\"âœ“ Model components defined\")\n\n# ==================== PART 4: DATASET ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 4: DATASET\")\nprint(\"=\" * 80)\n\nclass MemeDataset(Dataset):\n    def __init__(self, df, tokenizer, image_transform, image_dir, cfg):\n        self.df = df.reset_index(drop=True)\n        self.tokenizer = tokenizer\n        self.image_transform = image_transform\n        self.image_dir = image_dir\n        self.cfg = cfg\n        self._detect_columns()\n    \n    def _detect_columns(self):\n        cols = self.df.columns.tolist()\n        self.image_col = next((c for c in ['image_name', 'image', 'img_name', 'filename', 'Unnamed: 0'] if c in cols), cols[0])\n        self.text_col = next((c for c in ['text', 'ocr_text', 'caption', 'OCR_extracted_text'] if c in cols), None)\n        self.sentiment_col = next((c for c in ['sentiment', 'overall_sentiment', 'overall'] if c in cols), None)\n        \n        self.sentiment_map = {'very_positive': 0, 'positive': 1, 'neutral': 2, 'negative': 3, 'very_negative': 4}\n        self.humor_map = {'not_funny': 0, 'funny': 1, 'very_funny': 1, 'hilarious': 1}\n        self.sarcasm_map = {'not_sarcastic': 0, 'general': 1, 'twisted_meaning': 1, 'very_twisted': 1}\n        self.offensive_map = {'not_offensive': 0, 'slight': 1, 'very_offensive': 1, 'hateful_offensive': 1}\n        self.motivational_map = {'not_motivational': 0, 'motivational': 1}\n    \n    def _map_label(self, value, mapping, default=0):\n        if pd.isna(value):\n            return default\n        if isinstance(value, str):\n            return mapping.get(value.lower().strip(), default)\n        return int(value)\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        \n        image_name = str(row[self.image_col])\n        if not any(image_name.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png']):\n            image_name = f\"{image_name}.jpg\"\n        image_path = os.path.join(self.image_dir, image_name)\n        \n        try:\n            image = Image.open(image_path).convert('RGB')\n            image = self.image_transform(image)\n        except:\n            image = torch.zeros(3, self.cfg['IMG_SIZE'], self.cfg['IMG_SIZE'])\n        \n        text = str(row.get(self.text_col, '')) if self.text_col else 'No text'\n        encoding = self.tokenizer(text, max_length=self.cfg['MAX_LEN'], padding='max_length', truncation=True, return_tensors='pt')\n        \n        sentiment_val = row.get(self.sentiment_col, 'neutral') if self.sentiment_col else 'neutral'\n        sentiment_label = self._map_label(sentiment_val, self.sentiment_map, default=2)\n        \n        emotion_labels = torch.tensor([\n            float(self._map_label(row.get('humour', row.get('humor', 0)), self.humor_map, 0)),\n            float(self._map_label(row.get('sarcastic', row.get('sarcasm', 0)), self.sarcasm_map, 0)),\n            float(self._map_label(row.get('offensive', 0), self.offensive_map, 0)),\n            float(self._map_label(row.get('motivational', 0), self.motivational_map, 0))\n        ], dtype=torch.float)\n        \n        return {\n            'input_ids': encoding['input_ids'].squeeze(0),\n            'attention_mask': encoding['attention_mask'].squeeze(0),\n            'image': image,\n            'sentiment_label': torch.tensor(sentiment_label, dtype=torch.long),\n            'emotion_labels': emotion_labels,\n            'intensity': torch.tensor(0.5, dtype=torch.float),\n            'motivational_flag': emotion_labels[3]\n        }\n\nprint(\"âœ“ Dataset class defined\")\n\n# ==================== PART 5: LOSS & METRICS ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 5: LOSS FUNCTIONS & METRICS\")\nprint(\"=\" * 80)\n\ndef ordinal_regression_loss(cumulative_logits, labels):\n    batch_size = labels.size(0)\n    num_thresholds = cumulative_logits.size(1)\n    target_cumulative = torch.zeros_like(cumulative_logits)\n    \n    for i in range(batch_size):\n        y = int(labels[i].item())\n        if y < num_thresholds:\n            target_cumulative[i, y:] = 1.0\n    \n    return F.binary_cross_entropy_with_logits(cumulative_logits, target_cumulative, reduction='mean')\n\ndef combined_loss(outputs, batch, cfg, emotion_loss_fn):\n    loss_sent = ordinal_regression_loss(outputs['sentiment']['cumulative_logits'], batch['sentiment_label'])\n    loss_emotion = emotion_loss_fn(outputs['emotion_logits'], batch['emotion_labels'])\n    loss_intensity = F.smooth_l1_loss(outputs['intensity'], batch['intensity'])\n    \n    total_loss = (\n        cfg['LOSS_WEIGHTS']['sentiment'] * loss_sent +\n        cfg['LOSS_WEIGHTS']['emotion'] * loss_emotion +\n        cfg['LOSS_WEIGHTS']['intensity'] * loss_intensity\n    )\n    \n    return total_loss, loss_sent, loss_emotion, loss_intensity\n\ndef compute_metrics(sentiment_outputs, sentiment_labels, emotion_logits, emotion_labels, thresholds):\n    # Sentiment\n    class_probs = sentiment_outputs['class_probs']\n    y_pred = torch.argmax(class_probs, dim=1).cpu().numpy()\n    y_true = sentiment_labels.cpu().numpy()\n    \n    sent_acc = accuracy_score(y_true, y_pred)\n    _, _, sent_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)\n    sent_mae = mean_absolute_error(y_true, y_pred)\n    sent_1off = np.mean(np.abs(y_true - y_pred) <= 1)\n    \n    # Emotions\n    emo_probs = torch.sigmoid(emotion_logits).cpu().numpy()\n    emo_true = emotion_labels.cpu().numpy()\n    thresholds = np.array(thresholds)\n    emo_pred = (emo_probs >= thresholds).astype(float)\n    \n    _, _, emo_f1, _ = precision_recall_fscore_support(emo_true, emo_pred, average='samples', zero_division=0)\n    \n    return {\n        'sentiment_accuracy': sent_acc,\n        'sentiment_f1': sent_f1,\n        'sentiment_mae': sent_mae,\n        'sentiment_1off_accuracy': sent_1off,\n        'emotion_f1': emo_f1\n    }\n\nprint(\"âœ“ Loss functions and metrics defined\")\n\n# ==================== PART 6: TRAINER ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 6: TRAINER\")\nprint(\"=\" * 80)\n\nclass Trainer:\n    def __init__(self, model, cfg, train_loader, val_loader, device, emotion_loss_fn):\n        self.model = model\n        self.cfg = cfg\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.device = device\n        self.emotion_loss_fn = emotion_loss_fn\n        \n        self.optimizer = self.make_optimizer()\n        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=cfg['EPOCHS'])\n        self.scaler = GradScaler() if cfg['USE_AMP'] else None\n        self.best_metric = -float('inf')\n    \n    def make_optimizer(self):\n        head_params = []\n        backbone_params = []\n        \n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                if 'text_model' in name or 'image_model' in name:\n                    backbone_params.append(param)\n                else:\n                    head_params.append(param)\n        \n        param_groups = [{'params': head_params, 'lr': self.cfg['LR_HEADS']}]\n        if backbone_params:\n            param_groups.append({'params': backbone_params, 'lr': self.cfg['LR_BACKBONE']})\n        \n        return torch.optim.AdamW(param_groups, weight_decay=self.cfg['WEIGHT_DECAY'])\n    \n    def train_epoch(self, epoch):\n        self.model.train()\n        total_loss = 0.0\n        \n        pbar = tqdm(self.train_loader, desc=f\"Epoch {epoch+1}/{self.cfg['EPOCHS']} [Train]\")\n        self.optimizer.zero_grad()\n        \n        for batch_idx, batch in enumerate(pbar):\n            batch_device = {k: v.to(self.device) for k, v in batch.items() if k != 'motivational_flag'}\n            \n            if self.cfg['USE_AMP']:\n                with autocast():\n                    outputs = self.model(batch_device['input_ids'], batch_device['attention_mask'], batch_device['image'])\n                    loss, l_sent, l_emo, l_int = combined_loss(outputs, batch_device, self.cfg, self.emotion_loss_fn)\n                    loss = loss / self.cfg['GRADIENT_ACCUMULATION_STEPS']\n                \n                self.scaler.scale(loss).backward()\n                \n                if (batch_idx + 1) % self.cfg['GRADIENT_ACCUMULATION_STEPS'] == 0:\n                    if self.cfg['GRADIENT_CLIP'] > 0:\n                        self.scaler.unscale_(self.optimizer)\n                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.cfg['GRADIENT_CLIP'])\n                    self.scaler.step(self.optimizer)\n                    self.scaler.update()\n                    self.optimizer.zero_grad()\n            else:\n                outputs = self.model(batch_device['input_ids'], batch_device['attention_mask'], batch_device['image'])\n                loss, l_sent, l_emo, l_int = combined_loss(outputs, batch_device, self.cfg, self.emotion_loss_fn)\n                loss = loss / self.cfg['GRADIENT_ACCUMULATION_STEPS']\n                loss.backward()\n                \n                if (batch_idx + 1) % self.cfg['GRADIENT_ACCUMULATION_STEPS'] == 0:\n                    if self.cfg['GRADIENT_CLIP'] > 0:\n                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.cfg['GRADIENT_CLIP'])\n                    self.optimizer.step()\n                    self.optimizer.zero_grad()\n            \n            total_loss += loss.item() * self.cfg['GRADIENT_ACCUMULATION_STEPS']\n            pbar.set_postfix({'loss': f\"{loss.item() * self.cfg['GRADIENT_ACCUMULATION_STEPS']:.4f}\"})\n        \n        return total_loss / len(self.train_loader)\n    \n    def validate(self, epoch):\n        self.model.eval()\n        total_loss = 0.0\n        \n        all_sentiment_labels = []\n        all_sentiment_outputs = []\n        all_emotion_labels = []\n        all_emotion_logits = []\n        \n        with torch.no_grad():\n            for batch in tqdm(self.val_loader, desc=f\"Epoch {epoch+1} [Val]\"):\n                batch_device = {k: v.to(self.device) for k, v in batch.items() if k != 'motivational_flag'}\n                \n                outputs = self.model(batch_device['input_ids'], batch_device['attention_mask'], batch_device['image'])\n                loss, _, _, _ = combined_loss(outputs, batch_device, self.cfg, self.emotion_loss_fn)\n                total_loss += loss.item()\n                \n                all_sentiment_labels.append(batch_device['sentiment_label'].cpu())\n                all_sentiment_outputs.append({\n                    'cumulative_logits': outputs['sentiment']['cumulative_logits'].cpu(),\n                    'class_probs': outputs['sentiment']['class_probs'].cpu()\n                })\n                all_emotion_labels.append(batch_device['emotion_labels'].cpu())\n                all_emotion_logits.append(outputs['emotion_logits'].cpu())\n        \n        all_sentiment_labels = torch.cat(all_sentiment_labels)\n        combined_sentiment = {\n            'cumulative_logits': torch.cat([o['cumulative_logits'] for o in all_sentiment_outputs]),\n            'class_probs': torch.cat([o['class_probs'] for o in all_sentiment_outputs])\n        }\n        all_emotion_labels = torch.cat(all_emotion_labels)\n        all_emotion_logits = torch.cat(all_emotion_logits)\n        \n        metrics = compute_metrics(combined_sentiment, all_sentiment_labels, all_emotion_logits, \n                                 all_emotion_labels, self.cfg['EMO_THRESHOLDS'])\n        \n        avg_loss = total_loss / len(self.val_loader)\n        \n        print(f\"\\n{'='*70}\")\n        print(f\"Validation Results (Epoch {epoch+1}):\")\n        print(f\"  Loss: {avg_loss:.4f}\")\n        print(f\"  Sentiment Accuracy: {metrics['sentiment_accuracy']:.4f}\")\n        print(f\"  Sentiment F1: {metrics['sentiment_f1']:.4f}\")\n        print(f\"  Sentiment MAE: {metrics['sentiment_mae']:.4f}\")\n        print(f\"  Sentiment 1-off Acc: {metrics['sentiment_1off_accuracy']:.4f}\")\n        print(f\"  Emotion F1: {metrics['emotion_f1']:.4f}\")\n        print(f\"{'='*70}\\n\")\n        \n        return {**metrics, 'val_loss': avg_loss}\n    \n    def fit(self):\n        print(f\"\\n{'='*70}\")\n        print(f\"STARTING TRAINING: {self.cfg['EPOCHS']} EPOCHS\")\n        print(f\"{'='*70}\\n\")\n        \n        for epoch in range(self.cfg['EPOCHS']):\n            # Early backbone unfreezing\n            if epoch == self.cfg['UNFREEZE_BACKBONE_EPOCH']:\n                print(f\"\\n{'='*70}\")\n                print(f\"ðŸ”“ UNFREEZING BACKBONE at epoch {epoch+1}\")\n                print(f\"{'='*70}\\n\")\n                self.model.unfreeze_backbone(layers_to_unfreeze=self.cfg['UNFREEZE_LAYERS'])\n                self.optimizer = self.make_optimizer()\n                self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=self.cfg['EPOCHS'])\n            \n            train_loss = self.train_epoch(epoch)\n            print(f\"\\nTrain Loss: {train_loss:.4f}\")\n            \n            val_metrics = self.validate(epoch)\n            \n            if self.scheduler:\n                self.scheduler.step()\n            \n            # Composite metric (emphasis on emotion F1)\n            composite = (\n                val_metrics['sentiment_f1'] +\n                val_metrics['sentiment_1off_accuracy'] -\n                val_metrics['sentiment_mae'] +\n                val_metrics['emotion_f1'] * 1.5\n            )\n            \n            if composite > self.best_metric:\n                self.best_metric = composite\n                os.makedirs(self.cfg['CHECKPOINT_PATH'], exist_ok=True)\n                checkpoint_path = os.path.join(self.cfg['CHECKPOINT_PATH'], 'best_model_enhanced.pt')\n                torch.save({\n                    'epoch': epoch,\n                    'model_state_dict': self.model.state_dict(),\n                    'optimizer_state_dict': self.optimizer.state_dict(),\n                    'best_metric': self.best_metric,\n                    'metrics': val_metrics,\n                    'config': self.cfg\n                }, checkpoint_path)\n                print(f\"âœ“ Saved best model (composite: {composite:.4f})\")\n        \n        print(\"\\nâœ… TRAINING COMPLETED!\")\n        return self.best_metric\n\nprint(\"âœ“ Trainer class defined\")\n\n# ==================== PART 7: DATA LOADING ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 7: DATA LOADING & PREPARATION\")\nprint(\"=\" * 80)\n\n# Initialize tokenizer and transforms\ntokenizer = AutoTokenizer.from_pretrained(cfg['TEXT_MODEL'])\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((cfg['IMG_SIZE'], cfg['IMG_SIZE'])),\n    transforms.RandomHorizontalFlip(p=0.3),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n                       std=[0.26862954, 0.26130258, 0.27577711])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((cfg['IMG_SIZE'], cfg['IMG_SIZE'])),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n                       std=[0.26862954, 0.26130258, 0.27577711])\n])\n\nprint(\"âœ“ Tokenizer and transforms initialized\")\n\n# Create datasets\ntrain_dataset = MemeDataset(train_df, tokenizer, train_transform, NEW_TRAIN_DIR, cfg)\nval_dataset = MemeDataset(val_df, tokenizer, val_transform, NEW_VAL_DIR, cfg)\n\nprint(f\"âœ“ Train dataset: {len(train_dataset)} samples\")\nprint(f\"âœ“ Val dataset: {len(val_dataset)} samples\")\n\n# Create weighted sampler for motivational oversampling\nprint(\"\\nCreating weighted sampler...\")\nsample_weights = []\nmotivational_count = 0\n\nfor idx in range(len(train_dataset)):\n    item = train_dataset[idx]\n    is_motivational = int(item['motivational_flag'].item())\n    \n    if is_motivational:\n        weight = cfg['MOTIVATIONAL_OVERSAMPLE_FACTOR']\n        motivational_count += 1\n    else:\n        weight = 1.0\n    \n    sample_weights.append(weight)\n\nprint(f\"  Motivational samples: {motivational_count} ({motivational_count/len(train_dataset)*100:.2f}%)\")\nprint(f\"  Oversampling factor: {cfg['MOTIVATIONAL_OVERSAMPLE_FACTOR']}x\")\nprint(f\"  Effective representation: {motivational_count * cfg['MOTIVATIONAL_OVERSAMPLE_FACTOR'] / len(train_dataset) * 100:.1f}%\")\n\nsampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n\n# Create dataloaders\ntrain_loader = DataLoader(\n    train_dataset, batch_size=cfg['BATCH_SIZE'], sampler=sampler,\n    num_workers=2, pin_memory=True, drop_last=True\n)\n\nval_loader = DataLoader(\n    val_dataset, batch_size=cfg['BATCH_SIZE'], shuffle=False,\n    num_workers=2, pin_memory=True\n)\n\nprint(f\"âœ“ Train batches: {len(train_loader)}\")\nprint(f\"âœ“ Val batches: {len(val_loader)}\")\n\n# ==================== PART 8: MODEL INITIALIZATION & TRAINING ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 8: MODEL INITIALIZATION\")\nprint(\"=\" * 80)\n\nmodel = EnhancedFusionModel(cfg).to(device)\n\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f\"\\nModel Statistics:\")\nprint(f\"  Total parameters: {total_params:,}\")\nprint(f\"  Trainable parameters: {trainable_params:,}\")\nprint(f\"  Frozen parameters: {total_params - trainable_params:,}\")\n\n# Initialize enhanced emotion loss\nemotion_loss_fn = EnhancedAsymmetricLoss(\n    gamma_neg=cfg['ASL_GAMMA_NEG'],\n    gamma_pos=cfg['ASL_GAMMA_POS'],\n    clip=cfg['ASL_CLIP'],\n    priors=cfg['EMO_PRIORS'],\n    prior_tau=cfg['ASL_PRIOR_TAU']\n)\n\nprint(f\"\\nâœ“ Enhanced ASL initialized:\")\nprint(f\"  Î³_neg={cfg['ASL_GAMMA_NEG']}, Î³_pos={cfg['ASL_GAMMA_POS']}\")\nprint(f\"  Prior adjustment: Ï„={cfg['ASL_PRIOR_TAU']}\")\nprint(f\"  Priors: {[f'{p:.3f}' for p in cfg['EMO_PRIORS']]}\")\n\n# Initialize trainer\ntrainer = Trainer(model, cfg, train_loader, val_loader, device, emotion_loss_fn)\n\nprint(\"\\nâœ“ Trainer initialized\")\n\n# ==================== START TRAINING ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"STARTING TRAINING\")\nprint(\"=\" * 80)\n\nbest_metric = trainer.fit()\n\nprint(f\"\\n{'='*80}\")\nprint(f\"âœ… TRAINING COMPLETED!\")\nprint(f\"{'='*80}\")\nprint(f\"Best composite metric: {best_metric:.4f}\")\nprint(f\"Model saved to: {cfg['CHECKPOINT_PATH']}/best_model_enhanced.pt\")\n\n# Generate model card\nmodel_card = f\"\"\"# Enhanced Multi-modal Meme Analysis Model\n\n## Overview\nThis model uses a hybrid loss strategy combining ordinal regression for sentiment \nand enhanced asymmetric loss (ASL) with prior adjustment for emotions.\n\n## Key Improvements\n\n### 1. Hybrid Loss Strategy\n- **Sentiment**: Ordinal regression respects natural class ordering\n- **Emotions**: Enhanced ASL with positive focusing (Î³_pos={cfg['ASL_GAMMA_POS']}) \n  and prior adjustment (Ï„={cfg['ASL_PRIOR_TAU']})\n- **Intensity**: Smooth L1 loss\n\n### 2. Motivational Oversampling\n- Factor: {cfg['MOTIVATIONAL_OVERSAMPLE_FACTOR']}x\n- Original representation: {motivational_count/len(train_dataset)*100:.2f}%\n- Effective representation: {motivational_count * cfg['MOTIVATIONAL_OVERSAMPLE_FACTOR'] / len(train_dataset) * 100:.1f}%\n\n### 3. Early Backbone Unfreezing\n- Unfreezes at epoch {cfg['UNFREEZE_BACKBONE_EPOCH']}\n- Layers unfrozen: {cfg['UNFREEZE_LAYERS']}\n\n## Architecture\n- **Text**: {cfg['TEXT_MODEL']}\n- **Image**: {cfg['IMAGE_MODEL']}\n- **Fusion**: Bidirectional cross-attention\n- **Params**: {total_params:,} total, {trainable_params:,} trainable\n\n## Training Details\n- Epochs: {cfg['EPOCHS']}\n- Batch size: {cfg['BATCH_SIZE']}\n- LR (heads): {cfg['LR_HEADS']}\n- LR (backbone): {cfg['LR_BACKBONE']}\n- Loss weights: Sentiment={cfg['LOSS_WEIGHTS']['sentiment']}, \n  Emotion={cfg['LOSS_WEIGHTS']['emotion']}, Intensity={cfg['LOSS_WEIGHTS']['intensity']}\n\n## Performance\n- Best composite metric: {best_metric:.4f}\n\n## Dataset\n- Training samples: {len(train_df):,}\n- Validation samples: {len(val_df):,}\n\n## Usage\n\n```python\ncheckpoint = torch.load('best_model_enhanced.pt')\nmodel = EnhancedFusionModel(checkpoint['config']).to(device)\nmodel.load_state_dict(checkpoint['model_state_dict'])\nmodel.eval()\n\nwith torch.no_grad():\n    outputs = model(input_ids, attention_mask, image)\n    sentiment = outputs['sentiment']['class_probs']\n    emotions = torch.sigmoid(outputs['emotion_logits'])\n```\n\"\"\"\n\nmodel_card_path = os.path.join(cfg['CHECKPOINT_PATH'], 'model_card.md')\nwith open(model_card_path, 'w') as f:\n    f.write(model_card)\n\nprint(f\"\\nâœ“ Model card saved to: {model_card_path}\")\nprint(f\"\\n{'='*80}\")\nprint(\"ALL DONE! ðŸŽ‰\")\nprint(f\"{'='*80}\\n\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-20T21:48:54.746555Z","iopub.execute_input":"2025-11-20T21:48:54.747215Z","iopub.status.idle":"2025-11-20T22:10:20.841547Z","shell.execute_reply.started":"2025-11-20T21:48:54.747179Z","shell.execute_reply":"2025-11-20T22:10:20.840581Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nINSTALLING DEPENDENCIES...\n================================================================================\n","output_type":"stream"},{"name":"stderr","text":"2025-11-20 21:49:04.146254: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763675344.168900     202 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763675344.175760     202 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"âœ“ All dependencies installed\n\n================================================================================\nPART 1: DATA PREPARATION\n================================================================================\n\nDownloading dataset...\nExtracting dataset...\nExtracting protected archive...\nâœ“ Extracted to: /kaggle/working/\n\nLoading CSV file...\nâœ“ Image column: Unnamed: 0\n\nâœ“ Stratified split complete:\n  Training: 5950 samples\n  Validation: 1050 samples\n\nâœ“ Label priors calculated:\n  offensive_pos_rate: 0.3909\n  motivational_pos_rate: 0.1187\n  humor_pos_rate: 0.8558\n  sarcasm_pos_rate: 0.7891\n\nCopying images...\n","output_type":"stream"},{"name":"stderr","text":"Copying to /kaggle/working/validation_images/: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1050/1050 [00:00<00:00, 5463.37it/s]\nCopying to /kaggle/working/new_train_images/: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5950/5950 [00:01<00:00, 5799.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ“ Validation: 1050 copied, 0 missing\nâœ“ Training: 5950 copied, 0 missing\n\nâœ“ Saved train CSV: /kaggle/working/train_split.csv\nâœ“ Saved validation CSV: /kaggle/working/validation_split.csv\n\nâœ… DATA PREPARATION COMPLETE\n\n================================================================================\nPART 2: CONFIGURATION\n================================================================================\n\nâœ“ Configuration loaded:\n  Device: cuda\n  Epochs: 20\n  Batch size: 16\n  Motivational oversampling: 8.0x\n  Emotion priors: ['0.856', '0.789', '0.391', '0.119']\n\n================================================================================\nPART 3: MODEL COMPONENTS\n================================================================================\nâœ“ Model components defined\n\n================================================================================\nPART 4: DATASET\n================================================================================\nâœ“ Dataset class defined\n\n================================================================================\nPART 5: LOSS FUNCTIONS & METRICS\n================================================================================\nâœ“ Loss functions and metrics defined\n\n================================================================================\nPART 6: TRAINER\n================================================================================\nâœ“ Trainer class defined\n\n================================================================================\nPART 7: DATA LOADING & PREPARATION\n================================================================================\nâœ“ Tokenizer and transforms initialized\nâœ“ Train dataset: 5950 samples\nâœ“ Val dataset: 1050 samples\n\nCreating weighted sampler...\n  Motivational samples: 706 (11.87%)\n  Oversampling factor: 8.0x\n  Effective representation: 94.9%\nâœ“ Train batches: 371\nâœ“ Val batches: 66\n\n================================================================================\nPART 8: MODEL INITIALIZATION\n================================================================================\n\nModel Statistics:\n  Total parameters: 333,224,714\n  Trainable parameters: 8,212,490\n  Frozen parameters: 325,012,224\n\nâœ“ Enhanced ASL initialized:\n  Î³_neg=6.0, Î³_pos=0.5\n  Prior adjustment: Ï„=1.2\n  Priors: ['0.856', '0.789', '0.391', '0.119']\n\nâœ“ Trainer initialized\n\n================================================================================\nSTARTING TRAINING\n================================================================================\n\n======================================================================\nSTARTING TRAINING: 20 EPOCHS\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 1/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:38<00:00,  9.57it/s, loss=0.9950]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 1.1381\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 1 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 1):\n  Loss: 1.0792\n  Sentiment Accuracy: 0.1524\n  Sentiment F1: 0.1141\n  Sentiment MAE: 1.4781\n  Sentiment 1-off Acc: 0.5200\n  Emotion F1: 0.7725\n======================================================================\n\nâœ“ Saved best model (composite: 0.3147)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 2/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:37<00:00,  9.83it/s, loss=0.9703]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 1.0789\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 2 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 2):\n  Loss: 1.0800\n  Sentiment Accuracy: 0.2533\n  Sentiment F1: 0.1556\n  Sentiment MAE: 1.0990\n  Sentiment 1-off Acc: 0.7019\n  Emotion F1: 0.7721\n======================================================================\n\nâœ“ Saved best model (composite: 0.9165)\n\n======================================================================\nðŸ”“ UNFREEZING BACKBONE at epoch 3\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 3/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:53<00:00,  6.88it/s, loss=0.8796]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 1.0138\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 3 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 3):\n  Loss: 1.1298\n  Sentiment Accuracy: 0.2733\n  Sentiment F1: 0.1728\n  Sentiment MAE: 1.1486\n  Sentiment 1-off Acc: 0.6667\n  Emotion F1: 0.7724\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 4/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:53<00:00,  6.89it/s, loss=0.7981]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.8568\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 4 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 4):\n  Loss: 1.0088\n  Sentiment Accuracy: 0.3686\n  Sentiment F1: 0.2045\n  Sentiment MAE: 0.8781\n  Sentiment 1-off Acc: 0.7981\n  Emotion F1: 0.7725\n======================================================================\n\nâœ“ Saved best model (composite: 1.2832)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 5/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.85it/s, loss=1.1279]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.7734\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 5 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 5):\n  Loss: 1.0306\n  Sentiment Accuracy: 0.3743\n  Sentiment F1: 0.1956\n  Sentiment MAE: 0.8495\n  Sentiment 1-off Acc: 0.8190\n  Emotion F1: 0.7721\n======================================================================\n\nâœ“ Saved best model (composite: 1.3233)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 6/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.82it/s, loss=0.6593]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.7128\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 6 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 6):\n  Loss: 0.9872\n  Sentiment Accuracy: 0.4276\n  Sentiment F1: 0.1934\n  Sentiment MAE: 0.7048\n  Sentiment 1-off Acc: 0.8790\n  Emotion F1: 0.7721\n======================================================================\n\nâœ“ Saved best model (composite: 1.5258)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 7/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.84it/s, loss=0.7044]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.6817\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 7 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 7):\n  Loss: 1.0010\n  Sentiment Accuracy: 0.4114\n  Sentiment F1: 0.2067\n  Sentiment MAE: 0.7562\n  Sentiment 1-off Acc: 0.8562\n  Emotion F1: 0.7723\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 8/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.86it/s, loss=0.6159]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.6349\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 8 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 8):\n  Loss: 1.0518\n  Sentiment Accuracy: 0.3781\n  Sentiment F1: 0.1987\n  Sentiment MAE: 0.8686\n  Sentiment 1-off Acc: 0.8048\n  Emotion F1: 0.7719\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 9/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.86it/s, loss=0.6831]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.6123\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 9 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 9):\n  Loss: 1.0411\n  Sentiment Accuracy: 0.3990\n  Sentiment F1: 0.1990\n  Sentiment MAE: 0.8067\n  Sentiment 1-off Acc: 0.8343\n  Emotion F1: 0.7718\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 10/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.86it/s, loss=0.4957]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.5884\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 10 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 10):\n  Loss: 1.0069\n  Sentiment Accuracy: 0.4124\n  Sentiment F1: 0.2019\n  Sentiment MAE: 0.7438\n  Sentiment 1-off Acc: 0.8648\n  Emotion F1: 0.7723\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 11/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.86it/s, loss=0.5324]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.5470\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 11 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 11):\n  Loss: 1.0307\n  Sentiment Accuracy: 0.3924\n  Sentiment F1: 0.1944\n  Sentiment MAE: 0.8076\n  Sentiment 1-off Acc: 0.8352\n  Emotion F1: 0.7723\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 12/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.85it/s, loss=0.5565]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.5366\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 12 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 12):\n  Loss: 1.0420\n  Sentiment Accuracy: 0.3886\n  Sentiment F1: 0.2020\n  Sentiment MAE: 0.8333\n  Sentiment 1-off Acc: 0.8210\n  Emotion F1: 0.7725\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 13/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.86it/s, loss=0.7034]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.5215\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 13 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 13):\n  Loss: 1.0205\n  Sentiment Accuracy: 0.4076\n  Sentiment F1: 0.1921\n  Sentiment MAE: 0.7686\n  Sentiment 1-off Acc: 0.8495\n  Emotion F1: 0.7723\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 14/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.85it/s, loss=0.5655]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4980\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 14 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 14):\n  Loss: 1.0112\n  Sentiment Accuracy: 0.4248\n  Sentiment F1: 0.2011\n  Sentiment MAE: 0.7057\n  Sentiment 1-off Acc: 0.8829\n  Emotion F1: 0.7723\n======================================================================\n\nâœ“ Saved best model (composite: 1.5367)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 15/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.86it/s, loss=0.4832]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4759\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 15 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 15):\n  Loss: 1.0116\n  Sentiment Accuracy: 0.4219\n  Sentiment F1: 0.2154\n  Sentiment MAE: 0.7133\n  Sentiment 1-off Acc: 0.8810\n  Emotion F1: 0.7721\n======================================================================\n\nâœ“ Saved best model (composite: 1.5412)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 16/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.85it/s, loss=0.4140]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4620\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 16 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 16):\n  Loss: 1.0295\n  Sentiment Accuracy: 0.4229\n  Sentiment F1: 0.2226\n  Sentiment MAE: 0.7181\n  Sentiment 1-off Acc: 0.8752\n  Emotion F1: 0.7723\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 17/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.85it/s, loss=0.6387]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4498\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 17 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 17):\n  Loss: 1.0208\n  Sentiment Accuracy: 0.4390\n  Sentiment F1: 0.2266\n  Sentiment MAE: 0.7000\n  Sentiment 1-off Acc: 0.8771\n  Emotion F1: 0.7725\n======================================================================\n\nâœ“ Saved best model (composite: 1.5625)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 18/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.86it/s, loss=0.4542]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4430\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 18 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 18):\n  Loss: 1.0401\n  Sentiment Accuracy: 0.4343\n  Sentiment F1: 0.2351\n  Sentiment MAE: 0.7057\n  Sentiment 1-off Acc: 0.8762\n  Emotion F1: 0.7723\n======================================================================\n\nâœ“ Saved best model (composite: 1.5640)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 19/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:53<00:00,  6.87it/s, loss=0.4440]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4292\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 19 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 19):\n  Loss: 1.0500\n  Sentiment Accuracy: 0.4390\n  Sentiment F1: 0.2273\n  Sentiment MAE: 0.6943\n  Sentiment 1-off Acc: 0.8800\n  Emotion F1: 0.7723\n======================================================================\n\nâœ“ Saved best model (composite: 1.5714)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 20/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.85it/s, loss=0.3672]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4199\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 20 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.40it/s]","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 20):\n  Loss: 1.0659\n  Sentiment Accuracy: 0.4371\n  Sentiment F1: 0.2295\n  Sentiment MAE: 0.7048\n  Sentiment 1-off Acc: 0.8752\n  Emotion F1: 0.7723\n======================================================================\n\n\nâœ… TRAINING COMPLETED!\n\n================================================================================\nâœ… TRAINING COMPLETED!\n================================================================================\nBest composite metric: 1.5714\nModel saved to: /kaggle/working/checkpoints/best_model_enhanced.pt\n\nâœ“ Model card saved to: /kaggle/working/checkpoints/model_card.md\n\n================================================================================\nALL DONE! ðŸŽ‰\n================================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ==================== PART 9: INFERENCE & EVALUATION ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 9: INFERENCE & COMPREHENSIVE EVALUATION\")\nprint(\"=\" * 80)\n\nclass Predictor:\n    \"\"\"Inference class for the enhanced model\"\"\"\n    def __init__(self, checkpoint_path, device='cuda'):\n        # Handle both string and torch.device inputs\n        if isinstance(device, torch.device):\n            self.device = device if torch.cuda.is_available() else torch.device('cpu')\n        else:\n            self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n        \n        print(f\"Loading checkpoint from: {checkpoint_path}\")\n        # IMPORTANT: weights_only=False to avoid UnpicklingError in PyTorch 2.6+\n        checkpoint = torch.load(\n            checkpoint_path,\n            map_location=self.device,\n            weights_only=False\n        )\n        self.cfg = checkpoint['config']\n\n        # ---------- SAFE DEFAULTS / BACKWARD COMPATIBILITY ----------\n        # Default sentiment mapping (index -> label)\n        default_sentiment_map = {\n            0: \"very_positive\",\n            1: \"positive\",\n            2: \"neutral\",\n            3: \"negative\",\n            4: \"very_negative\"\n        }\n        sentiment_map_cfg = self.cfg.get('SENTIMENT_MAP_REV', default_sentiment_map)\n\n        # Normalize keys to int in case YAML stored them as strings\n        self.sentiment_map = {int(k): v for k, v in sentiment_map_cfg.items()}\n\n        # Emotion labels and thresholds\n        self.emotion_labels = self.cfg.get('EMOTION_LABELS', [\"humor\", \"sarcasm\", \"offensive\", \"motivational\"])\n        self.emotion_thresholds = self.cfg.get('EMO_THRESHOLDS', [0.5, 0.5, 0.60, 0.60])\n\n        print(\"Initializing model...\")\n        self.model = EnhancedFusionModel(self.cfg).to(self.device)\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        self.model.eval()\n        \n        print(\"Loading tokenizer...\")\n        self.tokenizer = AutoTokenizer.from_pretrained(self.cfg['TEXT_MODEL'])\n        \n        self.transform = transforms.Compose([\n            transforms.Resize((self.cfg['IMG_SIZE'], self.cfg['IMG_SIZE'])),\n            transforms.ToTensor(),\n            transforms.Normalize(\n                mean=[0.48145466, 0.4578275, 0.40821073],\n                std=[0.26862954, 0.26130258, 0.27577711]\n            )\n        ])\n        \n        print(f\"âœ“ Predictor ready on {self.device}\")\n    \n    def predict(self, text, image_path):\n        \"\"\"Predict sentiment and emotions for a single sample\"\"\"\n        # Tokenize text\n        encoding = self.tokenizer(\n            text,\n            max_length=self.cfg['MAX_LEN'],\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        input_ids = encoding['input_ids'].to(self.device)\n        attention_mask = encoding['attention_mask'].to(self.device)\n        \n        # Load and transform image\n        try:\n            image = Image.open(image_path).convert('RGB')\n            image_tensor = self.transform(image).unsqueeze(0).to(self.device)\n        except Exception as e:\n            print(f\"âš  Could not load image: {image_path} ({e})\")\n            image_tensor = torch.zeros(\n                1, 3,\n                self.cfg['IMG_SIZE'],\n                self.cfg['IMG_SIZE']\n            ).to(self.device)\n        \n        # Predict\n        with torch.no_grad():\n            outputs = self.model(input_ids, attention_mask, image_tensor)\n        \n        # ----- Sentiment -----\n        class_probs = outputs['sentiment']['class_probs'].squeeze(0).cpu().numpy()\n        sentiment_pred = int(np.argmax(class_probs))\n        sentiment_label = self.sentiment_map.get(sentiment_pred, str(sentiment_pred))\n        expected_class = float(np.sum(class_probs * np.arange(len(class_probs))))\n        \n        sentiment_probs_dict = {\n            self.sentiment_map.get(i, str(i)): f\"{p:.2%}\"\n            for i, p in enumerate(class_probs)\n        }\n        \n        # ----- Emotions -----\n        emotion_logits = outputs['emotion_logits'].squeeze(0).cpu().numpy()\n        emotion_probs = 1 / (1 + np.exp(-emotion_logits))\n        emotion_preds = (emotion_probs >= np.array(self.emotion_thresholds)).astype(int)\n        \n        emotion_results = {\n            label: {\n                'probability': f\"{prob:.2%}\",\n                'predicted': bool(pred),\n                'threshold': f\"{thr:.3f}\"\n            }\n            for label, prob, pred, thr in zip(\n                self.emotion_labels, emotion_probs, emotion_preds, self.emotion_thresholds\n            )\n        }\n        \n        # ----- Intensity -----\n        intensity = float(outputs['intensity'].squeeze().cpu().item())\n        \n        return {\n            'sentiment': sentiment_label,\n            'sentiment_confidence': f\"{class_probs[sentiment_pred]:.2%}\",\n            'sentiment_expected_class': f\"{expected_class:.2f}\",\n            'sentiment_probs': sentiment_probs_dict,\n            'emotions': emotion_results,\n            'intensity': f\"{intensity:.4f}\"\n        }\n\n\n# Initialize predictor\ncheckpoint_path = os.path.join(cfg['CHECKPOINT_PATH'], 'best_model_enhanced.pt')\nif os.path.exists(checkpoint_path):\n    predictor = Predictor(checkpoint_path, device=device)\n    \n    # ==================== SAMPLE PREDICTIONS ====================\n    print(\"\\n\" + \"=\" * 80)\n    print(\"SAMPLE PREDICTIONS\")\n    print(\"=\" * 80)\n    \n    # Detect columns\n    image_col = next(\n        (c for c in ['image_name', 'image', 'img_name', 'filename', 'Unnamed: 0']\n         if c in val_df.columns),\n        val_df.columns[0]\n    )\n    text_col = next(\n        (c for c in ['text', 'ocr_text', 'caption', 'OCR_extracted_text']\n         if c in val_df.columns),\n        None\n    )\n    \n    # Random samples\n    random.seed(42)\n    sample_indices = random.sample(range(len(val_df)), min(5, len(val_df)))\n    \n    for idx in sample_indices:\n        row = val_df.iloc[idx]\n        sample_text = str(row.get(text_col, '')) if text_col else ''\n        sample_image_name = str(row.get(image_col, f'{idx}.jpg'))\n        \n        if not any(sample_image_name.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png']):\n            sample_image_name = f\"{sample_image_name}.jpg\"\n        \n        sample_image_path = os.path.join(NEW_VAL_DIR, sample_image_name)\n        \n        if not os.path.exists(sample_image_path):\n            print(f\"\\nâš  Image not found: {sample_image_path}\")\n            continue\n        \n        print(f\"\\n{'='*70}\")\n        print(f\"Sample {idx}:\")\n        print(f\"  Text: '{sample_text[:150]}...'\")\n        print(f\"  Image: {sample_image_name}\")\n        \n        result = predictor.predict(sample_text, sample_image_path)\n        \n        print(f\"\\nPredictions:\")\n        print(f\"  Sentiment: {result['sentiment']} (confidence: {result['sentiment_confidence']})\")\n        print(f\"  Expected class: {result['sentiment_expected_class']}\")\n        print(f\"  Sentiment distribution:\")\n        for sent, prob in result['sentiment_probs'].items():\n            print(f\"    {sent}: {prob}\")\n        print(f\"  Intensity: {result['intensity']}\")\n        print(f\"  Emotions:\")\n        for emotion, info in result['emotions'].items():\n            status = \"âœ“\" if info['predicted'] else \"âœ—\"\n            print(f\"    {status} {emotion.capitalize()}: {info['probability']} (threshold: {info['threshold']})\")\n    \n    # ==================== FULL EVALUATION ====================\n    print(\"\\n\" + \"=\" * 80)\n    print(\"FULL EVALUATION ON VALIDATION SET\")\n    print(\"=\" * 80)\n    \n    model.eval()\n    all_results = []\n    \n    with torch.no_grad():\n        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n            batch_device = {\n                k: v.to(device)\n                for k, v in batch.items()\n                if k != 'motivational_flag'\n            }\n            \n            outputs = model(\n                batch_device['input_ids'],\n                batch_device['attention_mask'],\n                batch_device['image']\n            )\n            \n            # Sentiment predictions\n            class_probs = outputs['sentiment']['class_probs'].cpu().numpy()\n            sentiment_preds = np.argmax(class_probs, axis=1)\n            expected_classes = np.sum(\n                class_probs * np.arange(class_probs.shape[1])[None, :],\n                axis=1\n            )\n            \n            # Emotion predictions\n            emotion_logits = outputs['emotion_logits'].cpu().numpy()\n            emotion_probs = 1 / (1 + np.exp(-emotion_logits))\n            emotion_preds = (emotion_probs >= np.array(cfg['EMO_THRESHOLDS'])).astype(int)\n            \n            # True labels\n            sentiment_true = batch_device['sentiment_label'].cpu().numpy()\n            emotion_true = batch_device['emotion_labels'].cpu().numpy()\n            \n            # Store results\n            for i in range(len(sentiment_preds)):\n                all_results.append({\n                    'sentiment_pred': int(sentiment_preds[i]),\n                    'sentiment_expected': float(expected_classes[i]),\n                    'sentiment_true': int(sentiment_true[i]),\n                    'emotion_pred': emotion_preds[i].tolist(),\n                    'emotion_true': emotion_true[i].tolist(),\n                    'emotion_probs': emotion_probs[i].tolist()\n                })\n    \n    # Create results dataframe\n    results_df = pd.DataFrame(all_results)\n\n    # Use sentiment map from config if available, else default\n    sentiment_map_for_eval = {\n        0: \"very_positive\",\n        1: \"positive\",\n        2: \"neutral\",\n        3: \"negative\",\n        4: \"very_negative\"\n    }\n    if 'SENTIMENT_MAP_REV' in cfg:\n        try:\n            sentiment_map_for_eval = {int(k): v for k, v in cfg['SENTIMENT_MAP_REV'].items()}\n        except Exception:\n            pass\n\n    results_df['sentiment_pred_label'] = results_df['sentiment_pred'].map(sentiment_map_for_eval)\n    results_df['sentiment_true_label'] = results_df['sentiment_true'].map(sentiment_map_for_eval)\n    results_df['sentiment_error'] = np.abs(results_df['sentiment_pred'] - results_df['sentiment_true'])\n    results_df['sentiment_correct'] = results_df['sentiment_pred'] == results_df['sentiment_true']\n    results_df['sentiment_1off'] = results_df['sentiment_error'] <= 1\n    \n    print(\"\\n\" + \"=\" * 80)\n    print(\"OVERALL METRICS\")\n    print(\"=\" * 80)\n    \n    # Sentiment metrics\n    sent_acc = results_df['sentiment_correct'].mean()\n    sent_1off = results_df['sentiment_1off'].mean()\n    sent_mae = results_df['sentiment_error'].mean()\n    \n    print(f\"\\nSentiment:\")\n    print(f\"  Accuracy: {sent_acc:.4f}\")\n    print(f\"  1-off Accuracy: {sent_1off:.4f}\")\n    print(f\"  MAE: {sent_mae:.4f}\")\n    \n    # Per-class sentiment metrics\n    print(f\"\\nPer-Class Sentiment:\")\n    for label in sorted(results_df['sentiment_true_label'].dropna().unique()):\n        class_df = results_df[results_df['sentiment_true_label'] == label]\n        class_acc = class_df['sentiment_correct'].mean()\n        class_1off = class_df['sentiment_1off'].mean()\n        class_mae = class_df['sentiment_error'].mean()\n        print(\n            f\"  {label}: Acc={class_acc:.4f}, \"\n            f\"1-off={class_1off:.4f}, \"\n            f\"MAE={class_mae:.4f} (n={len(class_df)})\"\n        )\n    \n    # Emotion metrics\n    print(f\"\\nEmotions:\")\n    for i, emotion in enumerate(cfg['EMOTION_LABELS']):\n        true_labels = [row[i] for row in results_df['emotion_true']]\n        pred_labels = [row[i] for row in results_df['emotion_pred']]\n        \n        acc = accuracy_score(true_labels, pred_labels)\n        prec, rec, f1, _ = precision_recall_fscore_support(\n            true_labels, pred_labels,\n            average='binary',\n            zero_division=0\n        )\n        \n        print(f\"  {emotion.capitalize()}:\")\n        print(\n            f\"    Accuracy: {acc:.4f}, \"\n            f\"Precision: {prec:.4f}, \"\n            f\"Recall: {rec:.4f}, \"\n            f\"F1: {f1:.4f}\"\n        )\n    \n    # Save detailed results\n    results_csv_path = os.path.join(cfg['CHECKPOINT_PATH'], 'detailed_results.csv')\n    results_df.to_csv(results_csv_path, index=False)\n    print(f\"\\nâœ“ Detailed results saved to: {results_csv_path}\")\n\nelse:\n    print(f\"âš  Checkpoint not found: {checkpoint_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T22:34:22.394742Z","iopub.execute_input":"2025-11-20T22:34:22.395537Z","iopub.status.idle":"2025-11-20T22:34:33.627802Z","shell.execute_reply.started":"2025-11-20T22:34:22.395511Z","shell.execute_reply":"2025-11-20T22:34:33.626852Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nPART 9: INFERENCE & COMPREHENSIVE EVALUATION\n================================================================================\nLoading checkpoint from: /kaggle/working/checkpoints/best_model_enhanced.pt\nInitializing model...\nLoading tokenizer...\nâœ“ Predictor ready on cuda\n\n================================================================================\nSAMPLE PREDICTIONS\n================================================================================\n\n======================================================================\nSample 228:\n  Text: '...'\n  Image: 1708.jpg\n\nPredictions:\n  Sentiment: neutral (confidence: 57.59%)\n  Expected class: 2.01\n  Sentiment distribution:\n    very_positive: 4.82%\n    positive: 13.77%\n    neutral: 57.59%\n    negative: 22.92%\n    very_negative: 0.90%\n  Intensity: 0.4974\n  Emotions:\n    âœ“ Humor: 88.74% (threshold: 0.500)\n    âœ“ Sarcasm: 77.98% (threshold: 0.500)\n    âœ— Offensive: 41.95% (threshold: 0.600)\n    âœ— Motivational: 12.66% (threshold: 0.600)\n\n======================================================================\nSample 51:\n  Text: '...'\n  Image: 341.jpg\n\nPredictions:\n  Sentiment: positive (confidence: 35.93%)\n  Expected class: 1.00\n  Sentiment distribution:\n    very_positive: 33.43%\n    positive: 35.93%\n    neutral: 27.58%\n    negative: 2.96%\n    very_negative: 0.09%\n  Intensity: 0.4964\n  Emotions:\n    âœ“ Humor: 98.60% (threshold: 0.500)\n    âœ“ Sarcasm: 82.65% (threshold: 0.500)\n    âœ— Offensive: 34.46% (threshold: 0.600)\n    âœ— Motivational: 3.80% (threshold: 0.600)\n\n======================================================================\nSample 563:\n  Text: '...'\n  Image: 3810.jpg\n\nPredictions:\n  Sentiment: neutral (confidence: 45.27%)\n  Expected class: 1.44\n  Sentiment distribution:\n    very_positive: 16.65%\n    positive: 30.73%\n    neutral: 45.27%\n    negative: 7.12%\n    very_negative: 0.23%\n  Intensity: 0.4933\n  Emotions:\n    âœ“ Humor: 98.48% (threshold: 0.500)\n    âœ“ Sarcasm: 83.64% (threshold: 0.500)\n    âœ— Offensive: 33.70% (threshold: 0.600)\n    âœ— Motivational: 3.05% (threshold: 0.600)\n\n======================================================================\nSample 501:\n  Text: '...'\n  Image: 3415.jpg\n\nPredictions:\n  Sentiment: negative (confidence: 70.79%)\n  Expected class: 3.01\n  Sentiment distribution:\n    very_positive: 0.24%\n    positive: 0.84%\n    neutral: 12.19%\n    negative: 70.79%\n    very_negative: 15.94%\n  Intensity: 0.4961\n  Emotions:\n    âœ“ Humor: 73.72% (threshold: 0.500)\n    âœ“ Sarcasm: 77.77% (threshold: 0.500)\n    âœ— Offensive: 57.01% (threshold: 0.600)\n    âœ— Motivational: 14.78% (threshold: 0.600)\n\n======================================================================\nSample 457:\n  Text: '...'\n  Image: 3141.jpg\n\nPredictions:\n  Sentiment: negative (confidence: 70.38%)\n  Expected class: 3.05\n  Sentiment distribution:\n    very_positive: 0.21%\n    positive: 0.73%\n    neutral: 10.85%\n    negative: 70.38%\n    very_negative: 17.83%\n  Intensity: 0.4956\n  Emotions:\n    âœ“ Humor: 74.30% (threshold: 0.500)\n    âœ“ Sarcasm: 78.32% (threshold: 0.500)\n    âœ— Offensive: 57.87% (threshold: 0.600)\n    âœ— Motivational: 14.07% (threshold: 0.600)\n\n================================================================================\nFULL EVALUATION ON VALIDATION SET\n================================================================================\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEvaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.43it/s]","output_type":"stream"},{"name":"stdout","text":"\n================================================================================\nOVERALL METRICS\n================================================================================\n\nSentiment:\n  Accuracy: 0.4371\n  1-off Accuracy: 0.8752\n  MAE: 0.7048\n\nPer-Class Sentiment:\n  negative: Acc=0.2267, 1-off=0.9111, MAE=0.9111 (n=225)\n  neutral: Acc=0.8367, 1-off=0.9620, MAE=0.2013 (n=447)\n  positive: Acc=0.1053, 1-off=0.9404, MAE=0.9544 (n=285)\n  very_negative: Acc=0.0000, 1-off=0.2041, MAE=1.9184 (n=49)\n  very_positive: Acc=0.0909, 1-off=0.1364, MAE=1.7955 (n=44)\n\nEmotions:\n  Humor:\n    Accuracy: 0.8552, Precision: 0.8552, Recall: 1.0000, F1: 0.9220\n  Sarcasm:\n    Accuracy: 0.7895, Precision: 0.7895, Recall: 1.0000, F1: 0.8824\n  Offensive:\n    Accuracy: 0.6086, Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n  Motivational:\n    Accuracy: 0.8810, Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n\nâœ“ Detailed results saved to: /kaggle/working/checkpoints/detailed_results.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"print(\"\\n\" + \"=\" * 80)\nprint(\"PART 10: VISUALIZATION & ANALYSIS\")\nprint(\"=\" * 80)\n\nif os.path.exists(checkpoint_path) and 'results_df' in locals():\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n    \n    sns.set_style(\"whitegrid\")\n    \n    # Create analysis directory\n    analysis_dir = os.path.join(cfg['CHECKPOINT_PATH'], 'analysis')\n    os.makedirs(analysis_dir, exist_ok=True)\n    \n    # 1. SENTIMENT CONFUSION MATRIX\n    print(\"\\nGenerating sentiment confusion matrix...\")\n    sentiment_labels = sorted(results_df['sentiment_true_label'].unique())\n    cm = confusion_matrix(\n        results_df['sentiment_true_label'],\n        results_df['sentiment_pred_label'],\n        labels=sentiment_labels\n    )\n    \n    fig, ax = plt.subplots(figsize=(10, 8))\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=sentiment_labels)\n    disp.plot(cmap='Blues', ax=ax, xticks_rotation='vertical', values_format='d')\n    plt.title('Sentiment Classification Confusion Matrix\\n(Ordinal Regression)', fontsize=14, fontweight='bold')\n    plt.tight_layout()\n    cm_path = os.path.join(analysis_dir, 'sentiment_confusion_matrix.png')\n    plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n    plt.close()\n    print(f\"âœ“ Saved to: {cm_path}\")\n    \n    # 2. SENTIMENT ERROR DISTRIBUTION\n    print(\"\\nGenerating error distribution plot...\")\n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n    \n    # Error distance histogram\n    ax = axes[0]\n    error_counts = results_df['sentiment_error'].value_counts().sort_index()\n    ax.bar(error_counts.index, error_counts.values, color='coral', alpha=0.7, edgecolor='black')\n    ax.set_xlabel('Ordinal Distance Error', fontsize=12)\n    ax.set_ylabel('Count', fontsize=12)\n    ax.set_title('Distribution of Ordinal Errors', fontsize=13, fontweight='bold')\n    ax.grid(axis='y', alpha=0.3)\n    \n    # Cumulative error percentage\n    ax = axes[1]\n    cumulative_pct = np.cumsum([\n        (results_df['sentiment_error'] == i).sum() for i in range(5)\n    ]) / len(results_df) * 100\n    ax.plot(range(5), cumulative_pct, marker='o', linewidth=2, markersize=8, color='steelblue')\n    ax.set_xlabel('Maximum Allowed Error', fontsize=12)\n    ax.set_ylabel('Cumulative Percentage (%)', fontsize=12)\n    ax.set_title('Cumulative Error Tolerance', fontsize=13, fontweight='bold')\n    ax.set_xticks(range(5))\n    ax.grid(alpha=0.3)\n    ax.axhline(y=90, color='red', linestyle='--', alpha=0.5, label='90% threshold')\n    ax.legend()\n    \n    plt.tight_layout()\n    error_path = os.path.join(analysis_dir, 'error_distribution.png')\n    plt.savefig(error_path, dpi=300, bbox_inches='tight')\n    plt.close()\n    print(f\"âœ“ Saved to: {error_path}\")\n    \n    # 3. EMOTION PERFORMANCE\n    print(\"\\nGenerating emotion performance plots...\")\n    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n    \n    emotion_metrics = []\n    for i, emotion in enumerate(cfg['EMOTION_LABELS']):\n        true_labels = [row[i] for row in results_df['emotion_true']]\n        pred_labels = [row[i] for row in results_df['emotion_pred']]\n        probs = [row[i] for row in results_df['emotion_probs']]\n        \n        acc = accuracy_score(true_labels, pred_labels)\n        prec, rec, f1, _ = precision_recall_fscore_support(\n            true_labels, pred_labels, average='binary', zero_division=0\n        )\n        \n        emotion_metrics.append({\n            'emotion': emotion,\n            'accuracy': acc,\n            'precision': prec,\n            'recall': rec,\n            'f1': f1,\n            'positive_rate': np.mean(true_labels),\n            'pred_positive_rate': np.mean(pred_labels)\n        })\n    \n    emotion_df = pd.DataFrame(emotion_metrics)\n    \n    # Plot 1: Overall metrics\n    ax = axes[0, 0]\n    x = np.arange(len(cfg['EMOTION_LABELS']))\n    width = 0.2\n    ax.bar(x - 1.5*width, emotion_df['accuracy'], width, label='Accuracy', alpha=0.8)\n    ax.bar(x - 0.5*width, emotion_df['precision'], width, label='Precision', alpha=0.8)\n    ax.bar(x + 0.5*width, emotion_df['recall'], width, label='Recall', alpha=0.8)\n    ax.bar(x + 1.5*width, emotion_df['f1'], width, label='F1', alpha=0.8)\n    ax.set_xlabel('Emotion', fontsize=11)\n    ax.set_ylabel('Score', fontsize=11)\n    ax.set_title('Emotion Classification Metrics', fontsize=12, fontweight='bold')\n    ax.set_xticks(x)\n    ax.set_xticklabels([e.capitalize() for e in cfg['EMOTION_LABELS']], rotation=45, ha='right')\n    ax.legend()\n    ax.set_ylim([0, 1])\n    ax.grid(axis='y', alpha=0.3)\n    \n    # Plot 2: Class distribution\n    ax = axes[0, 1]\n    x = np.arange(len(cfg['EMOTION_LABELS']))\n    width = 0.35\n    ax.bar(x - width/2, emotion_df['positive_rate'] * 100, width, label='True', alpha=0.8)\n    ax.bar(x + width/2, emotion_df['pred_positive_rate'] * 100, width, label='Predicted', alpha=0.8)\n    ax.set_xlabel('Emotion', fontsize=11)\n    ax.set_ylabel('Positive Class (%)', fontsize=11)\n    ax.set_title('Class Distribution: True vs Predicted', fontsize=12, fontweight='bold')\n    ax.set_xticks(x)\n    ax.set_xticklabels([e.capitalize() for e in cfg['EMOTION_LABELS']], rotation=45, ha='right')\n    ax.legend()\n    ax.grid(axis='y', alpha=0.3)\n    \n    # Plot 3 & 4: Individual emotion confusion matrices\n    for idx, emotion in enumerate(cfg['EMOTION_LABELS'][:2]):\n        ax = axes[1, idx]\n        true_labels = [row[idx] for row in results_df['emotion_true']]\n        pred_labels = [row[idx] for row in results_df['emotion_pred']]\n        \n        cm = np.array([\n            [sum((t == 0) & (p == 0) for t, p in zip(true_labels, pred_labels)),\n             sum((t == 0) & (p == 1) for t, p in zip(true_labels, pred_labels))],\n            [sum((t == 1) & (p == 0) for t, p in zip(true_labels, pred_labels)),\n             sum((t == 1) & (p == 1) for t, p in zip(true_labels, pred_labels))]\n        ])\n        \n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n                   xticklabels=['Negative', 'Positive'],\n                   yticklabels=['Negative', 'Positive'])\n        ax.set_title(f'{emotion.capitalize()} Confusion Matrix', fontsize=11, fontweight='bold')\n        ax.set_ylabel('True')\n        ax.set_xlabel('Predicted')\n    \n    plt.tight_layout()\n    emotion_path = os.path.join(analysis_dir, 'emotion_performance.png')\n    plt.savefig(emotion_path, dpi=300, bbox_inches='tight')\n    plt.close()\n    print(f\"âœ“ Saved to: {emotion_path}\")\n    \n    # 4. WORST PREDICTIONS\n    print(\"\\nAnalyzing worst predictions...\")\n    worst_df = results_df.nlargest(20, 'sentiment_error')\n    \n    print(f\"\\nTop 10 Worst Sentiment Predictions:\")\n    print(\"=\" * 70)\n    for i, (idx, row) in enumerate(worst_df.head(10).iterrows(), 1):\n        print(f\"\\n{i}. Index: {idx}\")\n        print(f\"   True: {row['sentiment_true_label']} (class {row['sentiment_true']})\")\n        print(f\"   Predicted: {row['sentiment_pred_label']} (class {row['sentiment_pred']})\")\n        print(f\"   Error: {row['sentiment_error']:.0f} classes\")\n    \n    worst_csv_path = os.path.join(analysis_dir, 'worst_predictions.csv')\n    worst_df.to_csv(worst_csv_path, index=True)\n    print(f\"\\nâœ“ Worst predictions saved to: {worst_csv_path}\")\n    \n    # 5. SUMMARY REPORT\n    print(\"\\n\" + \"=\" * 80)\n    print(\"FINAL SUMMARY REPORT\")\n    print(\"=\" * 80)\n    \n    summary = {\n        'Total Samples': len(results_df),\n        'Sentiment Accuracy': results_df['sentiment_correct'].mean(),\n        'Sentiment 1-off Accuracy': results_df['sentiment_1off'].mean(),\n        'Sentiment MAE': results_df['sentiment_error'].mean(),\n    }\n    \n    for i, emotion in enumerate(cfg['EMOTION_LABELS']):\n        true_labels = [row[i] for row in results_df['emotion_true']]\n        pred_labels = [row[i] for row in results_df['emotion_pred']]\n        acc = accuracy_score(true_labels, pred_labels)\n        _, _, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average='binary', zero_division=0)\n        summary[f'{emotion.capitalize()} Accuracy'] = acc\n        summary[f'{emotion.capitalize()} F1'] = f1\n    \n    summary_df = pd.DataFrame([summary]).T\n    summary_df.columns = ['Value']\n    \n    print(\"\\nðŸ“Š SUMMARY METRICS:\")\n    print(summary_df.to_string())\n    \n    summary_path = os.path.join(analysis_dir, 'summary_metrics.csv')\n    summary_df.to_csv(summary_path)\n    print(f\"\\nâœ“ Summary saved to: {summary_path}\")\n    \n    print(\"\\n\" + \"=\" * 80)\n    print(\"âœ… ALL ANALYSIS COMPLETE!\")\n    print(\"=\" * 80)\n    print(f\"\\nGenerated files in {analysis_dir}:\")\n    print(\"  1. sentiment_confusion_matrix.png\")\n    print(\"  2. error_distribution.png\")\n    print(\"  3. emotion_performance.png\")\n    print(\"  4. worst_predictions.csv\")\n    print(\"  5. summary_metrics.csv\")\n    print(f\"\\nDetailed results: {results_csv_path}\")\n    print(f\"Model checkpoint: {checkpoint_path}\")\n    print(f\"Model card: {model_card_path}\")\n    print(\"\\n\" + \"=\" * 80)\n\nprint(\"\\nðŸŽ‰ COMPLETE PIPELINE FINISHED! ðŸŽ‰\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T22:35:09.362549Z","iopub.execute_input":"2025-11-20T22:35:09.362861Z","iopub.status.idle":"2025-11-20T22:35:12.996103Z","shell.execute_reply.started":"2025-11-20T22:35:09.362832Z","shell.execute_reply":"2025-11-20T22:35:12.995222Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nPART 10: VISUALIZATION & ANALYSIS\n================================================================================\n\nGenerating sentiment confusion matrix...\nâœ“ Saved to: /kaggle/working/checkpoints/analysis/sentiment_confusion_matrix.png\n\nGenerating error distribution plot...\nâœ“ Saved to: /kaggle/working/checkpoints/analysis/error_distribution.png\n\nGenerating emotion performance plots...\nâœ“ Saved to: /kaggle/working/checkpoints/analysis/emotion_performance.png\n\nAnalyzing worst predictions...\n\nTop 10 Worst Sentiment Predictions:\n======================================================================\n\n1. Index: 810\n   True: very_negative (class 4)\n   Predicted: very_positive (class 0)\n   Error: 4 classes\n\n2. Index: 23\n   True: negative (class 3)\n   Predicted: very_positive (class 0)\n   Error: 3 classes\n\n3. Index: 36\n   True: negative (class 3)\n   Predicted: very_positive (class 0)\n   Error: 3 classes\n\n4. Index: 97\n   True: negative (class 3)\n   Predicted: very_positive (class 0)\n   Error: 3 classes\n\n5. Index: 262\n   True: negative (class 3)\n   Predicted: very_positive (class 0)\n   Error: 3 classes\n\n6. Index: 284\n   True: negative (class 3)\n   Predicted: very_positive (class 0)\n   Error: 3 classes\n\n7. Index: 299\n   True: negative (class 3)\n   Predicted: very_positive (class 0)\n   Error: 3 classes\n\n8. Index: 326\n   True: very_negative (class 4)\n   Predicted: positive (class 1)\n   Error: 3 classes\n\n9. Index: 330\n   True: negative (class 3)\n   Predicted: very_positive (class 0)\n   Error: 3 classes\n\n10. Index: 479\n   True: negative (class 3)\n   Predicted: very_positive (class 0)\n   Error: 3 classes\n\nâœ“ Worst predictions saved to: /kaggle/working/checkpoints/analysis/worst_predictions.csv\n\n================================================================================\nFINAL SUMMARY REPORT\n================================================================================\n\nðŸ“Š SUMMARY METRICS:\n                                Value\nTotal Samples             1050.000000\nSentiment Accuracy           0.437143\nSentiment 1-off Accuracy     0.875238\nSentiment MAE                0.704762\nHumor Accuracy               0.855238\nHumor F1                     0.921971\nSarcasm Accuracy             0.789524\nSarcasm F1                   0.882384\nOffensive Accuracy           0.608571\nOffensive F1                 0.000000\nMotivational Accuracy        0.880952\nMotivational F1              0.000000\n\nâœ“ Summary saved to: /kaggle/working/checkpoints/analysis/summary_metrics.csv\n\n================================================================================\nâœ… ALL ANALYSIS COMPLETE!\n================================================================================\n\nGenerated files in /kaggle/working/checkpoints/analysis:\n  1. sentiment_confusion_matrix.png\n  2. error_distribution.png\n  3. emotion_performance.png\n  4. worst_predictions.csv\n  5. summary_metrics.csv\n\nDetailed results: /kaggle/working/checkpoints/detailed_results.csv\nModel checkpoint: /kaggle/working/checkpoints/best_model_enhanced.pt\nModel card: /kaggle/working/checkpoints/model_card.md\n\n================================================================================\n\nðŸŽ‰ COMPLETE PIPELINE FINISHED! ðŸŽ‰\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"print(\"\\n\" + \"=\" * 80)\nprint(\"PART 10: VISUALIZATION & ANALYSIS\")\nprint(\"=\" * 80)\n\nif os.path.exists(checkpoint_path) and 'results_df' in locals():\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    from sklearn.metrics import (\n        confusion_matrix,\n        ConfusionMatrixDisplay,\n        f1_score,\n        accuracy_score,\n        precision_recall_fscore_support\n    )\n    \n    sns.set_style(\"whitegrid\")\n    \n    # Create analysis directory\n    analysis_dir = os.path.join(cfg['CHECKPOINT_PATH'], 'analysis')\n    os.makedirs(analysis_dir, exist_ok=True)\n    \n    # 1. SENTIMENT CONFUSION MATRIX (TASK A)\n    print(\"\\nGenerating sentiment confusion matrix...\")\n    sentiment_labels = sorted(results_df['sentiment_true_label'].unique())\n    cm = confusion_matrix(\n        results_df['sentiment_true_label'],\n        results_df['sentiment_pred_label'],\n        labels=sentiment_labels\n    )\n    \n    fig, ax = plt.subplots(figsize=(10, 8))\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=sentiment_labels)\n    disp.plot(cmap='Blues', ax=ax, xticks_rotation='vertical', values_format='d')\n    plt.title('Sentiment Classification Confusion Matrix\\n(Ordinal Regression)', fontsize=14, fontweight='bold')\n    plt.tight_layout()\n    cm_path = os.path.join(analysis_dir, 'sentiment_confusion_matrix.png')\n    plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n    plt.close()\n    print(f\"âœ“ Saved to: {cm_path}\")\n    \n    # 2. SENTIMENT ERROR DISTRIBUTION\n    print(\"\\nGenerating error distribution plot...\")\n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n    \n    # Error distance histogram\n    ax = axes[0]\n    error_counts = results_df['sentiment_error'].value_counts().sort_index()\n    ax.bar(error_counts.index, error_counts.values, color='coral', alpha=0.7, edgecolor='black')\n    ax.set_xlabel('Ordinal Distance Error', fontsize=12)\n    ax.set_ylabel('Count', fontsize=12)\n    ax.set_title('Distribution of Ordinal Errors', fontsize=13, fontweight='bold')\n    ax.grid(axis='y', alpha=0.3)\n    \n    # Cumulative error percentage\n    ax = axes[1]\n    max_err = int(results_df['sentiment_error'].max())\n    cumulative_pct = np.cumsum([\n        (results_df['sentiment_error'] == i).sum() for i in range(max_err + 1)\n    ]) / len(results_df) * 100\n    ax.plot(range(max_err + 1), cumulative_pct, marker='o', linewidth=2, markersize=8, color='steelblue')\n    ax.set_xlabel('Maximum Allowed Error', fontsize=12)\n    ax.set_ylabel('Cumulative Percentage (%)', fontsize=12)\n    ax.set_title('Cumulative Error Tolerance', fontsize=13, fontweight='bold')\n    ax.set_xticks(range(max_err + 1))\n    ax.grid(alpha=0.3)\n    ax.axhline(y=90, color='red', linestyle='--', alpha=0.5, label='90% threshold')\n    ax.legend()\n    \n    plt.tight_layout()\n    error_path = os.path.join(analysis_dir, 'error_distribution.png')\n    plt.savefig(error_path, dpi=300, bbox_inches='tight')\n    plt.close()\n    print(f\"âœ“ Saved to: {error_path}\")\n    \n    # 3. EMOTION PERFORMANCE (TASK B)\n    print(\"\\nGenerating emotion performance plots...\")\n    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n    \n    emotion_metrics = []\n    for i, emotion in enumerate(cfg['EMOTION_LABELS']):\n        true_labels = [row[i] for row in results_df['emotion_true']]\n        pred_labels = [row[i] for row in results_df['emotion_pred']]\n        probs = [row[i] for row in results_df['emotion_probs']]\n        \n        acc = accuracy_score(true_labels, pred_labels)\n        prec, rec, f1_bin, _ = precision_recall_fscore_support(\n            true_labels, pred_labels, average='binary', zero_division=0\n        )\n        # Weighted-F1 per subtask (this is what Memotion uses per B1â€“B4)\n        f1_weighted = f1_score(true_labels, pred_labels, average='weighted', zero_division=0)\n        \n        emotion_metrics.append({\n            'emotion': emotion,\n            'accuracy': acc,\n            'precision': prec,\n            'recall': rec,\n            'f1_binary': f1_bin,\n            'f1_weighted': f1_weighted,\n            'positive_rate': np.mean(true_labels),\n            'pred_positive_rate': np.mean(pred_labels)\n        })\n    \n    emotion_df = pd.DataFrame(emotion_metrics)\n    \n    # Plot 1: Overall metrics (per emotion)\n    ax = axes[0, 0]\n    x = np.arange(len(cfg['EMOTION_LABELS']))\n    width = 0.2\n    ax.bar(x - 1.5*width, emotion_df['accuracy'], width, label='Accuracy', alpha=0.8)\n    ax.bar(x - 0.5*width, emotion_df['precision'], width, label='Precision', alpha=0.8)\n    ax.bar(x + 0.5*width, emotion_df['recall'], width, label='Recall', alpha=0.8)\n    ax.bar(x + 1.5*width, emotion_df['f1_binary'], width, label='F1 (binary)', alpha=0.8)\n    ax.set_xlabel('Emotion', fontsize=11)\n    ax.set_ylabel('Score', fontsize=11)\n    ax.set_title('Emotion Classification Metrics (Per Subtask)', fontsize=12, fontweight='bold')\n    ax.set_xticks(x)\n    ax.set_xticklabels([e.capitalize() for e in cfg['EMOTION_LABELS']], rotation=45, ha='right')\n    ax.legend()\n    ax.set_ylim([0, 1])\n    ax.grid(axis='y', alpha=0.3)\n    \n    # Plot 2: Class distribution\n    ax = axes[0, 1]\n    x = np.arange(len(cfg['EMOTION_LABELS']))\n    width = 0.35\n    ax.bar(x - width/2, emotion_df['positive_rate'] * 100, width, label='True', alpha=0.8)\n    ax.bar(x + width/2, emotion_df['pred_positive_rate'] * 100, width, label='Predicted', alpha=0.8)\n    ax.set_xlabel('Emotion', fontsize=11)\n    ax.set_ylabel('Positive Class (%)', fontsize=11)\n    ax.set_title('Class Distribution: True vs Predicted', fontsize=12, fontweight='bold')\n    ax.set_xticks(x)\n    ax.set_xticklabels([e.capitalize() for e in cfg['EMOTION_LABELS']], rotation=45, ha='right')\n    ax.legend()\n    ax.grid(axis='y', alpha=0.3)\n    \n    # Plot 3 & 4: Individual emotion confusion matrices (for first two emotions)\n    for idx, emotion in enumerate(cfg['EMOTION_LABELS'][:2]):\n        ax = axes[1, idx]\n        true_labels = [row[idx] for row in results_df['emotion_true']]\n        pred_labels = [row[idx] for row in results_df['emotion_pred']]\n        \n        cm = np.array([\n            [sum((t == 0) & (p == 0) for t, p in zip(true_labels, pred_labels)),\n             sum((t == 0) & (p == 1) for t, p in zip(true_labels, pred_labels))],\n            [sum((t == 1) & (p == 0) for t, p in zip(true_labels, pred_labels)),\n             sum((t == 1) & (p == 1) for t, p in zip(true_labels, pred_labels))]\n        ])\n        \n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n                    xticklabels=['Negative', 'Positive'],\n                    yticklabels=['Negative', 'Positive'])\n        ax.set_title(f'{emotion.capitalize()} Confusion Matrix', fontsize=11, fontweight='bold')\n        ax.set_ylabel('True')\n        ax.set_xlabel('Predicted')\n    \n    plt.tight_layout()\n    emotion_path = os.path.join(analysis_dir, 'emotion_performance.png')\n    plt.savefig(emotion_path, dpi=300, bbox_inches='tight')\n    plt.close()\n    print(f\"âœ“ Saved to: {emotion_path}\")\n    \n    # 4. WORST PREDICTIONS (TASK A VIEW)\n    print(\"\\nAnalyzing worst predictions...\")\n    worst_df = results_df.nlargest(20, 'sentiment_error')\n    \n    print(f\"\\nTop 10 Worst Sentiment Predictions:\")\n    print(\"=\" * 70)\n    for i, (idx, row) in enumerate(worst_df.head(10).iterrows(), 1):\n        print(f\"\\n{i}. Index: {idx}\")\n        print(f\"   True: {row['sentiment_true_label']} (class {row['sentiment_true']})\")\n        print(f\"   Predicted: {row['sentiment_pred_label']} (class {row['sentiment_pred']})\")\n        print(f\"   Error: {row['sentiment_error']:.0f} classes\")\n    \n    worst_csv_path = os.path.join(analysis_dir, 'worst_predictions.csv')\n    worst_df.to_csv(worst_csv_path, index=True)\n    print(f\"\\nâœ“ Worst predictions saved to: {worst_csv_path}\")\n    \n    # 5. FINAL SUMMARY REPORT (MEMOTION 3 TASKS A/B/C)\n    print(\"\\n\" + \"=\" * 80)\n    print(\"FINAL SUMMARY REPORT â€“ MEMOTION 3 TASKS\")\n    print(\"=\" * 80)\n    \n    # ---------- Task A: Sentiment Analysis ----------\n    sent_true = results_df['sentiment_true'].values\n    sent_pred = results_df['sentiment_pred'].values\n    \n    taskA_weighted_f1 = f1_score(sent_true, sent_pred, average='weighted', zero_division=0)\n    taskA_macro_f1   = f1_score(sent_true, sent_pred, average='macro', zero_division=0)\n    taskA_acc        = results_df['sentiment_correct'].mean()\n    taskA_1off       = results_df['sentiment_1off'].mean()\n    taskA_mae        = results_df['sentiment_error'].mean()\n    \n    # ---------- Task B: Emotion Classification ----------\n    # Compute weighted-F1 for each of the 4 subtasks (B1â€“B4), then average (Memotion official way)\n    taskB_weighted_f1_per_emotion = []\n    taskB_binary_f1_per_emotion   = []\n    for i, emotion in enumerate(cfg['EMOTION_LABELS']):\n        true_labels = np.array([row[i] for row in results_df['emotion_true']], dtype=int)\n        pred_labels = np.array([row[i] for row in results_df['emotion_pred']], dtype=int)\n        \n        f1_weighted = f1_score(true_labels, pred_labels, average='weighted', zero_division=0)\n        f1_bin      = f1_score(true_labels, pred_labels, average='binary', zero_division=0)\n        \n        taskB_weighted_f1_per_emotion.append(f1_weighted)\n        taskB_binary_f1_per_emotion.append(f1_bin)\n    \n    taskB_avg_weighted_f1 = float(np.mean(taskB_weighted_f1_per_emotion))\n    taskB_avg_binary_f1   = float(np.mean(taskB_binary_f1_per_emotion))\n    \n    # Optional: sample-based F1 across all 4 emotions at once\n    emo_true = np.array(results_df['emotion_true'].tolist(), dtype=int)   # (N, 4)\n    emo_pred = np.array(results_df['emotion_pred'].tolist(), dtype=int)   # (N, 4)\n    taskB_sample_f1 = f1_score(emo_true, emo_pred, average='samples', zero_division=0)\n    \n    # ---------- Task C: Intensity of Emotions ----------\n    # NOTE: We can only compute Task C if you store ground-truth intensity labels into results_df.\n    has_taskC = all(\n        col in results_df.columns\n        for col in [\n            'humor_int_true', 'sarcasm_int_true', 'offensive_int_true', 'motivational_int_true',\n            'humor_int_pred', 'sarcasm_int_pred', 'offensive_int_pred', 'motivational_int_pred'\n        ]\n    )\n    \n    taskC_info = \"Not computed (no intensity labels in results_df)\"\n    taskC_avg_weighted_f1 = None\n    \n    if has_taskC:\n        taskC_f1_list = []\n        for emo in ['humor', 'sarcasm', 'offensive', 'motivational']:\n            y_true = results_df[f'{emo}_int_true'].values\n            y_pred = results_df[f'{emo}_int_pred'].values\n            f1_w = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n            taskC_f1_list.append(f1_w)\n        taskC_avg_weighted_f1 = float(np.mean(taskC_f1_list))\n        taskC_info = f\"Average weighted F1 across 4 intensity subtasks: {taskC_avg_weighted_f1:.4f}\"\n    \n    # ---------- Print Memotion-style summary ----------\n    print(\"\\nðŸ“Œ Task A â€“ Sentiment Analysis\")\n    print(f\"  Weighted F1 : {taskA_weighted_f1:.4f}\")\n    print(f\"  Macro F1    : {taskA_macro_f1:.4f}\")\n    print(f\"  Accuracy    : {taskA_acc:.4f}\")\n    print(f\"  1-off Acc   : {taskA_1off:.4f}\")\n    print(f\"  MAE         : {taskA_mae:.4f}\")\n    \n    print(\"\\nðŸ“Œ Task B â€“ Emotion Classification\")\n    print(f\"  Avg Weighted F1 over 4 emotions (B1â€“B4): {taskB_avg_weighted_f1:.4f}\")\n    print(f\"  Avg Binary F1 over 4 emotions         : {taskB_avg_binary_f1:.4f}\")\n    print(f\"  Sample-based F1 (multi-label)         : {taskB_sample_f1:.4f}\")\n    \n    print(\"\\nðŸ“Œ Task C â€“ Emotion Intensity\")\n    print(f\"  {taskC_info}\")\n    \n    # ---------- Detailed summary dict ----------\n    summary = {\n        'Total Samples': len(results_df),\n        'TaskA_Sentiment_Accuracy': taskA_acc,\n        'TaskA_Sentiment_WeightedF1': taskA_weighted_f1,\n        'TaskA_Sentiment_MacroF1': taskA_macro_f1,\n        'TaskA_Sentiment_1offAccuracy': taskA_1off,\n        'TaskA_Sentiment_MAE': taskA_mae,\n        'TaskB_AvgWeightedF1_4Emotions': taskB_avg_weighted_f1,\n        'TaskB_AvgBinaryF1_4Emotions': taskB_avg_binary_f1,\n        'TaskB_SampleBasedF1': taskB_sample_f1,\n        'TaskC_Info': taskC_info,\n        'TaskC_AvgWeightedF1_4Intensities': taskC_avg_weighted_f1 if taskC_avg_weighted_f1 is not None else 'N/A',\n    }\n    \n    # Also log per-emotion metrics\n    for i, emotion in enumerate(cfg['EMOTION_LABELS']):\n        true_labels = [row[i] for row in results_df['emotion_true']]\n        pred_labels = [row[i] for row in results_df['emotion_pred']]\n        acc = accuracy_score(true_labels, pred_labels)\n        _, _, f1_bin, _ = precision_recall_fscore_support(\n            true_labels, pred_labels,\n            average='binary', zero_division=0\n        )\n        f1_w = f1_score(true_labels, pred_labels, average='weighted', zero_division=0)\n        summary[f'{emotion.capitalize()}_Accuracy'] = acc\n        summary[f'{emotion.capitalize()}_F1_Binary'] = f1_bin\n        summary[f'{emotion.capitalize()}_F1_Weighted'] = f1_w\n    \n    summary_df = pd.DataFrame([summary]).T\n    summary_df.columns = ['Value']\n    \n    print(\"\\nðŸ“Š SUMMARY METRICS (DETAILED):\")\n    print(summary_df.to_string())\n    \n    summary_path = os.path.join(analysis_dir, 'summary_metrics.csv')\n    summary_df.to_csv(summary_path)\n    print(f\"\\nâœ“ Summary saved to: {summary_path}\")\n    \n    print(\"\\n\" + \"=\" * 80)\n    print(\"âœ… ALL ANALYSIS COMPLETE!\")\n    print(\"=\" * 80)\n    print(f\"\\nGenerated files in {analysis_dir}:\")\n    print(\"  1. sentiment_confusion_matrix.png\")\n    print(\"  2. error_distribution.png\")\n    print(\"  3. emotion_performance.png\")\n    print(\"  4. worst_predictions.csv\")\n    print(\"  5. summary_metrics.csv\")\n    print(f\"\\nDetailed results: {results_csv_path}\")\n    print(f\"Model checkpoint: {checkpoint_path}\")\n    print(f\"Model card: {model_card_path}\")\n    print(\"\\n\" + \"=\" * 80)\n\nprint(\"\\nðŸŽ‰ COMPLETE PIPELINE FINISHED! ðŸŽ‰\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T22:43:24.957710Z","iopub.execute_input":"2025-11-20T22:43:24.958034Z","iopub.status.idle":"2025-11-20T22:43:28.540460Z","shell.execute_reply.started":"2025-11-20T22:43:24.958011Z","shell.execute_reply":"2025-11-20T22:43:28.539646Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nPART 10: VISUALIZATION & ANALYSIS\n================================================================================\n\nGenerating sentiment confusion matrix...\nâœ“ Saved to: /kaggle/working/checkpoints/analysis/sentiment_confusion_matrix.png\n\nGenerating error distribution plot...\nâœ“ Saved to: /kaggle/working/checkpoints/analysis/error_distribution.png\n\nGenerating emotion performance plots...\nâœ“ Saved to: /kaggle/working/checkpoints/analysis/emotion_performance.png\n\nAnalyzing worst predictions...\n\nTop 10 Worst Sentiment Predictions:\n======================================================================\n\n1. Index: 810\n   True: very_negative (class 4)\n   Predicted: very_positive (class 0)\n   Error: 4 classes\n\n2. Index: 23\n   True: negative (class 3)\n   Predicted: very_positive (class 0)\n   Error: 3 classes\n\n3. Index: 36\n   True: negative (class 3)\n   Predicted: very_positive (class 0)\n   Error: 3 classes\n\n4. Index: 97\n   True: negative (class 3)\n   Predicted: very_positive (class 0)\n   Error: 3 classes\n\n5. Index: 262\n   True: negative (class 3)\n   Predicted: very_positive (class 0)\n   Error: 3 classes\n\n6. Index: 284\n   True: negative (class 3)\n   Predicted: very_positive (class 0)\n   Error: 3 classes\n\n7. Index: 299\n   True: negative (class 3)\n   Predicted: very_positive (class 0)\n   Error: 3 classes\n\n8. Index: 326\n   True: very_negative (class 4)\n   Predicted: positive (class 1)\n   Error: 3 classes\n\n9. Index: 330\n   True: negative (class 3)\n   Predicted: very_positive (class 0)\n   Error: 3 classes\n\n10. Index: 479\n   True: negative (class 3)\n   Predicted: very_positive (class 0)\n   Error: 3 classes\n\nâœ“ Worst predictions saved to: /kaggle/working/checkpoints/analysis/worst_predictions.csv\n\n================================================================================\nFINAL SUMMARY REPORT â€“ MEMOTION 3 TASKS\n================================================================================\n\nðŸ“Œ Task A â€“ Sentiment Analysis\n  Weighted F1 : 0.3677\n  Macro F1    : 0.2295\n  Accuracy    : 0.4371\n  1-off Acc   : 0.8752\n  MAE         : 0.7048\n\nðŸ“Œ Task B â€“ Emotion Classification\n  Avg Weighted F1 over 4 emotions (B1â€“B4): 0.6931\n  Avg Binary F1 over 4 emotions         : 0.4511\n  Sample-based F1 (multi-label)         : 0.7723\n\nðŸ“Œ Task C â€“ Emotion Intensity\n  Not computed (no intensity labels in results_df)\n\nðŸ“Š SUMMARY METRICS (DETAILED):\n                                                                             Value\nTotal Samples                                                                 1050\nTaskA_Sentiment_Accuracy                                                  0.437143\nTaskA_Sentiment_WeightedF1                                                0.367669\nTaskA_Sentiment_MacroF1                                                    0.22948\nTaskA_Sentiment_1offAccuracy                                              0.875238\nTaskA_Sentiment_MAE                                                       0.704762\nTaskB_AvgWeightedF1_4Emotions                                             0.693115\nTaskB_AvgBinaryF1_4Emotions                                               0.451089\nTaskB_SampleBasedF1                                                       0.772286\nTaskC_Info                        Not computed (no intensity labels in results_df)\nTaskC_AvgWeightedF1_4Intensities                                               N/A\nHumor_Accuracy                                                            0.855238\nHumor_F1_Binary                                                           0.921971\nHumor_F1_Weighted                                                         0.788505\nSarcasm_Accuracy                                                          0.789524\nSarcasm_F1_Binary                                                         0.882384\nSarcasm_F1_Weighted                                                       0.696663\nOffensive_Accuracy                                                        0.608571\nOffensive_F1_Binary                                                            0.0\nOffensive_F1_Weighted                                                     0.461203\nMotivational_Accuracy                                                     0.880952\nMotivational_F1_Binary                                                         0.0\nMotivational_F1_Weighted                                                  0.826088\n\nâœ“ Summary saved to: /kaggle/working/checkpoints/analysis/summary_metrics.csv\n\n================================================================================\nâœ… ALL ANALYSIS COMPLETE!\n================================================================================\n\nGenerated files in /kaggle/working/checkpoints/analysis:\n  1. sentiment_confusion_matrix.png\n  2. error_distribution.png\n  3. emotion_performance.png\n  4. worst_predictions.csv\n  5. summary_metrics.csv\n\nDetailed results: /kaggle/working/checkpoints/detailed_results.csv\nModel checkpoint: /kaggle/working/checkpoints/best_model_enhanced.pt\nModel card: /kaggle/working/checkpoints/model_card.md\n\n================================================================================\n\nðŸŽ‰ COMPLETE PIPELINE FINISHED! ðŸŽ‰\n\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ==================== COMPLETE ENHANCED MEME ANALYSIS PIPELINE ====================\n# This code includes BOTH data preparation AND enhanced training\n# Run this entire script from start to finish\n\n# ==================== PART 0: SETUP & DEPENDENCIES ====================\nimport sys, subprocess, os, json, zipfile, shutil, random, warnings\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom torch.cuda.amp import GradScaler, autocast\nimport torchvision.transforms as transforms\nfrom PIL import Image\nfrom tqdm import tqdm\nimport yaml\n\nwarnings.filterwarnings('ignore')\n\nprint(\"=\" * 80)\nprint(\"INSTALLING DEPENDENCIES...\")\nprint(\"=\" * 80)\n\n# Install required packages\nsubprocess.check_call([\n    sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n    \"transformers>=4.40.0\", \"accelerate\", \"torch\", \"timm\",\n    \"scikit-learn\", \"pandas\", \"matplotlib\", \"seaborn\",\n    \"huggingface_hub>=0.18.0\", \"gdown\", \"iterative-stratification\"\n])\n\n# Import additional packages\nfrom sklearn.metrics import (\n    accuracy_score, precision_recall_fscore_support,\n    mean_squared_error, mean_absolute_error, f1_score\n)\nfrom transformers import AutoModel, AutoTokenizer, CLIPModel\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n\nprint(\"âœ“ All dependencies installed\\n\")\n\n# ==================== PART 1: DATA PREPARATION ====================\nprint(\"=\" * 80)\nprint(\"PART 1: DATA PREPARATION\")\nprint(\"=\" * 80)\n\n# Download and extract dataset\nprint(\"\\nDownloading dataset...\")\nsubprocess.run([\"gdown\", \"1jEJ2nf5CDJknq80ogzU-Uyz7jbBi-1LZ\", \"--fuzzy\"], \n               check=False, capture_output=True)\n\nprint(\"Extracting dataset...\")\nzip_files = [f for f in os.listdir('.') if f.endswith('.zip')]\nif zip_files:\n    subprocess.run([\"unzip\", \"-q\", \"-o\", zip_files[0]], check=False, capture_output=True)\n\n# Download additional files\nsubprocess.run([\n    \"gdown\", \"--folder\", \"19yaav8ORSVj9DeJUaHKq1H3HtVnkClBw\", \"--remaining-ok\"\n], check=False, capture_output=True)\n\n# Extract password-protected archive\nprint(\"Extracting protected archive...\")\nzip_path = '/kaggle/working/Memotion 3/memotion3.zip'\nextract_to = '/kaggle/working/'\npassword = b'memotion3taskaaai@22'\n\nif os.path.exists(zip_path):\n    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n        zip_ref.extractall(extract_to, pwd=password)\n    print(f\"âœ“ Extracted to: {extract_to}\")\n\n# Setup paths\nORIGINAL_TRAIN_IMG_DIR = '/kaggle/working/trainImages/'\nORIGINAL_CSV_PATH = '/kaggle/working/memotion3/train.csv'\nVALIDATION_SPLIT_RATIO = 0.15\n\nOUTPUT_BASE_DIR = '/kaggle/working/'\nNEW_VAL_DIR = os.path.join(OUTPUT_BASE_DIR, 'validation_images/')\nNEW_TRAIN_DIR = os.path.join(OUTPUT_BASE_DIR, 'new_train_images/')\n\nos.makedirs(NEW_VAL_DIR, exist_ok=True)\nos.makedirs(NEW_TRAIN_DIR, exist_ok=True)\n\n# Load and process CSV\nprint(\"\\nLoading CSV file...\")\ndf = pd.read_csv(ORIGINAL_CSV_PATH)\n\n# Detect image column\npossible_image_cols = ['image_name', 'image', 'img_name', 'filename', 'Unnamed: 0']\nIMAGE_FILENAME_COLUMN = next((col for col in possible_image_cols if col in df.columns), df.columns[0])\nprint(f\"âœ“ Image column: {IMAGE_FILENAME_COLUMN}\")\n\n# Normalize labels\nfor col in ['offensive', 'motivational', 'humour', 'humor', 'sarcastic', 'sarcasm', 'overall', 'sentiment']:\n    if col in df.columns:\n        df[col] = df[col].astype(str).str.lower().str.strip()\n\n# Create binary labels\ndef create_binary_label(value, positive_values):\n    if pd.isna(value) or value in ['nan', 'none', '']:\n        return 0\n    return 1 if value in positive_values else 0\n\nif 'offensive' in df.columns:\n    df['offensive_bin'] = df['offensive'].apply(\n        lambda x: create_binary_label(x, ['slight', 'very_offensive', 'hateful_offensive'])\n    )\nelse:\n    df['offensive_bin'] = 0\n\nif 'motivational' in df.columns:\n    df['motivational_bin'] = df['motivational'].apply(\n        lambda x: create_binary_label(x, ['motivational'])\n    )\nelse:\n    df['motivational_bin'] = 0\n\nif 'humour' in df.columns or 'humor' in df.columns:\n    humor_col = 'humour' if 'humour' in df.columns else 'humor'\n    df['humor_bin'] = df[humor_col].apply(\n        lambda x: create_binary_label(x, ['funny', 'very_funny', 'hilarious'])\n    )\nelse:\n    df['humor_bin'] = 0\n\nif 'sarcastic' in df.columns or 'sarcasm' in df.columns:\n    sarcasm_col = 'sarcastic' if 'sarcastic' in df.columns else 'sarcasm'\n    df['sarcasm_bin'] = df[sarcasm_col].apply(\n        lambda x: create_binary_label(x, ['general', 'twisted_meaning', 'very_twisted'])\n    )\nelse:\n    df['sarcasm_bin'] = 0\n\n# Stratified split\nstratify_columns = ['offensive_bin', 'motivational_bin', 'humor_bin', 'sarcasm_bin']\ny_stratify = df[stratify_columns].values\n\nmsss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=VALIDATION_SPLIT_RATIO, random_state=42)\ntrain_idx, val_idx = next(msss.split(df, y_stratify))\n\ntrain_df = df.iloc[train_idx].reset_index(drop=True)\nval_df = df.iloc[val_idx].reset_index(drop=True)\n\nprint(f\"\\nâœ“ Stratified split complete:\")\nprint(f\"  Training: {len(train_df)} samples\")\nprint(f\"  Validation: {len(val_df)} samples\")\n\n# Calculate label priors\nlabel_priors = {\n    'offensive_pos_rate': float(train_df['offensive_bin'].sum() / len(train_df)),\n    'motivational_pos_rate': float(train_df['motivational_bin'].sum() / len(train_df)),\n    'humor_pos_rate': float(train_df['humor_bin'].sum() / len(train_df)),\n    'sarcasm_pos_rate': float(train_df['sarcasm_bin'].sum() / len(train_df))\n}\n\npriors_path = os.path.join(OUTPUT_BASE_DIR, 'label_priors.json')\nwith open(priors_path, 'w') as f:\n    json.dump(label_priors, f, indent=2)\n\nprint(f\"\\nâœ“ Label priors calculated:\")\nfor key, val in label_priors.items():\n    print(f\"  {key}: {val:.4f}\")\n\n# Copy images\ndef copy_images(df_subset, dest_dir, source_dir, image_col):\n    copied = 0\n    missing = 0\n    \n    for idx in tqdm(df_subset[image_col], desc=f\"Copying to {dest_dir}\"):\n        filename = str(idx)\n        if not any(filename.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif']):\n            for ext in ['.jpg', '.jpeg', '.png']:\n                test_path = os.path.join(source_dir, f\"{filename}{ext}\")\n                if os.path.exists(test_path):\n                    filename = f\"{filename}{ext}\"\n                    break\n            else:\n                filename = f\"{filename}.jpg\"\n        \n        source_path = os.path.join(source_dir, filename)\n        if os.path.exists(source_path):\n            shutil.copy(source_path, os.path.join(dest_dir, filename))\n            copied += 1\n        else:\n            missing += 1\n    \n    return copied, missing\n\nprint(\"\\nCopying images...\")\ncopied_val, missing_val = copy_images(val_df, NEW_VAL_DIR, ORIGINAL_TRAIN_IMG_DIR, IMAGE_FILENAME_COLUMN)\ncopied_train, missing_train = copy_images(train_df, NEW_TRAIN_DIR, ORIGINAL_TRAIN_IMG_DIR, IMAGE_FILENAME_COLUMN)\n\nprint(f\"âœ“ Validation: {copied_val} copied, {missing_val} missing\")\nprint(f\"âœ“ Training: {copied_train} copied, {missing_train} missing\")\n\n# Save CSVs\ntrain_csv_path = os.path.join(OUTPUT_BASE_DIR, 'train_split.csv')\nval_csv_path = os.path.join(OUTPUT_BASE_DIR, 'validation_split.csv')\n\ntrain_df.to_csv(train_csv_path, index=False)\nval_df.to_csv(val_csv_path, index=False)\n\nprint(f\"\\nâœ“ Saved train CSV: {train_csv_path}\")\nprint(f\"âœ“ Saved validation CSV: {val_csv_path}\")\nprint(\"\\nâœ… DATA PREPARATION COMPLETE\\n\")\n\n# ==================== PART 2: CONFIGURATION ====================\nprint(\"=\" * 80)\nprint(\"PART 2: CONFIGURATION\")\nprint(\"=\" * 80)\n\nCONFIG_YAML = \"\"\"\nTEXT_MODEL: \"google/muril-base-cased\"\nIMAGE_MODEL: \"openai/clip-vit-base-patch32\"\nTEXT_DIM: 768\nIMAGE_DIM: 768\nFUSION_DIM: 512\nFUSION_OUT_DIM: 512\n\nMAX_LEN: 128\nIMG_SIZE: 224\nBATCH_SIZE: 16\nGRADIENT_ACCUMULATION_STEPS: 2\nLR_HEADS: 0.001\nLR_BACKBONE: 0.00002\nWEIGHT_DECAY: 0.01\nEPOCHS: 20\nSEED: 42\nDEVICE: \"cuda\"\nCHECKPOINT_PATH: \"/kaggle/working/checkpoints\"\n\nNUM_SENTIMENT_CLASSES: 5\nNUM_EMOTION_CLASSES: 4\n\nUSE_ORDINAL_REGRESSION: true\nORDINAL_LINK: \"logit\"\n\nLOSS_WEIGHTS:\n  sentiment: 2.0\n  emotion: 1.5\n  intensity: 0.5\n\nASL_GAMMA_NEG: 6.0\nASL_GAMMA_POS: 0.5\nASL_CLIP: 0.05\nASL_PRIOR_TAU: 1.2\n\nEMOTION_LABELS: [\"humor\", \"sarcasm\", \"offensive\", \"motivational\"]\nEMO_THRESHOLDS: [0.5, 0.5, 0.60, 0.60]\n\n# NEW: thresholds for expected-value based sentiment decoding\nSENTIMENT_EXPECTED_THRESHOLDS: [0.5, 1.5, 2.5, 3.5]\n\n# NEW: class weights for ordinal loss (upweight extremes 0 and 4)\nSENTIMENT_CLASS_WEIGHTS: [1.5, 1.0, 1.0, 1.0, 1.5]\n\nPOOLING: \"mean\"\nUSE_AMP: true\nGRADIENT_CLIP: 1.0\nSCHEDULER: \"cosine\"\nUNFREEZE_BACKBONE_EPOCH: 2\nUNFREEZE_LAYERS: 3\n\nMOTIVATIONAL_OVERSAMPLE_FACTOR: 8.0\n\n# NEW: oversampling factor for extreme sentiment classes (very_positive & very_negative)\nEXTREME_SENTIMENT_OVERSAMPLE_FACTOR: 5.0\n\nCROSS_ATTN_HEADS: 8\nCROSS_ATTN_DROPOUT: 0.1\n\nSENTIMENT_MAP_REV:\n  0: \"very_positive\"\n  1: \"positive\"\n  2: \"neutral\"\n  3: \"negative\"\n  4: \"very_negative\"\n\"\"\"\n\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\ncfg = yaml.safe_load(CONFIG_YAML)\nset_seed(cfg['SEED'])\n\n# Load priors\nwith open(priors_path, 'r') as f:\n    priors = json.load(f)\n\ncfg['EMO_PRIORS'] = [\n    priors['humor_pos_rate'],\n    priors['sarcasm_pos_rate'],\n    priors['offensive_pos_rate'],\n    priors['motivational_pos_rate']\n]\n\ndevice = torch.device(cfg['DEVICE'] if torch.cuda.is_available() else 'cpu')\n\nprint(f\"\\nâœ“ Configuration loaded:\")\nprint(f\"  Device: {device}\")\nprint(f\"  Epochs: {cfg['EPOCHS']}\")\nprint(f\"  Batch size: {cfg['BATCH_SIZE']}\")\nprint(f\"  Motivational oversampling: {cfg['MOTIVATIONAL_OVERSAMPLE_FACTOR']}x\")\nprint(f\"  Extreme sentiment oversampling: {cfg['EXTREME_SENTIMENT_OVERSAMPLE_FACTOR']}x\")\nprint(f\"  Emotion priors: {[f'{p:.3f}' for p in cfg['EMO_PRIORS']]}\")\n\n# ==================== PART 3: MODEL COMPONENTS ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 3: MODEL COMPONENTS\")\nprint(\"=\" * 80)\n\nclass EnhancedAsymmetricLoss(nn.Module):\n    \"\"\"Enhanced ASL with prior adjustment\"\"\"\n    def __init__(self, gamma_neg=6.0, gamma_pos=0.5, clip=0.05, priors=None, prior_tau=1.2, eps=1e-8):\n        super().__init__()\n        self.gamma_neg = gamma_neg\n        self.gamma_pos = gamma_pos\n        self.clip = clip\n        self.eps = eps\n        self.priors = priors\n        self.prior_tau = prior_tau\n    \n    def forward(self, logits, targets):\n        # Prior adjustment\n        if self.priors is not None:\n            priors_tensor = torch.tensor(self.priors, device=logits.device, dtype=logits.dtype)\n            adjustment = self.prior_tau * torch.log(priors_tensor.clamp(min=self.eps))\n            logits = logits - adjustment\n        \n        xs_pos = torch.sigmoid(logits)\n        xs_neg = 1 - xs_pos\n        \n        if self.clip is not None and self.clip > 0:\n            xs_neg = (xs_neg + self.clip).clamp(max=1)\n        \n        los_pos = targets * torch.log(xs_pos.clamp(min=self.eps))\n        los_neg = (1 - targets) * torch.log(xs_neg.clamp(min=self.eps))\n        \n        if self.gamma_neg > 0 or self.gamma_pos > 0:\n            pt0 = xs_pos * targets\n            pt1 = xs_neg * (1 - targets)\n            pt = pt0 + pt1\n            one_sided_gamma = self.gamma_pos * targets + self.gamma_neg * (1 - targets)\n            one_sided_w = torch.pow(1 - pt, one_sided_gamma)\n            loss = one_sided_w * (los_pos + los_neg)\n        else:\n            loss = los_pos + los_neg\n        \n        return -loss.mean()\n\nclass OrdinalRegressionHead(nn.Module):\n    \"\"\"Ordinal regression using cumulative link model\"\"\"\n    def __init__(self, input_dim, num_classes):\n        super().__init__()\n        self.num_classes = num_classes\n        self.num_thresholds = num_classes - 1\n        \n        self.projection = nn.Sequential(\n            nn.Linear(input_dim, 256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, 1)\n        )\n        \n        initial_thresholds = torch.linspace(-2, 2, self.num_thresholds)\n        self.thresholds = nn.Parameter(initial_thresholds)\n    \n    def forward(self, x):\n        score = self.projection(x).squeeze(-1)\n        ordered_thresholds = torch.cumsum(F.softplus(self.thresholds), dim=0)\n        cumulative_logits = ordered_thresholds.unsqueeze(0) - score.unsqueeze(1)\n        cumulative_probs = torch.sigmoid(cumulative_logits)\n        \n        batch_size = cumulative_probs.size(0)\n        class_probs = torch.zeros(batch_size, self.num_classes, device=x.device)\n        \n        class_probs[:, 0] = cumulative_probs[:, 0]\n        for k in range(1, self.num_thresholds):\n            class_probs[:, k] = cumulative_probs[:, k] - cumulative_probs[:, k-1]\n        class_probs[:, -1] = 1.0 - cumulative_probs[:, -1]\n        class_probs = torch.clamp(class_probs, min=1e-7, max=1.0)\n        \n        return {'cumulative_logits': cumulative_logits, 'class_probs': class_probs}\n\nclass CrossAttentionFusion(nn.Module):\n    \"\"\"Bidirectional cross-attention\"\"\"\n    def __init__(self, dim, num_heads=8, dropout=0.1):\n        super().__init__()\n        self.text_to_image_attn = nn.MultiheadAttention(dim, num_heads, dropout, batch_first=True)\n        self.image_to_text_attn = nn.MultiheadAttention(dim, num_heads, dropout, batch_first=True)\n        self.text_norm = nn.LayerNorm(dim)\n        self.image_norm = nn.LayerNorm(dim)\n        self.text_ffn = nn.Sequential(\n            nn.Linear(dim, dim * 4), nn.GELU(), nn.Dropout(dropout),\n            nn.Linear(dim * 4, dim), nn.Dropout(dropout)\n        )\n        self.image_ffn = nn.Sequential(\n            nn.Linear(dim, dim * 4), nn.GELU(), nn.Dropout(dropout),\n            nn.Linear(dim * 4, dim), nn.Dropout(dropout)\n        )\n        self.ffn_norm_text = nn.LayerNorm(dim)\n        self.ffn_norm_image = nn.LayerNorm(dim)\n    \n    def forward(self, text_emb, image_emb):\n        text_seq = text_emb.unsqueeze(1)\n        image_seq = image_emb.unsqueeze(1)\n        \n        text_attended, _ = self.text_to_image_attn(text_seq, image_seq, image_seq)\n        text_out = self.text_norm(text_emb + text_attended.squeeze(1))\n        \n        image_attended, _ = self.image_to_text_attn(image_seq, text_seq, text_seq)\n        image_out = self.image_norm(image_emb + image_attended.squeeze(1))\n        \n        text_final = self.ffn_norm_text(text_out + self.text_ffn(text_out))\n        image_final = self.ffn_norm_image(image_out + self.image_ffn(image_out))\n        \n        return text_final, image_final\n\nclass EnhancedFusionModel(nn.Module):\n    \"\"\"Multi-modal model with ordinal regression + enhanced ASL\"\"\"\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg = cfg\n        \n        self.text_model = AutoModel.from_pretrained(cfg['TEXT_MODEL'])\n        clip_model = CLIPModel.from_pretrained(cfg['IMAGE_MODEL'])\n        self.image_model = clip_model.vision_model\n        \n        self._freeze_encoders()\n        \n        self.text_proj = nn.Linear(cfg['TEXT_DIM'], cfg['FUSION_DIM'])\n        self.image_proj = nn.Linear(cfg['IMAGE_DIM'], cfg['FUSION_DIM'])\n        \n        self.cross_attention = CrossAttentionFusion(\n            dim=cfg['FUSION_DIM'],\n            num_heads=cfg['CROSS_ATTN_HEADS'],\n            dropout=cfg['CROSS_ATTN_DROPOUT']\n        )\n        \n        fusion_input_dim = cfg['FUSION_DIM'] * 2\n        self.fusion_norm = nn.LayerNorm(fusion_input_dim)\n        self.fusion_mlp = nn.Sequential(\n            nn.Linear(fusion_input_dim, 512), nn.GELU(), nn.Dropout(0.2),\n            nn.Linear(512, cfg['FUSION_OUT_DIM']), nn.LayerNorm(cfg['FUSION_OUT_DIM'])\n        )\n        \n        self.sentiment_head = OrdinalRegressionHead(cfg['FUSION_OUT_DIM'], cfg['NUM_SENTIMENT_CLASSES'])\n        self.emotion_head = nn.Sequential(\n            nn.Linear(cfg['FUSION_OUT_DIM'], 256), nn.ReLU(), nn.Dropout(0.2),\n            nn.Linear(256, cfg['NUM_EMOTION_CLASSES'])\n        )\n        self.intensity_head = nn.Sequential(\n            nn.Linear(cfg['FUSION_OUT_DIM'], 128), nn.ReLU(), nn.Dropout(0.2),\n            nn.Linear(128, 1)\n        )\n    \n    def _freeze_encoders(self):\n        for param in self.text_model.parameters():\n            param.requires_grad = False\n        for param in self.image_model.parameters():\n            param.requires_grad = False\n    \n    def unfreeze_backbone(self, layers_to_unfreeze=3):\n        if hasattr(self.text_model, 'encoder') and hasattr(self.text_model.encoder, 'layer'):\n            for layer in list(self.text_model.encoder.layer[-layers_to_unfreeze:]):\n                for param in layer.parameters():\n                    param.requires_grad = True\n        \n        if hasattr(self.image_model, 'encoder') and hasattr(self.image_model.encoder, 'layers'):\n            for layer in list(self.image_model.encoder.layers[-layers_to_unfreeze:]):\n                for param in layer.parameters():\n                    param.requires_grad = True\n    \n    def pool_text(self, model_output, attention_mask):\n        last_hidden = model_output.last_hidden_state\n        if self.cfg['POOLING'] == 'cls':\n            return last_hidden[:, 0]\n        mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden.size()).float()\n        sum_embeddings = torch.sum(last_hidden * mask_expanded, 1)\n        sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n        return sum_embeddings / sum_mask\n    \n    def forward(self, input_ids, attention_mask, image):\n        text_output = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n        text_emb = self.pool_text(text_output, attention_mask)\n        \n        image_output = self.image_model(pixel_values=image)\n        image_emb = image_output.pooler_output\n        \n        text_proj = self.text_proj(text_emb)\n        image_proj = self.image_proj(image_emb)\n        \n        text_cross, image_cross = self.cross_attention(text_proj, image_proj)\n        \n        fused = torch.cat([text_cross, image_cross], dim=1)\n        fused = self.fusion_norm(fused)\n        fused = self.fusion_mlp(fused)\n        \n        sentiment_outputs = self.sentiment_head(fused)\n        emotion_logits = self.emotion_head(fused)\n        intensity = self.intensity_head(fused).squeeze(-1)\n        \n        return {\n            'sentiment': sentiment_outputs,\n            'emotion_logits': emotion_logits,\n            'intensity': intensity\n        }\n\nprint(\"âœ“ Model components defined\")\n\n# ==================== PART 4: DATASET ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 4: DATASET\")\nprint(\"=\" * 80)\n\nclass MemeDataset(Dataset):\n    def __init__(self, df, tokenizer, image_transform, image_dir, cfg):\n        self.df = df.reset_index(drop=True)\n        self.tokenizer = tokenizer\n        self.image_transform = image_transform\n        self.image_dir = image_dir\n        self.cfg = cfg\n        self._detect_columns()\n    \n    def _detect_columns(self):\n        cols = self.df.columns.tolist()\n        self.image_col = next((c for c in ['image_name', 'image', 'img_name', 'filename', 'Unnamed: 0'] if c in cols), cols[0])\n        self.text_col = next((c for c in ['text', 'ocr_text', 'caption', 'OCR_extracted_text'] if c in cols), None)\n        self.sentiment_col = next((c for c in ['sentiment', 'overall_sentiment', 'overall'] if c in cols), None)\n        \n        self.sentiment_map = {'very_positive': 0, 'positive': 1, 'neutral': 2, 'negative': 3, 'very_negative': 4}\n        self.humor_map = {'not_funny': 0, 'funny': 1, 'very_funny': 1, 'hilarious': 1}\n        self.sarcasm_map = {'not_sarcastic': 0, 'general': 1, 'twisted_meaning': 1, 'very_twisted': 1}\n        self.offensive_map = {'not_offensive': 0, 'slight': 1, 'very_offensive': 1, 'hateful_offensive': 1}\n        self.motivational_map = {'not_motivational': 0, 'motivational': 1}\n    \n    def _map_label(self, value, mapping, default=0):\n        if pd.isna(value):\n            return default\n        if isinstance(value, str):\n            return mapping.get(value.lower().strip(), default)\n        return int(value)\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        \n        image_name = str(row[self.image_col])\n        if not any(image_name.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png']):\n            image_name = f\"{image_name}.jpg\"\n        image_path = os.path.join(self.image_dir, image_name)\n        \n        try:\n            image = Image.open(image_path).convert('RGB')\n            image = self.image_transform(image)\n        except:\n            image = torch.zeros(3, self.cfg['IMG_SIZE'], self.cfg['IMG_SIZE'])\n        \n        text = str(row.get(self.text_col, '')) if self.text_col else 'No text'\n        encoding = self.tokenizer(text, max_length=self.cfg['MAX_LEN'], padding='max_length', truncation=True, return_tensors='pt')\n        \n        sentiment_val = row.get(self.sentiment_col, 'neutral') if self.sentiment_col else 'neutral'\n        sentiment_label = self._map_label(sentiment_val, self.sentiment_map, default=2)\n        \n        emotion_labels = torch.tensor([\n            float(self._map_label(row.get('humour', row.get('humor', 0)), self.humor_map, 0)),\n            float(self._map_label(row.get('sarcastic', row.get('sarcasm', 0)), self.sarcasm_map, 0)),\n            float(self._map_label(row.get('offensive', 0), self.offensive_map, 0)),\n            float(self._map_label(row.get('motivational', 0), self.motivational_map, 0))\n        ], dtype=torch.float)\n        \n        return {\n            'input_ids': encoding['input_ids'].squeeze(0),\n            'attention_mask': encoding['attention_mask'].squeeze(0),\n            'image': image,\n            'sentiment_label': torch.tensor(sentiment_label, dtype=torch.long),\n            'emotion_labels': emotion_labels,\n            'intensity': torch.tensor(0.5, dtype=torch.float),\n            'motivational_flag': emotion_labels[3]\n        }\n\nprint(\"âœ“ Dataset class defined\")\n\n# ==================== PART 5: LOSS & METRICS ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 5: LOSS FUNCTIONS & METRICS\")\nprint(\"=\" * 80)\n\n# UPDATED: class-weighted ordinal loss, with extra argument\ndef ordinal_regression_loss(cumulative_logits, labels, class_weights=None):\n    batch_size = labels.size(0)\n    num_thresholds = cumulative_logits.size(1)\n    target_cumulative = torch.zeros_like(cumulative_logits)\n    \n    for i in range(batch_size):\n        y = int(labels[i].item())\n        if y < num_thresholds:\n            target_cumulative[i, y:] = 1.0\n    \n    # compute per-sample, per-threshold loss\n    loss_matrix = F.binary_cross_entropy_with_logits(\n        cumulative_logits, target_cumulative, reduction='none'\n    )  # [B, num_thresholds]\n    \n    if class_weights is not None:\n        # class_weights is list[5]; map each sample to its class weight\n        cw = torch.tensor(class_weights, device=labels.device, dtype=loss_matrix.dtype)\n        sample_weights = cw[labels]  # [B]\n        loss_matrix = loss_matrix * sample_weights.unsqueeze(1)\n    \n    return loss_matrix.mean()\n\ndef combined_loss(outputs, batch, cfg, emotion_loss_fn):\n    loss_sent = ordinal_regression_loss(\n        outputs['sentiment']['cumulative_logits'],\n        batch['sentiment_label'],\n        cfg.get('SENTIMENT_CLASS_WEIGHTS')\n    )\n    loss_emotion = emotion_loss_fn(outputs['emotion_logits'], batch['emotion_labels'])\n    loss_intensity = F.smooth_l1_loss(outputs['intensity'], batch['intensity'])\n    \n    total_loss = (\n        cfg['LOSS_WEIGHTS']['sentiment'] * loss_sent +\n        cfg['LOSS_WEIGHTS']['emotion'] * loss_emotion +\n        cfg['LOSS_WEIGHTS']['intensity'] * loss_intensity\n    )\n    \n    return total_loss, loss_sent, loss_emotion, loss_intensity\n\n# UPDATED: now takes both emotion thresholds and sentiment EV thresholds\ndef compute_metrics(sentiment_outputs, sentiment_labels, emotion_logits, emotion_labels,\n                    emotion_thresholds, expected_thresholds):\n    # Sentiment\n    class_probs = sentiment_outputs['class_probs']\n    num_classes = class_probs.size(1)\n    \n    y_true = sentiment_labels.cpu().numpy()\n    class_probs_np = class_probs.cpu().numpy()\n    \n    # EXPECTED VALUE based decoding instead of plain argmax\n    # E[class] = sum_k p_k * k\n    ev = np.sum(class_probs_np * np.arange(num_classes), axis=1)\n    ev_thresholds = np.array(expected_thresholds)\n    \n    # np.digitize: returns bin index; with 4 thresholds -> values in {0..4}\n    y_pred = np.digitize(ev, bins=ev_thresholds)\n    \n    sent_acc = accuracy_score(y_true, y_pred)\n    _, _, sent_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)\n    sent_mae = mean_absolute_error(y_true, y_pred)\n    sent_1off = np.mean(np.abs(y_true - y_pred) <= 1)\n    \n    # Emotions\n    emo_probs = torch.sigmoid(emotion_logits).cpu().numpy()\n    emo_true = emotion_labels.cpu().numpy()\n    emo_thresholds = np.array(emotion_thresholds)\n    emo_pred = (emo_probs >= emo_thresholds).astype(float)\n    \n    _, _, emo_f1, _ = precision_recall_fscore_support(emo_true, emo_pred, average='samples', zero_division=0)\n    \n    return {\n        'sentiment_accuracy': sent_acc,\n        'sentiment_f1': sent_f1,\n        'sentiment_mae': sent_mae,\n        'sentiment_1off_accuracy': sent_1off,\n        'emotion_f1': emo_f1\n    }\n\nprint(\"âœ“ Loss functions and metrics defined\")\n\n# ==================== PART 6: TRAINER ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 6: TRAINER\")\nprint(\"=\" * 80)\n\nclass Trainer:\n    def __init__(self, model, cfg, train_loader, val_loader, device, emotion_loss_fn):\n        self.model = model\n        self.cfg = cfg\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.device = device\n        self.emotion_loss_fn = emotion_loss_fn\n        \n        self.optimizer = self.make_optimizer()\n        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=cfg['EPOCHS'])\n        self.scaler = GradScaler() if cfg['USE_AMP'] else None\n        self.best_metric = -float('inf')\n    \n    def make_optimizer(self):\n        head_params = []\n        backbone_params = []\n        \n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                if 'text_model' in name or 'image_model' in name:\n                    backbone_params.append(param)\n                else:\n                    head_params.append(param)\n        \n        param_groups = [{'params': head_params, 'lr': self.cfg['LR_HEADS']}]\n        if backbone_params:\n            param_groups.append({'params': backbone_params, 'lr': self.cfg['LR_BACKBONE']})\n        \n        return torch.optim.AdamW(param_groups, weight_decay=self.cfg['WEIGHT_DECAY'])\n    \n    def train_epoch(self, epoch):\n        self.model.train()\n        total_loss = 0.0\n        \n        pbar = tqdm(self.train_loader, desc=f\"Epoch {epoch+1}/{self.cfg['EPOCHS']} [Train]\")\n        self.optimizer.zero_grad()\n        \n        for batch_idx, batch in enumerate(pbar):\n            batch_device = {k: v.to(self.device) for k, v in batch.items() if k != 'motivational_flag'}\n            \n            if self.cfg['USE_AMP']:\n                with autocast():\n                    outputs = self.model(batch_device['input_ids'], batch_device['attention_mask'], batch_device['image'])\n                    loss, l_sent, l_emo, l_int = combined_loss(outputs, batch_device, self.cfg, self.emotion_loss_fn)\n                    loss = loss / self.cfg['GRADIENT_ACCUMULATION_STEPS']\n                \n                self.scaler.scale(loss).backward()\n                \n                if (batch_idx + 1) % self.cfg['GRADIENT_ACCUMULATION_STEPS'] == 0:\n                    if self.cfg['GRADIENT_CLIP'] > 0:\n                        self.scaler.unscale_(self.optimizer)\n                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.cfg['GRADIENT_CLIP'])\n                    self.scaler.step(self.optimizer)\n                    self.scaler.update()\n                    self.optimizer.zero_grad()\n            else:\n                outputs = self.model(batch_device['input_ids'], batch_device['attention_mask'], batch_device['image'])\n                loss, l_sent, l_emo, l_int = combined_loss(outputs, batch_device, self.cfg, self.emotion_loss_fn)\n                loss = loss / self.cfg['GRADIENT_ACCUMULATION_STEPS']\n                loss.backward()\n                \n                if (batch_idx + 1) % self.cfg['GRADIENT_ACCUMULATION_STEPS'] == 0:\n                    if self.cfg['GRADIENT_CLIP'] > 0:\n                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.cfg['GRADIENT_CLIP'])\n                    self.optimizer.step()\n                    self.optimizer.zero_grad()\n            \n            total_loss += loss.item() * self.cfg['GRADIENT_ACCUMULATION_STEPS']\n            pbar.set_postfix({'loss': f\"{loss.item() * self.cfg['GRADIENT_ACCUMULATION_STEPS']:.4f}\"})\n        \n        return total_loss / len(self.train_loader)\n    \n    def validate(self, epoch):\n        self.model.eval()\n        total_loss = 0.0\n        \n        all_sentiment_labels = []\n        all_sentiment_outputs = []\n        all_emotion_labels = []\n        all_emotion_logits = []\n        \n        with torch.no_grad():\n            for batch in tqdm(self.val_loader, desc=f\"Epoch {epoch+1} [Val]\"):\n                batch_device = {k: v.to(self.device) for k, v in batch.items() if k != 'motivational_flag'}\n                \n                outputs = self.model(batch_device['input_ids'], batch_device['attention_mask'], batch_device['image'])\n                loss, _, _, _ = combined_loss(outputs, batch_device, self.cfg, self.emotion_loss_fn)\n                total_loss += loss.item()\n                \n                all_sentiment_labels.append(batch_device['sentiment_label'].cpu())\n                all_sentiment_outputs.append({\n                    'cumulative_logits': outputs['sentiment']['cumulative_logits'].cpu(),\n                    'class_probs': outputs['sentiment']['class_probs'].cpu()\n                })\n                all_emotion_labels.append(batch_device['emotion_labels'].cpu())\n                all_emotion_logits.append(outputs['emotion_logits'].cpu())\n        \n        all_sentiment_labels = torch.cat(all_sentiment_labels)\n        combined_sentiment = {\n            'cumulative_logits': torch.cat([o['cumulative_logits'] for o in all_sentiment_outputs]),\n            'class_probs': torch.cat([o['class_probs'] for o in all_sentiment_outputs])\n        }\n        all_emotion_labels = torch.cat(all_emotion_labels)\n        all_emotion_logits = torch.cat(all_emotion_logits)\n        \n        metrics = compute_metrics(\n            combined_sentiment,\n            all_sentiment_labels,\n            all_emotion_logits, \n            all_emotion_labels,\n            self.cfg['EMO_THRESHOLDS'],\n            self.cfg['SENTIMENT_EXPECTED_THRESHOLDS']\n        )\n        \n        avg_loss = total_loss / len(self.val_loader)\n        \n        print(f\"\\n{'='*70}\")\n        print(f\"Validation Results (Epoch {epoch+1}):\")\n        print(f\"  Loss: {avg_loss:.4f}\")\n        print(f\"  Sentiment Accuracy: {metrics['sentiment_accuracy']:.4f}\")\n        print(f\"  Sentiment F1: {metrics['sentiment_f1']:.4f}\")\n        print(f\"  Sentiment MAE: {metrics['sentiment_mae']:.4f}\")\n        print(f\"  Sentiment 1-off Acc: {metrics['sentiment_1off_accuracy']:.4f}\")\n        print(f\"  Emotion F1: {metrics['emotion_f1']:.4f}\")\n        print(f\"{'='*70}\\n\")\n        \n        return {**metrics, 'val_loss': avg_loss}\n    \n    def fit(self):\n        print(f\"\\n{'='*70}\")\n        print(f\"STARTING TRAINING: {self.cfg['EPOCHS']} EPOCHS\")\n        print(f\"{'='*70}\\n\")\n        \n        for epoch in range(self.cfg['EPOCHS']):\n            # Early backbone unfreezing\n            if epoch == self.cfg['UNFREEZE_BACKBONE_EPOCH']:\n                print(f\"\\n{'='*70}\")\n                print(f\"ðŸ”“ UNFREEZING BACKBONE at epoch {epoch+1}\")\n                print(f\"{'='*70}\\n\")\n                self.model.unfreeze_backbone(layers_to_unfreeze=self.cfg['UNFREEZE_LAYERS'])\n                self.optimizer = self.make_optimizer()\n                self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=self.cfg['EPOCHS'])\n            \n            train_loss = self.train_epoch(epoch)\n            print(f\"\\nTrain Loss: {train_loss:.4f}\")\n            \n            val_metrics = self.validate(epoch)\n            \n            if self.scheduler:\n                self.scheduler.step()\n            \n            # Composite metric (emphasis on emotion F1)\n            composite = (\n                val_metrics['sentiment_f1'] +\n                val_metrics['sentiment_1off_accuracy'] -\n                val_metrics['sentiment_mae'] +\n                val_metrics['emotion_f1'] * 1.5\n            )\n            \n            if composite > self.best_metric:\n                self.best_metric = composite\n                os.makedirs(self.cfg['CHECKPOINT_PATH'], exist_ok=True)\n                checkpoint_path = os.path.join(self.cfg['CHECKPOINT_PATH'], 'best_model_enhanced.pt')\n                torch.save({\n                    'epoch': epoch,\n                    'model_state_dict': self.model.state_dict(),\n                    'optimizer_state_dict': self.optimizer.state_dict(),\n                    'best_metric': self.best_metric,\n                    'metrics': val_metrics,\n                    'config': self.cfg\n                }, checkpoint_path)\n                print(f\"âœ“ Saved best model (composite: {composite:.4f})\")\n        \n        print(\"\\nâœ… TRAINING COMPLETED!\")\n        return self.best_metric\n\nprint(\"âœ“ Trainer class defined\")\n\n# ==================== PART 7: DATA LOADING ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 7: DATA LOADING & PREPARATION\")\nprint(\"=\" * 80)\n\n# Initialize tokenizer and transforms\ntokenizer = AutoTokenizer.from_pretrained(cfg['TEXT_MODEL'])\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((cfg['IMG_SIZE'], cfg['IMG_SIZE'])),\n    transforms.RandomHorizontalFlip(p=0.3),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n                       std=[0.26862954, 0.26130258, 0.27577711])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((cfg['IMG_SIZE'], cfg['IMG_SIZE'])),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n                       std=[0.26862954, 0.26130258, 0.27577711])\n])\n\nprint(\"âœ“ Tokenizer and transforms initialized\")\n\n# Create datasets\ntrain_dataset = MemeDataset(train_df, tokenizer, train_transform, NEW_TRAIN_DIR, cfg)\nval_dataset = MemeDataset(val_df, tokenizer, val_transform, NEW_VAL_DIR, cfg)\n\nprint(f\"âœ“ Train dataset: {len(train_dataset)} samples\")\nprint(f\"âœ“ Val dataset: {len(val_dataset)} samples\")\n\n# UPDATED: Create weighted sampler for motivational + extreme sentiment oversampling\nprint(\"\\nCreating weighted sampler...\")\nsample_weights = []\nmotivational_count = 0\nextreme_count = 0  # very_positive (0) + very_negative (4)\n\nfor idx in range(len(train_dataset)):\n    item = train_dataset[idx]\n    is_motivational = int(item['motivational_flag'].item())\n    sent_label = int(item['sentiment_label'].item())\n    \n    weight = 1.0\n    \n    # Motivational oversampling\n    if is_motivational:\n        weight *= cfg['MOTIVATIONAL_OVERSAMPLE_FACTOR']\n        motivational_count += 1\n    \n    # Extreme sentiment oversampling (very_positive=0, very_negative=4)\n    if sent_label in [0, 4]:\n        weight *= cfg['EXTREME_SENTIMENT_OVERSAMPLE_FACTOR']\n        extreme_count += 1\n    \n    sample_weights.append(weight)\n\nmotivational_pct = motivational_count / len(train_dataset) * 100 if len(train_dataset) > 0 else 0\nextreme_pct = extreme_count / len(train_dataset) * 100 if len(train_dataset) > 0 else 0\neffective_motivational = motivational_count * cfg['MOTIVATIONAL_OVERSAMPLE_FACTOR'] / len(train_dataset) * 100 if len(train_dataset) > 0 else 0\neffective_extreme = extreme_count * cfg['EXTREME_SENTIMENT_OVERSAMPLE_FACTOR'] / len(train_dataset) * 100 if len(train_dataset) > 0 else 0\n\nprint(f\"  Motivational samples: {motivational_count} ({motivational_pct:.2f}%)\")\nprint(f\"  Oversampling factor (motivational): {cfg['MOTIVATIONAL_OVERSAMPLE_FACTOR']}x\")\nprint(f\"  Effective motivational representation: {effective_motivational:.1f}%\")\n\nprint(f\"  Extreme sentiment samples (very_pos/very_neg): {extreme_count} ({extreme_pct:.2f}%)\")\nprint(f\"  Oversampling factor (extremes): {cfg['EXTREME_SENTIMENT_OVERSAMPLE_FACTOR']}x\")\nprint(f\"  Effective extreme representation: {effective_extreme:.1f}%\")\n\nsampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n\n# Create dataloaders\ntrain_loader = DataLoader(\n    train_dataset, batch_size=cfg['BATCH_SIZE'], sampler=sampler,\n    num_workers=2, pin_memory=True, drop_last=True\n)\n\nval_loader = DataLoader(\n    val_dataset, batch_size=cfg['BATCH_SIZE'], shuffle=False,\n    num_workers=2, pin_memory=True\n)\n\nprint(f\"âœ“ Train batches: {len(train_loader)}\")\nprint(f\"âœ“ Val batches: {len(val_loader)}\")\n\n# ==================== PART 8: MODEL INITIALIZATION & TRAINING ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 8: MODEL INITIALIZATION\")\nprint(\"=\" * 80)\n\nmodel = EnhancedFusionModel(cfg).to(device)\n\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f\"\\nModel Statistics:\")\nprint(f\"  Total parameters: {total_params:,}\")\nprint(f\"  Trainable parameters: {trainable_params:,}\")\nprint(f\"  Frozen parameters: {total_params - trainable_params:,}\")\n\n# Initialize enhanced emotion loss\nemotion_loss_fn = EnhancedAsymmetricLoss(\n    gamma_neg=cfg['ASL_GAMMA_NEG'],\n    gamma_pos=cfg['ASL_GAMMA_POS'],\n    clip=cfg['ASL_CLIP'],\n    priors=cfg['EMO_PRIORS'],\n    prior_tau=cfg['ASL_PRIOR_TAU']\n)\n\nprint(f\"\\nâœ“ Enhanced ASL initialized:\")\nprint(f\"  Î³_neg={cfg['ASL_GAMMA_NEG']}, Î³_pos={cfg['ASL_GAMMA_POS']}\")\nprint(f\"  Prior adjustment: Ï„={cfg['ASL_PRIOR_TAU']}\")\nprint(f\"  Priors: {[f'{p:.3f}' for p in cfg['EMO_PRIORS']]}\")\n\n# Initialize trainer\ntrainer = Trainer(model, cfg, train_loader, val_loader, device, emotion_loss_fn)\n\nprint(\"\\nâœ“ Trainer initialized\")\n\n# ==================== START TRAINING ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"STARTING TRAINING\")\nprint(\"=\" * 80)\n\nbest_metric = trainer.fit()\n\nprint(f\"\\n{'='*80}\")\nprint(f\"âœ… TRAINING COMPLETED!\")\nprint(f\"{'='*80}\")\nprint(f\"Best composite metric: {best_metric:.4f}\")\nprint(f\"Model saved to: {cfg['CHECKPOINT_PATH']}/best_model_enhanced.pt\")\n\n# Generate model card\nmodel_card = f\"\"\"# Enhanced Multi-modal Meme Analysis Model\n\n## Overview\nThis model uses a hybrid loss strategy combining ordinal regression for sentiment \nand enhanced asymmetric loss (ASL) with prior adjustment for emotions.\n\n## Key Improvements\n\n### 1. Hybrid Loss Strategy\n- **Sentiment**: Ordinal regression respects natural class ordering, with class-weighting\n  to emphasize extreme sentiments.\n- **Emotions**: Enhanced ASL with positive focusing (Î³_pos={cfg['ASL_GAMMA_POS']}) \n  and prior adjustment (Ï„={cfg['ASL_PRIOR_TAU']})\n- **Intensity**: Smooth L1 loss\n\n### 2. Oversampling Strategy\n- Motivational oversampling factor: {cfg['MOTIVATIONAL_OVERSAMPLE_FACTOR']}x\n- Extreme sentiment oversampling factor (very_positive / very_negative): {cfg['EXTREME_SENTIMENT_OVERSAMPLE_FACTOR']}x\n- Original motivational representation: {motivational_pct:.2f}%\n- Effective motivational representation: {effective_motivational:.1f}%\n- Original extreme representation: {extreme_pct:.2f}%\n- Effective extreme representation: {effective_extreme:.1f}%\n\n### 3. Early Backbone Unfreezing\n- Unfreezes at epoch {cfg['UNFREEZE_BACKBONE_EPOCH']}\n- Layers unfrozen: {cfg['UNFREEZE_LAYERS']}\n\n## Architecture\n- **Text**: {cfg['TEXT_MODEL']}\n- **Image**: {cfg['IMAGE_MODEL']}\n- **Fusion**: Bidirectional cross-attention\n- **Params**: {total_params:,} total, {trainable_params:,} trainable\n\n## Training Details\n- Epochs: {cfg['EPOCHS']}\n- Batch size: {cfg['BATCH_SIZE']}\n- LR (heads): {cfg['LR_HEADS']}\n- LR (backbone): {cfg['LR_BACKBONE']}\n- Loss weights: Sentiment={cfg['LOSS_WEIGHTS']['sentiment']}, \n  Emotion={cfg['LOSS_WEIGHTS']['emotion']}, Intensity={cfg['LOSS_WEIGHTS']['intensity']}\n\n## Performance\n- Best composite metric: {best_metric:.4f}\n\n## Dataset\n- Training samples: {len(train_df):,}\n- Validation samples: {len(val_df):,}\n\n## Usage\n\n```python\ncheckpoint = torch.load('best_model_enhanced.pt')\nmodel = EnhancedFusionModel(checkpoint['config']).to(device)\nmodel.load_state_dict(checkpoint['model_state_dict'])\nmodel.eval()\n\nwith torch.no_grad():\n    outputs = model(input_ids, attention_mask, image)\n    sentiment_probs = outputs['sentiment']['class_probs']\n    # Expected-value based decoding (same as validation):\n    num_classes = sentiment_probs.size(1)\n    ev = (sentiment_probs * torch.arange(num_classes, device=sentiment_probs.device)).sum(dim=1)\n    # Apply thresholds from config['SENTIMENT_EXPECTED_THRESHOLDS'] as in compute_metrics\n    emotions = torch.sigmoid(outputs['emotion_logits'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T23:28:50.560836Z","iopub.execute_input":"2025-11-20T23:28:50.561650Z","iopub.status.idle":"2025-11-20T23:28:50.633201Z","shell.execute_reply.started":"2025-11-20T23:28:50.561622Z","shell.execute_reply":"2025-11-20T23:28:50.632120Z"}},"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_202/2831241693.py\"\u001b[0;36m, line \u001b[0;32m997\u001b[0m\n\u001b[0;31m    model_card = f\"\"\"# Enhanced Multi-modal Meme Analysis Model\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"],"ename":"SyntaxError","evalue":"incomplete input (2831241693.py, line 997)","output_type":"error"}],"execution_count":7},{"cell_type":"code","source":"# ==================== COMPLETE ENHANCED MEME ANALYSIS PIPELINE ====================\n# This code includes BOTH data preparation AND enhanced training\n# Run this entire script from start to finish\n\n# ==================== PART 0: SETUP & DEPENDENCIES ====================\nimport sys, subprocess, os, json, zipfile, shutil, random, warnings\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom torch.cuda.amp import GradScaler, autocast\nimport torchvision.transforms as transforms\nfrom PIL import Image\nfrom tqdm import tqdm\nimport yaml\n\nwarnings.filterwarnings('ignore')\n\nprint(\"=\" * 80)\nprint(\"INSTALLING DEPENDENCIES...\")\nprint(\"=\" * 80)\n\n# Install required packages\nsubprocess.check_call([\n    sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n    \"transformers>=4.40.0\", \"accelerate\", \"torch\", \"timm\",\n    \"scikit-learn\", \"pandas\", \"matplotlib\", \"seaborn\",\n    \"huggingface_hub>=0.18.0\", \"gdown\", \"iterative-stratification\"\n])\n\n# Import additional packages\nfrom sklearn.metrics import (\n    accuracy_score, precision_recall_fscore_support,\n    mean_squared_error, mean_absolute_error, f1_score\n)\nfrom transformers import AutoModel, AutoTokenizer, CLIPModel\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n\nprint(\"âœ“ All dependencies installed\\n\")\n\n# ==================== PART 1: DATA PREPARATION ====================\nprint(\"=\" * 80)\nprint(\"PART 1: DATA PREPARATION\")\nprint(\"=\" * 80)\n\n# Download and extract dataset\nprint(\"\\nDownloading dataset...\")\nsubprocess.run([\"gdown\", \"1jEJ2nf5CDJknq80ogzU-Uyz7jbBi-1LZ\", \"--fuzzy\"], \n               check=False, capture_output=True)\n\nprint(\"Extracting dataset...\")\nzip_files = [f for f in os.listdir('.') if f.endswith('.zip')]\nif zip_files:\n    subprocess.run([\"unzip\", \"-q\", \"-o\", zip_files[0]], check=False, capture_output=True)\n\n# Download additional files\nsubprocess.run([\n    \"gdown\", \"--folder\", \"19yaav8ORSVj9DeJUaHKq1H3HtVnkClBw\", \"--remaining-ok\"\n], check=False, capture_output=True)\n\n# Extract password-protected archive\nprint(\"Extracting protected archive...\")\nzip_path = '/kaggle/working/Memotion 3/memotion3.zip'\nextract_to = '/kaggle/working/'\npassword = b'memotion3taskaaai@22'\n\nif os.path.exists(zip_path):\n    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n        zip_ref.extractall(extract_to, pwd=password)\n    print(f\"âœ“ Extracted to: {extract_to}\")\n\n# Setup paths\nORIGINAL_TRAIN_IMG_DIR = '/kaggle/working/trainImages/'\nORIGINAL_CSV_PATH = '/kaggle/working/memotion3/train.csv'\nVALIDATION_SPLIT_RATIO = 0.15\n\nOUTPUT_BASE_DIR = '/kaggle/working/'\nNEW_VAL_DIR = os.path.join(OUTPUT_BASE_DIR, 'validation_images/')\nNEW_TRAIN_DIR = os.path.join(OUTPUT_BASE_DIR, 'new_train_images/')\n\nos.makedirs(NEW_VAL_DIR, exist_ok=True)\nos.makedirs(NEW_TRAIN_DIR, exist_ok=True)\n\n# Load and process CSV\nprint(\"\\nLoading CSV file...\")\ndf = pd.read_csv(ORIGINAL_CSV_PATH)\n\n# Detect image column\npossible_image_cols = ['image_name', 'image', 'img_name', 'filename', 'Unnamed: 0']\nIMAGE_FILENAME_COLUMN = next((col for col in possible_image_cols if col in df.columns), df.columns[0])\nprint(f\"âœ“ Image column: {IMAGE_FILENAME_COLUMN}\")\n\n# Normalize labels\nfor col in ['offensive', 'motivational', 'humour', 'humor', 'sarcastic', 'sarcasm', 'overall', 'sentiment']:\n    if col in df.columns:\n        df[col] = df[col].astype(str).str.lower().str.strip()\n\n# Create binary labels\ndef create_binary_label(value, positive_values):\n    if pd.isna(value) or value in ['nan', 'none', '']:\n        return 0\n    return 1 if value in positive_values else 0\n\nif 'offensive' in df.columns:\n    df['offensive_bin'] = df['offensive'].apply(\n        lambda x: create_binary_label(x, ['slight', 'very_offensive', 'hateful_offensive'])\n    )\nelse:\n    df['offensive_bin'] = 0\n\nif 'motivational' in df.columns:\n    df['motivational_bin'] = df['motivational'].apply(\n        lambda x: create_binary_label(x, ['motivational'])\n    )\nelse:\n    df['motivational_bin'] = 0\n\nif 'humour' in df.columns or 'humor' in df.columns:\n    humor_col = 'humour' if 'humour' in df.columns else 'humor'\n    df['humor_bin'] = df[humor_col].apply(\n        lambda x: create_binary_label(x, ['funny', 'very_funny', 'hilarious'])\n    )\nelse:\n    df['humor_bin'] = 0\n\nif 'sarcastic' in df.columns or 'sarcasm' in df.columns:\n    sarcasm_col = 'sarcastic' if 'sarcastic' in df.columns else 'sarcasm'\n    df['sarcasm_bin'] = df[sarcasm_col].apply(\n        lambda x: create_binary_label(x, ['general', 'twisted_meaning', 'very_twisted'])\n    )\nelse:\n    df['sarcasm_bin'] = 0\n\n# Stratified split\nstratify_columns = ['offensive_bin', 'motivational_bin', 'humor_bin', 'sarcasm_bin']\ny_stratify = df[stratify_columns].values\n\nmsss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=VALIDATION_SPLIT_RATIO, random_state=42)\ntrain_idx, val_idx = next(msss.split(df, y_stratify))\n\ntrain_df = df.iloc[train_idx].reset_index(drop=True)\nval_df = df.iloc[val_idx].reset_index(drop=True)\n\nprint(f\"\\nâœ“ Stratified split complete:\")\nprint(f\"  Training: {len(train_df)} samples\")\nprint(f\"  Validation: {len(val_df)} samples\")\n\n# Calculate label priors\nlabel_priors = {\n    'offensive_pos_rate': float(train_df['offensive_bin'].sum() / len(train_df)),\n    'motivational_pos_rate': float(train_df['motivational_bin'].sum() / len(train_df)),\n    'humor_pos_rate': float(train_df['humor_bin'].sum() / len(train_df)),\n    'sarcasm_pos_rate': float(train_df['sarcasm_bin'].sum() / len(train_df))\n}\n\npriors_path = os.path.join(OUTPUT_BASE_DIR, 'label_priors.json')\nwith open(priors_path, 'w') as f:\n    json.dump(label_priors, f, indent=2)\n\nprint(f\"\\nâœ“ Label priors calculated:\")\nfor key, val in label_priors.items():\n    print(f\"  {key}: {val:.4f}\")\n\n# Copy images\ndef copy_images(df_subset, dest_dir, source_dir, image_col):\n    copied = 0\n    missing = 0\n    \n    for idx in tqdm(df_subset[image_col], desc=f\"Copying to {dest_dir}\"):\n        filename = str(idx)\n        if not any(filename.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif']):\n            for ext in ['.jpg', '.jpeg', '.png']:\n                test_path = os.path.join(source_dir, f\"{filename}{ext}\")\n                if os.path.exists(test_path):\n                    filename = f\"{filename}{ext}\"\n                    break\n            else:\n                filename = f\"{filename}.jpg\"\n        \n        source_path = os.path.join(source_dir, filename)\n        if os.path.exists(source_path):\n            shutil.copy(source_path, os.path.join(dest_dir, filename))\n            copied += 1\n        else:\n            missing += 1\n    \n    return copied, missing\n\nprint(\"\\nCopying images...\")\ncopied_val, missing_val = copy_images(val_df, NEW_VAL_DIR, ORIGINAL_TRAIN_IMG_DIR, IMAGE_FILENAME_COLUMN)\ncopied_train, missing_train = copy_images(train_df, NEW_TRAIN_DIR, ORIGINAL_TRAIN_IMG_DIR, IMAGE_FILENAME_COLUMN)\n\nprint(f\"âœ“ Validation: {copied_val} copied, {missing_val} missing\")\nprint(f\"âœ“ Training: {copied_train} copied, {missing_train} missing\")\n\n# Save CSVs\ntrain_csv_path = os.path.join(OUTPUT_BASE_DIR, 'train_split.csv')\nval_csv_path = os.path.join(OUTPUT_BASE_DIR, 'validation_split.csv')\n\ntrain_df.to_csv(train_csv_path, index=False)\nval_df.to_csv(val_csv_path, index=False)\n\nprint(f\"\\nâœ“ Saved train CSV: {train_csv_path}\")\nprint(f\"âœ“ Saved validation CSV: {val_csv_path}\")\nprint(\"\\nâœ… DATA PREPARATION COMPLETE\\n\")\n\n# ==================== PART 2: CONFIGURATION ====================\nprint(\"=\" * 80)\nprint(\"PART 2: CONFIGURATION\")\nprint(\"=\" * 80)\n\nCONFIG_YAML = \"\"\"\nTEXT_MODEL: \"google/muril-base-cased\"\nIMAGE_MODEL: \"openai/clip-vit-base-patch32\"\nTEXT_DIM: 768\nIMAGE_DIM: 768\nFUSION_DIM: 512\nFUSION_OUT_DIM: 512\n\nMAX_LEN: 128\nIMG_SIZE: 224\nBATCH_SIZE: 16\nGRADIENT_ACCUMULATION_STEPS: 2\nLR_HEADS: 0.001\nLR_BACKBONE: 0.00002\nWEIGHT_DECAY: 0.01\nEPOCHS: 20\nSEED: 42\nDEVICE: \"cuda\"\nCHECKPOINT_PATH: \"/kaggle/working/checkpoints\"\n\nNUM_SENTIMENT_CLASSES: 5\nNUM_EMOTION_CLASSES: 4\n\nUSE_ORDINAL_REGRESSION: true\nORDINAL_LINK: \"logit\"\n\nLOSS_WEIGHTS:\n  sentiment: 2.0\n  emotion: 1.5\n  intensity: 0.5\n\nASL_GAMMA_NEG: 6.0\nASL_GAMMA_POS: 0.5\nASL_CLIP: 0.05\nASL_PRIOR_TAU: 1.2\n\nEMOTION_LABELS: [\"humor\", \"sarcasm\", \"offensive\", \"motivational\"]\nEMO_THRESHOLDS: [0.5, 0.5, 0.60, 0.60]\n\n# thresholds for expected-value based sentiment decoding\nSENTIMENT_EXPECTED_THRESHOLDS: [0.5, 1.5, 2.5, 3.5]\n\n# class weights for ordinal loss (upweight extremes 0 and 4)\nSENTIMENT_CLASS_WEIGHTS: [1.5, 1.0, 1.0, 1.0, 1.5]\n\nPOOLING: \"mean\"\nUSE_AMP: true\nGRADIENT_CLIP: 1.0\nSCHEDULER: \"cosine\"\nUNFREEZE_BACKBONE_EPOCH: 2\nUNFREEZE_LAYERS: 3\n\nMOTIVATIONAL_OVERSAMPLE_FACTOR: 8.0\n\n# oversampling factor for extreme sentiment classes (very_positive & very_negative)\nEXTREME_SENTIMENT_OVERSAMPLE_FACTOR: 5.0\n\nCROSS_ATTN_HEADS: 8\nCROSS_ATTN_DROPOUT: 0.1\n\nSENTIMENT_MAP_REV:\n  0: \"very_positive\"\n  1: \"positive\"\n  2: \"neutral\"\n  3: \"negative\"\n  4: \"very_negative\"\n\"\"\"\n\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\ncfg = yaml.safe_load(CONFIG_YAML)\nset_seed(cfg['SEED'])\n\n# Load priors\nwith open(priors_path, 'r') as f:\n    priors = json.load(f)\n\ncfg['EMO_PRIORS'] = [\n    priors['humor_pos_rate'],\n    priors['sarcasm_pos_rate'],\n    priors['offensive_pos_rate'],\n    priors['motivational_pos_rate']\n]\n\ndevice = torch.device(cfg['DEVICE'] if torch.cuda.is_available() else 'cpu')\n\nprint(f\"\\nâœ“ Configuration loaded:\")\nprint(f\"  Device: {device}\")\nprint(f\"  Epochs: {cfg['EPOCHS']}\")\nprint(f\"  Batch size: {cfg['BATCH_SIZE']}\")\nprint(f\"  Motivational oversampling: {cfg['MOTIVATIONAL_OVERSAMPLE_FACTOR']}x\")\nprint(f\"  Extreme sentiment oversampling: {cfg['EXTREME_SENTIMENT_OVERSAMPLE_FACTOR']}x\")\nprint(f\"  Emotion priors: {[f'{p:.3f}' for p in cfg['EMO_PRIORS']]}\")\n\n# ==================== PART 3: MODEL COMPONENTS ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 3: MODEL COMPONENTS\")\nprint(\"=\" * 80)\n\nclass EnhancedAsymmetricLoss(nn.Module):\n    \"\"\"Enhanced ASL with prior adjustment\"\"\"\n    def __init__(self, gamma_neg=6.0, gamma_pos=0.5, clip=0.05, priors=None, prior_tau=1.2, eps=1e-8):\n        super().__init__()\n        self.gamma_neg = gamma_neg\n        self.gamma_pos = gamma_pos\n        self.clip = clip\n        self.eps = eps\n        self.priors = priors\n        self.prior_tau = prior_tau\n    \n    def forward(self, logits, targets):\n        # Prior adjustment\n        if self.priors is not None:\n            priors_tensor = torch.tensor(self.priors, device=logits.device, dtype=logits.dtype)\n            adjustment = self.prior_tau * torch.log(priors_tensor.clamp(min=self.eps))\n            logits = logits - adjustment\n        \n        xs_pos = torch.sigmoid(logits)\n        xs_neg = 1 - xs_pos\n        \n        if self.clip is not None and self.clip > 0:\n            xs_neg = (xs_neg + self.clip).clamp(max=1)\n        \n        los_pos = targets * torch.log(xs_pos.clamp(min=self.eps))\n        los_neg = (1 - targets) * torch.log(xs_neg.clamp(min=self.eps))\n        \n        if self.gamma_neg > 0 or self.gamma_pos > 0:\n            pt0 = xs_pos * targets\n            pt1 = xs_neg * (1 - targets)\n            pt = pt0 + pt1\n            one_sided_gamma = self.gamma_pos * targets + self.gamma_neg * (1 - targets)\n            one_sided_w = torch.pow(1 - pt, one_sided_gamma)\n            loss = one_sided_w * (los_pos + los_neg)\n        else:\n            loss = los_pos + los_neg\n        \n        return -loss.mean()\n\nclass OrdinalRegressionHead(nn.Module):\n    \"\"\"Ordinal regression using cumulative link model\"\"\"\n    def __init__(self, input_dim, num_classes):\n        super().__init__()\n        self.num_classes = num_classes\n        self.num_thresholds = num_classes - 1\n        \n        self.projection = nn.Sequential(\n            nn.Linear(input_dim, 256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, 1)\n        )\n        \n        initial_thresholds = torch.linspace(-2, 2, self.num_thresholds)\n        self.thresholds = nn.Parameter(initial_thresholds)\n    \n    def forward(self, x):\n        score = self.projection(x).squeeze(-1)\n        ordered_thresholds = torch.cumsum(F.softplus(self.thresholds), dim=0)\n        cumulative_logits = ordered_thresholds.unsqueeze(0) - score.unsqueeze(1)\n        cumulative_probs = torch.sigmoid(cumulative_logits)\n        \n        batch_size = cumulative_probs.size(0)\n        class_probs = torch.zeros(batch_size, self.num_classes, device=x.device)\n        \n        class_probs[:, 0] = cumulative_probs[:, 0]\n        for k in range(1, self.num_thresholds):\n            class_probs[:, k] = cumulative_probs[:, k] - cumulative_probs[:, k-1]\n        class_probs[:, -1] = 1.0 - cumulative_probs[:, -1]\n        class_probs = torch.clamp(class_probs, min=1e-7, max=1.0)\n        \n        return {'cumulative_logits': cumulative_logits, 'class_probs': class_probs}\n\nclass CrossAttentionFusion(nn.Module):\n    \"\"\"Bidirectional cross-attention\"\"\"\n    def __init__(self, dim, num_heads=8, dropout=0.1):\n        super().__init__()\n        self.text_to_image_attn = nn.MultiheadAttention(dim, num_heads, dropout, batch_first=True)\n        self.image_to_text_attn = nn.MultiheadAttention(dim, num_heads, dropout, batch_first=True)\n        self.text_norm = nn.LayerNorm(dim)\n        self.image_norm = nn.LayerNorm(dim)\n        self.text_ffn = nn.Sequential(\n            nn.Linear(dim, dim * 4), nn.GELU(), nn.Dropout(dropout),\n            nn.Linear(dim * 4, dim), nn.Dropout(dropout)\n        )\n        self.image_ffn = nn.Sequential(\n            nn.Linear(dim, dim * 4), nn.GELU(), nn.Dropout(dropout),\n            nn.Linear(dim * 4, dim), nn.Dropout(dropout)\n        )\n        self.ffn_norm_text = nn.LayerNorm(dim)\n        self.ffn_norm_image = nn.LayerNorm(dim)\n    \n    def forward(self, text_emb, image_emb):\n        text_seq = text_emb.unsqueeze(1)\n        image_seq = image_emb.unsqueeze(1)\n        \n        text_attended, _ = self.text_to_image_attn(text_seq, image_seq, image_seq)\n        text_out = self.text_norm(text_emb + text_attended.squeeze(1))\n        \n        image_attended, _ = self.image_to_text_attn(image_seq, text_seq, text_seq)\n        image_out = self.image_norm(image_emb + image_attended.squeeze(1))\n        \n        text_final = self.ffn_norm_text(text_out + self.text_ffn(text_out))\n        image_final = self.ffn_norm_image(image_out + self.image_ffn(image_out))\n        \n        return text_final, image_final\n\nclass EnhancedFusionModel(nn.Module):\n    \"\"\"Multi-modal model with ordinal regression + enhanced ASL\"\"\"\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg = cfg\n        \n        self.text_model = AutoModel.from_pretrained(cfg['TEXT_MODEL'])\n        clip_model = CLIPModel.from_pretrained(cfg['IMAGE_MODEL'])\n        self.image_model = clip_model.vision_model\n        \n        self._freeze_encoders()\n        \n        self.text_proj = nn.Linear(cfg['TEXT_DIM'], cfg['FUSION_DIM'])\n        self.image_proj = nn.Linear(cfg['IMAGE_DIM'], cfg['FUSION_DIM'])\n        \n        self.cross_attention = CrossAttentionFusion(\n            dim=cfg['FUSION_DIM'],\n            num_heads=cfg['CROSS_ATTN_HEADS'],\n            dropout=cfg['CROSS_ATTN_DROPOUT']\n        )\n        \n        fusion_input_dim = cfg['FUSION_DIM'] * 2\n        self.fusion_norm = nn.LayerNorm(fusion_input_dim)\n        self.fusion_mlp = nn.Sequential(\n            nn.Linear(fusion_input_dim, 512), nn.GELU(), nn.Dropout(0.2),\n            nn.Linear(512, cfg['FUSION_OUT_DIM']), nn.LayerNorm(cfg['FUSION_OUT_DIM'])\n        )\n        \n        self.sentiment_head = OrdinalRegressionHead(cfg['FUSION_OUT_DIM'], cfg['NUM_SENTIMENT_CLASSES'])\n        self.emotion_head = nn.Sequential(\n            nn.Linear(cfg['FUSION_OUT_DIM'], 256), nn.ReLU(), nn.Dropout(0.2),\n            nn.Linear(256, cfg['NUM_EMOTION_CLASSES'])\n        )\n        self.intensity_head = nn.Sequential(\n            nn.Linear(cfg['FUSION_OUT_DIM'], 128), nn.ReLU(), nn.Dropout(0.2),\n            nn.Linear(128, 1)\n        )\n    \n    def _freeze_encoders(self):\n        for param in self.text_model.parameters():\n            param.requires_grad = False\n        for param in self.image_model.parameters():\n            param.requires_grad = False\n    \n    def unfreeze_backbone(self, layers_to_unfreeze=3):\n        if hasattr(self.text_model, 'encoder') and hasattr(self.text_model.encoder, 'layer'):\n            for layer in list(self.text_model.encoder.layer[-layers_to_unfreeze:]):\n                for param in layer.parameters():\n                    param.requires_grad = True\n        \n        if hasattr(self.image_model, 'encoder') and hasattr(self.image_model.encoder, 'layers'):\n            for layer in list(self.image_model.encoder.layers[-layers_to_unfreeze:]):\n                for param in layer.parameters():\n                    param.requires_grad = True\n    \n    def pool_text(self, model_output, attention_mask):\n        last_hidden = model_output.last_hidden_state\n        if self.cfg['POOLING'] == 'cls':\n            return last_hidden[:, 0]\n        mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden.size()).float()\n        sum_embeddings = torch.sum(last_hidden * mask_expanded, 1)\n        sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n        return sum_embeddings / sum_mask\n    \n    def forward(self, input_ids, attention_mask, image):\n        text_output = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n        text_emb = self.pool_text(text_output, attention_mask)\n        \n        image_output = self.image_model(pixel_values=image)\n        image_emb = image_output.pooler_output\n        \n        text_proj = self.text_proj(text_emb)\n        image_proj = self.image_proj(image_emb)\n        \n        text_cross, image_cross = self.cross_attention(text_proj, image_proj)\n        \n        fused = torch.cat([text_cross, image_cross], dim=1)\n        fused = self.fusion_norm(fused)\n        fused = self.fusion_mlp(fused)\n        \n        sentiment_outputs = self.sentiment_head(fused)\n        emotion_logits = self.emotion_head(fused)\n        intensity = self.intensity_head(fused).squeeze(-1)\n        \n        return {\n            'sentiment': sentiment_outputs,\n            'emotion_logits': emotion_logits,\n            'intensity': intensity\n        }\n\nprint(\"âœ“ Model components defined\")\n\n# ==================== PART 4: DATASET ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 4: DATASET\")\nprint(\"=\" * 80)\n\nclass MemeDataset(Dataset):\n    def __init__(self, df, tokenizer, image_transform, image_dir, cfg):\n        self.df = df.reset_index(drop=True)\n        self.tokenizer = tokenizer\n        self.image_transform = image_transform\n        self.image_dir = image_dir\n        self.cfg = cfg\n        self._detect_columns()\n    \n    def _detect_columns(self):\n        cols = self.df.columns.tolist()\n        self.image_col = next((c for c in ['image_name', 'image', 'img_name', 'filename', 'Unnamed: 0'] if c in cols), cols[0])\n        self.text_col = next((c for c in ['text', 'ocr_text', 'caption', 'OCR_extracted_text'] if c in cols), None)\n        self.sentiment_col = next((c for c in ['sentiment', 'overall_sentiment', 'overall'] if c in cols), None)\n        \n        self.sentiment_map = {'very_positive': 0, 'positive': 1, 'neutral': 2, 'negative': 3, 'very_negative': 4}\n        self.humor_map = {'not_funny': 0, 'funny': 1, 'very_funny': 1, 'hilarious': 1}\n        self.sarcasm_map = {'not_sarcastic': 0, 'general': 1, 'twisted_meaning': 1, 'very_twisted': 1}\n        self.offensive_map = {'not_offensive': 0, 'slight': 1, 'very_offensive': 1, 'hateful_offensive': 1}\n        self.motivational_map = {'not_motivational': 0, 'motivational': 1}\n    \n    def _map_label(self, value, mapping, default=0):\n        if pd.isna(value):\n            return default\n        if isinstance(value, str):\n            return mapping.get(value.lower().strip(), default)\n        return int(value)\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        \n        image_name = str(row[self.image_col])\n        if not any(image_name.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png']):\n            image_name = f\"{image_name}.jpg\"\n        image_path = os.path.join(self.image_dir, image_name)\n        \n        try:\n            image = Image.open(image_path).convert('RGB')\n            image = self.image_transform(image)\n        except:\n            image = torch.zeros(3, self.cfg['IMG_SIZE'], self.cfg['IMG_SIZE'])\n        \n        text = str(row.get(self.text_col, '')) if self.text_col else 'No text'\n        encoding = self.tokenizer(text, max_length=self.cfg['MAX_LEN'], padding='max_length', truncation=True, return_tensors='pt')\n        \n        sentiment_val = row.get(self.sentiment_col, 'neutral') if self.sentiment_col else 'neutral'\n        sentiment_label = self._map_label(sentiment_val, self.sentiment_map, default=2)\n        \n        emotion_labels = torch.tensor([\n            float(self._map_label(row.get('humour', row.get('humor', 0)), self.humor_map, 0)),\n            float(self._map_label(row.get('sarcastic', row.get('sarcasm', 0)), self.sarcasm_map, 0)),\n            float(self._map_label(row.get('offensive', 0), self.offensive_map, 0)),\n            float(self._map_label(row.get('motivational', 0), self.motivational_map, 0))\n        ], dtype=torch.float)\n        \n        return {\n            'input_ids': encoding['input_ids'].squeeze(0),\n            'attention_mask': encoding['attention_mask'].squeeze(0),\n            'image': image,\n            'sentiment_label': torch.tensor(sentiment_label, dtype=torch.long),\n            'emotion_labels': emotion_labels,\n            'intensity': torch.tensor(0.5, dtype=torch.float),\n            'motivational_flag': emotion_labels[3]\n        }\n\nprint(\"âœ“ Dataset class defined\")\n\n# ==================== PART 5: LOSS & METRICS ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 5: LOSS FUNCTIONS & METRICS\")\nprint(\"=\" * 80)\n\ndef ordinal_regression_loss(cumulative_logits, labels, class_weights=None):\n    batch_size = labels.size(0)\n    num_thresholds = cumulative_logits.size(1)\n    target_cumulative = torch.zeros_like(cumulative_logits)\n    \n    for i in range(batch_size):\n        y = int(labels[i].item())\n        if y < num_thresholds:\n            target_cumulative[i, y:] = 1.0\n    \n    loss_matrix = F.binary_cross_entropy_with_logits(\n        cumulative_logits, target_cumulative, reduction='none'\n    )\n    \n    if class_weights is not None:\n        cw = torch.tensor(class_weights, device=labels.device, dtype=loss_matrix.dtype)\n        sample_weights = cw[labels]\n        loss_matrix = loss_matrix * sample_weights.unsqueeze(1)\n    \n    return loss_matrix.mean()\n\ndef combined_loss(outputs, batch, cfg, emotion_loss_fn):\n    loss_sent = ordinal_regression_loss(\n        outputs['sentiment']['cumulative_logits'],\n        batch['sentiment_label'],\n        cfg.get('SENTIMENT_CLASS_WEIGHTS')\n    )\n    loss_emotion = emotion_loss_fn(outputs['emotion_logits'], batch['emotion_labels'])\n    loss_intensity = F.smooth_l1_loss(outputs['intensity'], batch['intensity'])\n    \n    total_loss = (\n        cfg['LOSS_WEIGHTS']['sentiment'] * loss_sent +\n        cfg['LOSS_WEIGHTS']['emotion'] * loss_emotion +\n        cfg['LOSS_WEIGHTS']['intensity'] * loss_intensity\n    )\n    \n    return total_loss, loss_sent, loss_emotion, loss_intensity\n\ndef compute_metrics(sentiment_outputs, sentiment_labels, emotion_logits, emotion_labels,\n                    emotion_thresholds, expected_thresholds):\n    class_probs = sentiment_outputs['class_probs']\n    num_classes = class_probs.size(1)\n    \n    y_true = sentiment_labels.cpu().numpy()\n    class_probs_np = class_probs.cpu().numpy()\n    \n    ev = np.sum(class_probs_np * np.arange(num_classes), axis=1)\n    ev_thresholds = np.array(expected_thresholds)\n    y_pred = np.digitize(ev, bins=ev_thresholds)\n    \n    sent_acc = accuracy_score(y_true, y_pred)\n    _, _, sent_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)\n    sent_mae = mean_absolute_error(y_true, y_pred)\n    sent_1off = np.mean(np.abs(y_true - y_pred) <= 1)\n    \n    emo_probs = torch.sigmoid(emotion_logits).cpu().numpy()\n    emo_true = emotion_labels.cpu().numpy()\n    emo_thresholds = np.array(emotion_thresholds)\n    emo_pred = (emo_probs >= emo_thresholds).astype(float)\n    \n    _, _, emo_f1, _ = precision_recall_fscore_support(emo_true, emo_pred, average='samples', zero_division=0)\n    \n    return {\n        'sentiment_accuracy': sent_acc,\n        'sentiment_f1': sent_f1,\n        'sentiment_mae': sent_mae,\n        'sentiment_1off_accuracy': sent_1off,\n        'emotion_f1': emo_f1\n    }\n\nprint(\"âœ“ Loss functions and metrics defined\")\n\n# ==================== PART 6: TRAINER ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 6: TRAINER\")\nprint(\"=\" * 80)\n\nclass Trainer:\n    def __init__(self, model, cfg, train_loader, val_loader, device, emotion_loss_fn):\n        self.model = model\n        self.cfg = cfg\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.device = device\n        self.emotion_loss_fn = emotion_loss_fn\n        \n        self.optimizer = self.make_optimizer()\n        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=cfg['EPOCHS'])\n        self.scaler = GradScaler() if cfg['USE_AMP'] else None\n        self.best_metric = -float('inf')\n    \n    def make_optimizer(self):\n        head_params = []\n        backbone_params = []\n        \n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                if 'text_model' in name or 'image_model' in name:\n                    backbone_params.append(param)\n                else:\n                    head_params.append(param)\n        \n        param_groups = [{'params': head_params, 'lr': self.cfg['LR_HEADS']}]\n        if backbone_params:\n            param_groups.append({'params': backbone_params, 'lr': self.cfg['LR_BACKBONE']})\n        \n        return torch.optim.AdamW(param_groups, weight_decay=self.cfg['WEIGHT_DECAY'])\n    \n    def train_epoch(self, epoch):\n        self.model.train()\n        total_loss = 0.0\n        \n        pbar = tqdm(self.train_loader, desc=f\"Epoch {epoch+1}/{self.cfg['EPOCHS']} [Train]\")\n        self.optimizer.zero_grad()\n        \n        for batch_idx, batch in enumerate(pbar):\n            batch_device = {k: v.to(self.device) for k, v in batch.items() if k != 'motivational_flag'}\n            \n            if self.cfg['USE_AMP']:\n                with autocast():\n                    outputs = self.model(batch_device['input_ids'], batch_device['attention_mask'], batch_device['image'])\n                    loss, l_sent, l_emo, l_int = combined_loss(outputs, batch_device, self.cfg, self.emotion_loss_fn)\n                    loss = loss / self.cfg['GRADIENT_ACCUMULATION_STEPS']\n                \n                self.scaler.scale(loss).backward()\n                \n                if (batch_idx + 1) % self.cfg['GRADIENT_ACCUMULATION_STEPS'] == 0:\n                    if self.cfg['GRADIENT_CLIP'] > 0:\n                        self.scaler.unscale_(self.optimizer)\n                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.cfg['GRADIENT_CLIP'])\n                    self.scaler.step(self.optimizer)\n                    self.scaler.update()\n                    self.optimizer.zero_grad()\n            else:\n                outputs = self.model(batch_device['input_ids'], batch_device['attention_mask'], batch_device['image'])\n                loss, l_sent, l_emo, l_int = combined_loss(outputs, batch_device, self.cfg, self.emotion_loss_fn)\n                loss = loss / self.cfg['GRADIENT_ACCUMULATION_STEPS']\n                loss.backward()\n                \n                if (batch_idx + 1) % self.cfg['GRADIENT_ACCUMULATION_STEPS'] == 0:\n                    if self.cfg['GRADIENT_CLIP'] > 0:\n                        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.cfg['GRADIENT_CLIP'])\n                    self.optimizer.step()\n                    self.optimizer.zero_grad()\n            \n            total_loss += loss.item() * self.cfg['GRADIENT_ACCUMULATION_STEPS']\n            pbar.set_postfix({'loss': f\"{loss.item() * self.cfg['GRADIENT_ACCUMULATION_STEPS']:.4f}\"})\n        \n        return total_loss / len(self.train_loader)\n    \n    def validate(self, epoch):\n        self.model.eval()\n        total_loss = 0.0\n        \n        all_sentiment_labels = []\n        all_sentiment_outputs = []\n        all_emotion_labels = []\n        all_emotion_logits = []\n        \n        with torch.no_grad():\n            for batch in tqdm(self.val_loader, desc=f\"Epoch {epoch+1} [Val]\"):\n                batch_device = {k: v.to(self.device) for k, v in batch.items() if k != 'motivational_flag'}\n                \n                outputs = self.model(batch_device['input_ids'], batch_device['attention_mask'], batch_device['image'])\n                loss, _, _, _ = combined_loss(outputs, batch_device, self.cfg, self.emotion_loss_fn)\n                total_loss += loss.item()\n                \n                all_sentiment_labels.append(batch_device['sentiment_label'].cpu())\n                all_sentiment_outputs.append({\n                    'cumulative_logits': outputs['sentiment']['cumulative_logits'].cpu(),\n                    'class_probs': outputs['sentiment']['class_probs'].cpu()\n                })\n                all_emotion_labels.append(batch_device['emotion_labels'].cpu())\n                all_emotion_logits.append(outputs['emotion_logits'].cpu())\n        \n        all_sentiment_labels = torch.cat(all_sentiment_labels)\n        combined_sentiment = {\n            'cumulative_logits': torch.cat([o['cumulative_logits'] for o in all_sentiment_outputs]),\n            'class_probs': torch.cat([o['class_probs'] for o in all_sentiment_outputs])\n        }\n        all_emotion_labels = torch.cat(all_emotion_labels)\n        all_emotion_logits = torch.cat(all_emotion_logits)\n        \n        metrics = compute_metrics(\n            combined_sentiment,\n            all_sentiment_labels,\n            all_emotion_logits, \n            all_emotion_labels,\n            self.cfg['EMO_THRESHOLDS'],\n            self.cfg['SENTIMENT_EXPECTED_THRESHOLDS']\n        )\n        \n        avg_loss = total_loss / len(self.val_loader)\n        \n        print(f\"\\n{'='*70}\")\n        print(f\"Validation Results (Epoch {epoch+1}):\")\n        print(f\"  Loss: {avg_loss:.4f}\")\n        print(f\"  Sentiment Accuracy: {metrics['sentiment_accuracy']:.4f}\")\n        print(f\"  Sentiment F1: {metrics['sentiment_f1']:.4f}\")\n        print(f\"  Sentiment MAE: {metrics['sentiment_mae']:.4f}\")\n        print(f\"  Sentiment 1-off Acc: {metrics['sentiment_1off_accuracy']:.4f}\")\n        print(f\"  Emotion F1: {metrics['emotion_f1']:.4f}\")\n        print(f\"{'='*70}\\n\")\n        \n        return {**metrics, 'val_loss': avg_loss}\n    \n    def fit(self):\n        print(f\"\\n{'='*70}\")\n        print(f\"STARTING TRAINING: {self.cfg['EPOCHS']} EPOCHS\")\n        print(f\"{'='*70}\\n\")\n        \n        for epoch in range(self.cfg['EPOCHS']):\n            if epoch == self.cfg['UNFREEZE_BACKBONE_EPOCH']:\n                print(f\"\\n{'='*70}\")\n                print(f\"ðŸ”“ UNFREEZING BACKBONE at epoch {epoch+1}\")\n                print(f\"{'='*70}\\n\")\n                self.model.unfreeze_backbone(layers_to_unfreeze=self.cfg['UNFREEZE_LAYERS'])\n                self.optimizer = self.make_optimizer()\n                self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=self.cfg['EPOCHS'])\n            \n            train_loss = self.train_epoch(epoch)\n            print(f\"\\nTrain Loss: {train_loss:.4f}\")\n            \n            val_metrics = self.validate(epoch)\n            \n            if self.scheduler:\n                self.scheduler.step()\n            \n            composite = (\n                val_metrics['sentiment_f1'] +\n                val_metrics['sentiment_1off_accuracy'] -\n                val_metrics['sentiment_mae'] +\n                val_metrics['emotion_f1'] * 1.5\n            )\n            \n            if composite > self.best_metric:\n                self.best_metric = composite\n                os.makedirs(self.cfg['CHECKPOINT_PATH'], exist_ok=True)\n                checkpoint_path = os.path.join(self.cfg['CHECKPOINT_PATH'], 'best_model_enhanced.pt')\n                torch.save({\n                    'epoch': epoch,\n                    'model_state_dict': self.model.state_dict(),\n                    'optimizer_state_dict': self.optimizer.state_dict(),\n                    'best_metric': self.best_metric,\n                    'metrics': val_metrics,\n                    'config': self.cfg\n                }, checkpoint_path)\n                print(f\"âœ“ Saved best model (composite: {composite:.4f})\")\n        \n        print(\"\\nâœ… TRAINING COMPLETED!\")\n        return self.best_metric\n\nprint(\"âœ“ Trainer class defined\")\n\n# ==================== PART 7: DATA LOADING ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 7: DATA LOADING & PREPARATION\")\nprint(\"=\" * 80)\n\ntokenizer = AutoTokenizer.from_pretrained(cfg['TEXT_MODEL'])\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((cfg['IMG_SIZE'], cfg['IMG_SIZE'])),\n    transforms.RandomHorizontalFlip(p=0.3),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n                       std=[0.26862954, 0.26130258, 0.27577711])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((cfg['IMG_SIZE'], cfg['IMG_SIZE'])),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n                       std=[0.26862954, 0.26130258, 0.27577711])\n])\n\nprint(\"âœ“ Tokenizer and transforms initialized\")\n\ntrain_dataset = MemeDataset(train_df, tokenizer, train_transform, NEW_TRAIN_DIR, cfg)\nval_dataset = MemeDataset(val_df, tokenizer, val_transform, NEW_VAL_DIR, cfg)\n\nprint(f\"âœ“ Train dataset: {len(train_dataset)} samples\")\nprint(f\"âœ“ Val dataset: {len(val_dataset)} samples\")\n\nprint(\"\\nCreating weighted sampler...\")\nsample_weights = []\nmotivational_count = 0\nextreme_count = 0\n\nfor idx in range(len(train_dataset)):\n    item = train_dataset[idx]\n    is_motivational = int(item['motivational_flag'].item())\n    sent_label = int(item['sentiment_label'].item())\n    \n    weight = 1.0\n    \n    if is_motivational:\n        weight *= cfg['MOTIVATIONAL_OVERSAMPLE_FACTOR']\n        motivational_count += 1\n    \n    if sent_label in [0, 4]:\n        weight *= cfg['EXTREME_SENTIMENT_OVERSAMPLE_FACTOR']\n        extreme_count += 1\n    \n    sample_weights.append(weight)\n\nif len(train_dataset) > 0:\n    motivational_pct = motivational_count / len(train_dataset) * 100\n    extreme_pct = extreme_count / len(train_dataset) * 100\n    effective_motivational = motivational_count * cfg['MOTIVATIONAL_OVERSAMPLE_FACTOR'] / len(train_dataset) * 100\n    effective_extreme = extreme_count * cfg['EXTREME_SENTIMENT_OVERSAMPLE_FACTOR'] / len(train_dataset) * 100\nelse:\n    motivational_pct = extreme_pct = effective_motivational = effective_extreme = 0.0\n\nprint(f\"  Motivational samples: {motivational_count} ({motivational_pct:.2f}%)\")\nprint(f\"  Oversampling factor (motivational): {cfg['MOTIVATIONAL_OVERSAMPLE_FACTOR']}x\")\nprint(f\"  Effective motivational representation: {effective_motivational:.1f}%\")\nprint(f\"  Extreme sentiment samples (very_pos/very_neg): {extreme_count} ({extreme_pct:.2f}%)\")\nprint(f\"  Oversampling factor (extremes): {cfg['EXTREME_SENTIMENT_OVERSAMPLE_FACTOR']}x\")\nprint(f\"  Effective extreme representation: {effective_extreme:.1f}%\")\n\nsampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n\ntrain_loader = DataLoader(\n    train_dataset, batch_size=cfg['BATCH_SIZE'], sampler=sampler,\n    num_workers=2, pin_memory=True, drop_last=True\n)\n\nval_loader = DataLoader(\n    val_dataset, batch_size=cfg['BATCH_SIZE'], shuffle=False,\n    num_workers=2, pin_memory=True\n)\n\nprint(f\"âœ“ Train batches: {len(train_loader)}\")\nprint(f\"âœ“ Val batches: {len(val_loader)}\")\n\n# ==================== PART 8: MODEL INITIALIZATION & TRAINING ====================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"PART 8: MODEL INITIALIZATION\")\nprint(\"=\" * 80)\n\nmodel = EnhancedFusionModel(cfg).to(device)\n\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f\"\\nModel Statistics:\")\nprint(f\"  Total parameters: {total_params:,}\")\nprint(f\"  Trainable parameters: {trainable_params:,}\")\nprint(f\"  Frozen parameters: {total_params - trainable_params:,}\")\n\nemotion_loss_fn = EnhancedAsymmetricLoss(\n    gamma_neg=cfg['ASL_GAMMA_NEG'],\n    gamma_pos=cfg['ASL_GAMMA_POS'],\n    clip=cfg['ASL_CLIP'],\n    priors=cfg['EMO_PRIORS'],\n    prior_tau=cfg['ASL_PRIOR_TAU']\n)\n\nprint(f\"\\nâœ“ Enhanced ASL initialized:\")\nprint(f\"  gamma_neg={cfg['ASL_GAMMA_NEG']}, gamma_pos={cfg['ASL_GAMMA_POS']}\")\nprint(f\"  Prior adjustment: tau={cfg['ASL_PRIOR_TAU']}\")\nprint(f\"  Priors: {[f'{p:.3f}' for p in cfg['EMO_PRIORS']]}\")\n\ntrainer = Trainer(model, cfg, train_loader, val_loader, device, emotion_loss_fn)\n\nprint(\"\\nâœ“ Trainer initialized\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"STARTING TRAINING\")\nprint(\"=\" * 80)\n\nbest_metric = trainer.fit()\n\nprint(f\"\\n{'='*80}\")\nprint(\"âœ… TRAINING COMPLETED!\")\nprint(f\"{'='*80}\")\nprint(f\"Best composite metric: {best_metric:.4f}\")\nprint(f\"Model saved to: {cfg['CHECKPOINT_PATH']}/best_model_enhanced.pt\")\n\nmodel_card_lines = [\n    \"# Enhanced Multi-modal Meme Analysis Model\",\n    \"\",\n    \"## Overview\",\n    \"This model uses a hybrid loss strategy combining ordinal regression for sentiment\",\n    \"and enhanced asymmetric loss (ASL) with prior adjustment for emotions.\",\n    \"\",\n    \"## Key Improvements\",\n    \"\",\n    \"### 1. Hybrid Loss Strategy\",\n    \"- Sentiment: Ordinal regression respects natural class ordering, with class-weighting\",\n    \"  to emphasize extreme sentiments.\",\n    f\"- Emotions: Enhanced ASL with positive focusing (gamma_pos={cfg['ASL_GAMMA_POS']})\",\n    f\"  and prior adjustment (tau={cfg['ASL_PRIOR_TAU']}).\",\n    \"- Intensity: Smooth L1 loss.\",\n    \"\",\n    \"### 2. Oversampling Strategy\",\n    f\"- Motivational oversampling factor: {cfg['MOTIVATIONAL_OVERSAMPLE_FACTOR']}x\",\n    f\"- Extreme sentiment oversampling factor (very_positive / very_negative): {cfg['EXTREME_SENTIMENT_OVERSAMPLE_FACTOR']}x\",\n    f\"- Original motivational representation: {motivational_pct:.2f}%\",\n    f\"- Effective motivational representation: {effective_motivational:.1f}%\",\n    f\"- Original extreme representation: {extreme_pct:.2f}%\",\n    f\"- Effective extreme representation: {effective_extreme:.1f}%\",\n    \"\",\n    \"### 3. Early Backbone Unfreezing\",\n    f\"- Unfreezes at epoch {cfg['UNFREEZE_BACKBONE_EPOCH']}\",\n    f\"- Layers unfrozen: {cfg['UNFREEZE_LAYERS']}\",\n    \"\",\n    \"## Architecture\",\n    f\"- Text encoder: {cfg['TEXT_MODEL']}\",\n    f\"- Image encoder: {cfg['IMAGE_MODEL']}\",\n    \"- Fusion: Bidirectional cross-attention\",\n    f\"- Parameters: {total_params:,} total, {trainable_params:,} trainable\",\n    \"\",\n    \"## Training Details\",\n    f\"- Epochs: {cfg['EPOCHS']}\",\n    f\"- Batch size: {cfg['BATCH_SIZE']}\",\n    f\"- LR (heads): {cfg['LR_HEADS']}\",\n    f\"- LR (backbone): {cfg['LR_BACKBONE']}\",\n    f\"- Loss weights: Sentiment={cfg['LOSS_WEIGHTS']['sentiment']}, \"\n    f\"Emotion={cfg['LOSS_WEIGHTS']['emotion']}, Intensity={cfg['LOSS_WEIGHTS']['intensity']}\",\n    \"\",\n    \"## Performance\",\n    f\"- Best composite metric: {best_metric:.4f}\",\n    \"\",\n    \"## Dataset\",\n    f\"- Training samples: {len(train_df):,}\",\n    f\"- Validation samples: {len(val_df):,}\",\n    \"\",\n    \"## Inference Hint\",\n    \"Use the same expected-value based decoding as in validation:\",\n    \"\",\n    \"```python\",\n    \"with torch.no_grad():\",\n    \"    outputs = model(input_ids, attention_mask, image)\",\n    \"    sentiment_probs = outputs['sentiment']['class_probs']\",\n    \"    num_classes = sentiment_probs.size(1)\",\n    \"    ev = (sentiment_probs * torch.arange(num_classes, device=sentiment_probs.device)).sum(dim=1)\",\n    \"    # Map ev to class index using cfg['SENTIMENT_EXPECTED_THRESHOLDS']\",\n    \"    emotions = torch.sigmoid(outputs['emotion_logits'])\",\n    \"```\",\n]\n\nmodel_card = \"\\n\".join(model_card_lines)\n\nmodel_card_path = os.path.join(cfg['CHECKPOINT_PATH'], 'model_card.md')\nwith open(model_card_path, 'w') as f:\n    f.write(model_card)\n\nprint(f\"\\nâœ“ Model card saved to: {model_card_path}\")\nprint(\"\\n\" + \"=\" * 80)\nprint(\"ALL DONE! ðŸŽ‰\")\nprint(\"=\" * 80 + \"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T23:35:48.380612Z","iopub.execute_input":"2025-11-20T23:35:48.381285Z","iopub.status.idle":"2025-11-20T23:56:48.335331Z","shell.execute_reply.started":"2025-11-20T23:35:48.381258Z","shell.execute_reply":"2025-11-20T23:56:48.334290Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nINSTALLING DEPENDENCIES...\n================================================================================\nâœ“ All dependencies installed\n\n================================================================================\nPART 1: DATA PREPARATION\n================================================================================\n\nDownloading dataset...\nExtracting dataset...\nExtracting protected archive...\nâœ“ Extracted to: /kaggle/working/\n\nLoading CSV file...\nâœ“ Image column: Unnamed: 0\n\nâœ“ Stratified split complete:\n  Training: 5950 samples\n  Validation: 1050 samples\n\nâœ“ Label priors calculated:\n  offensive_pos_rate: 0.3909\n  motivational_pos_rate: 0.1187\n  humor_pos_rate: 0.8558\n  sarcasm_pos_rate: 0.7891\n\nCopying images...\n","output_type":"stream"},{"name":"stderr","text":"Copying to /kaggle/working/validation_images/: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1050/1050 [00:00<00:00, 5975.73it/s]\nCopying to /kaggle/working/new_train_images/: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5950/5950 [00:01<00:00, 5543.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"âœ“ Validation: 1050 copied, 0 missing\nâœ“ Training: 5950 copied, 0 missing\n\nâœ“ Saved train CSV: /kaggle/working/train_split.csv\nâœ“ Saved validation CSV: /kaggle/working/validation_split.csv\n\nâœ… DATA PREPARATION COMPLETE\n\n================================================================================\nPART 2: CONFIGURATION\n================================================================================\n\nâœ“ Configuration loaded:\n  Device: cuda\n  Epochs: 20\n  Batch size: 16\n  Motivational oversampling: 8.0x\n  Extreme sentiment oversampling: 5.0x\n  Emotion priors: ['0.856', '0.789', '0.391', '0.119']\n\n================================================================================\nPART 3: MODEL COMPONENTS\n================================================================================\nâœ“ Model components defined\n\n================================================================================\nPART 4: DATASET\n================================================================================\nâœ“ Dataset class defined\n\n================================================================================\nPART 5: LOSS FUNCTIONS & METRICS\n================================================================================\nâœ“ Loss functions and metrics defined\n\n================================================================================\nPART 6: TRAINER\n================================================================================\nâœ“ Trainer class defined\n\n================================================================================\nPART 7: DATA LOADING & PREPARATION\n================================================================================\nâœ“ Tokenizer and transforms initialized\nâœ“ Train dataset: 5950 samples\nâœ“ Val dataset: 1050 samples\n\nCreating weighted sampler...\n  Motivational samples: 706 (11.87%)\n  Oversampling factor (motivational): 8.0x\n  Effective motivational representation: 94.9%\n  Extreme sentiment samples (very_pos/very_neg): 581 (9.76%)\n  Oversampling factor (extremes): 5.0x\n  Effective extreme representation: 48.8%\nâœ“ Train batches: 371\nâœ“ Val batches: 66\n\n================================================================================\nPART 8: MODEL INITIALIZATION\n================================================================================\n\nModel Statistics:\n  Total parameters: 333,224,714\n  Trainable parameters: 8,212,490\n  Frozen parameters: 325,012,224\n\nâœ“ Enhanced ASL initialized:\n  gamma_neg=6.0, gamma_pos=0.5\n  Prior adjustment: tau=1.2\n  Priors: ['0.856', '0.789', '0.391', '0.119']\n\nâœ“ Trainer initialized\n\n================================================================================\nSTARTING TRAINING\n================================================================================\n\n======================================================================\nSTARTING TRAINING: 20 EPOCHS\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 1/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:38<00:00,  9.71it/s, loss=1.5764]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 1.4921\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 1 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 1):\n  Loss: 1.3405\n  Sentiment Accuracy: 0.3362\n  Sentiment F1: 0.2126\n  Sentiment MAE: 0.8800\n  Sentiment 1-off Acc: 0.8067\n  Emotion F1: 0.7723\n======================================================================\n\nâœ“ Saved best model (composite: 1.2977)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 2/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:38<00:00,  9.70it/s, loss=1.3748]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 1.2829\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 2 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 2):\n  Loss: 1.4670\n  Sentiment Accuracy: 0.3210\n  Sentiment F1: 0.2614\n  Sentiment MAE: 0.9486\n  Sentiment 1-off Acc: 0.7771\n  Emotion F1: 0.7725\n======================================================================\n\n\n======================================================================\nðŸ”“ UNFREEZING BACKBONE at epoch 3\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 3/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.84it/s, loss=0.5593]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 1.0888\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 3 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 3):\n  Loss: 1.2462\n  Sentiment Accuracy: 0.4010\n  Sentiment F1: 0.2265\n  Sentiment MAE: 0.7295\n  Sentiment 1-off Acc: 0.8838\n  Emotion F1: 0.7725\n======================================================================\n\nâœ“ Saved best model (composite: 1.5395)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 4/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.84it/s, loss=0.7047]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.8090\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 4 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 4):\n  Loss: 1.1457\n  Sentiment Accuracy: 0.4314\n  Sentiment F1: 0.2309\n  Sentiment MAE: 0.6876\n  Sentiment 1-off Acc: 0.8867\n  Emotion F1: 0.7725\n======================================================================\n\nâœ“ Saved best model (composite: 1.5887)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 5/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.83it/s, loss=1.1620]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.6977\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 5 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 5):\n  Loss: 1.2570\n  Sentiment Accuracy: 0.3848\n  Sentiment F1: 0.2552\n  Sentiment MAE: 0.7838\n  Sentiment 1-off Acc: 0.8514\n  Emotion F1: 0.7725\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 6/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.84it/s, loss=0.6178]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.6278\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 6 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 6):\n  Loss: 1.1588\n  Sentiment Accuracy: 0.4267\n  Sentiment F1: 0.2452\n  Sentiment MAE: 0.7019\n  Sentiment 1-off Acc: 0.8810\n  Emotion F1: 0.7725\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 7/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.83it/s, loss=0.5110]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.5580\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 7 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 7):\n  Loss: 1.1383\n  Sentiment Accuracy: 0.4152\n  Sentiment F1: 0.2173\n  Sentiment MAE: 0.7114\n  Sentiment 1-off Acc: 0.8800\n  Emotion F1: 0.7721\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 8/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.83it/s, loss=0.4637]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.5293\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 8 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 8):\n  Loss: 1.1102\n  Sentiment Accuracy: 0.4257\n  Sentiment F1: 0.2405\n  Sentiment MAE: 0.7010\n  Sentiment 1-off Acc: 0.8790\n  Emotion F1: 0.7737\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 9/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.84it/s, loss=0.3486]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4957\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 9 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 9):\n  Loss: 1.0636\n  Sentiment Accuracy: 0.4257\n  Sentiment F1: 0.2182\n  Sentiment MAE: 0.6838\n  Sentiment 1-off Acc: 0.8943\n  Emotion F1: 0.7725\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 10/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.84it/s, loss=0.3523]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4777\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 10 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 10):\n  Loss: 1.0805\n  Sentiment Accuracy: 0.4381\n  Sentiment F1: 0.2325\n  Sentiment MAE: 0.6829\n  Sentiment 1-off Acc: 0.8867\n  Emotion F1: 0.7725\n======================================================================\n\nâœ“ Saved best model (composite: 1.5951)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 11/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.83it/s, loss=0.4972]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4295\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 11 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 11):\n  Loss: 1.0895\n  Sentiment Accuracy: 0.4390\n  Sentiment F1: 0.2353\n  Sentiment MAE: 0.6762\n  Sentiment 1-off Acc: 0.8914\n  Emotion F1: 0.7725\n======================================================================\n\nâœ“ Saved best model (composite: 1.6093)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 12/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.85it/s, loss=0.4463]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4084\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 12 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 12):\n  Loss: 1.1506\n  Sentiment Accuracy: 0.4324\n  Sentiment F1: 0.2546\n  Sentiment MAE: 0.6952\n  Sentiment 1-off Acc: 0.8829\n  Emotion F1: 0.7725\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 13/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.84it/s, loss=0.4195]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4322\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 13 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 13):\n  Loss: 1.2384\n  Sentiment Accuracy: 0.4171\n  Sentiment F1: 0.2432\n  Sentiment MAE: 0.7105\n  Sentiment 1-off Acc: 0.8848\n  Emotion F1: 0.7727\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 14/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.85it/s, loss=0.5461]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4430\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 14 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 14):\n  Loss: 1.2422\n  Sentiment Accuracy: 0.4219\n  Sentiment F1: 0.2481\n  Sentiment MAE: 0.7114\n  Sentiment 1-off Acc: 0.8800\n  Emotion F1: 0.7727\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 15/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.84it/s, loss=0.3939]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4418\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 15 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 15):\n  Loss: 1.2452\n  Sentiment Accuracy: 0.4143\n  Sentiment F1: 0.2457\n  Sentiment MAE: 0.7210\n  Sentiment 1-off Acc: 0.8790\n  Emotion F1: 0.7727\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 16/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.84it/s, loss=0.5094]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4505\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 16 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 16):\n  Loss: 1.2476\n  Sentiment Accuracy: 0.4114\n  Sentiment F1: 0.2439\n  Sentiment MAE: 0.7248\n  Sentiment 1-off Acc: 0.8790\n  Emotion F1: 0.7727\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 17/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.85it/s, loss=0.4361]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4388\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 17 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 17):\n  Loss: 1.2494\n  Sentiment Accuracy: 0.4124\n  Sentiment F1: 0.2454\n  Sentiment MAE: 0.7248\n  Sentiment 1-off Acc: 0.8781\n  Emotion F1: 0.7727\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 18/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.83it/s, loss=0.5918]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4471\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 18 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 18):\n  Loss: 1.2505\n  Sentiment Accuracy: 0.4124\n  Sentiment F1: 0.2455\n  Sentiment MAE: 0.7267\n  Sentiment 1-off Acc: 0.8762\n  Emotion F1: 0.7727\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 19/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.83it/s, loss=0.3884]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4406\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 19 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 19):\n  Loss: 1.2513\n  Sentiment Accuracy: 0.4124\n  Sentiment F1: 0.2455\n  Sentiment MAE: 0.7267\n  Sentiment 1-off Acc: 0.8762\n  Emotion F1: 0.7727\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/20 [Train]:   0%|          | 0/371 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 20/20 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 371/371 [00:54<00:00,  6.84it/s, loss=0.3862]\n","output_type":"stream"},{"name":"stdout","text":"\nTrain Loss: 0.4328\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20 [Val]:   0%|          | 0/66 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nEpoch 20 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66/66 [00:05<00:00, 11.25it/s]","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nValidation Results (Epoch 20):\n  Loss: 1.2518\n  Sentiment Accuracy: 0.4124\n  Sentiment F1: 0.2455\n  Sentiment MAE: 0.7267\n  Sentiment 1-off Acc: 0.8762\n  Emotion F1: 0.7727\n======================================================================\n\n\nâœ… TRAINING COMPLETED!\n\n================================================================================\nâœ… TRAINING COMPLETED!\n================================================================================\nBest composite metric: 1.6093\nModel saved to: /kaggle/working/checkpoints/best_model_enhanced.pt\n\nâœ“ Model card saved to: /kaggle/working/checkpoints/model_card.md\n\n================================================================================\nALL DONE! ðŸŽ‰\n================================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}